nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000024F94D68308>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 58.0387, LR: 0.0000100000
真实数据: 们也达到了相当高的水
结果显示: 他，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 65.3909, LR: 0.0000100000
真实数据: 给我读某些章。忍不住
结果显示: 经的，的
Epoch 0 Step 000200, model loss 61.1985, LR: 0.0000100000
真实数据: 在五光十色的包装下面
结果显示: 在的在的
Epoch 0 Step 000300, model loss 74.0925, LR: 0.0000100000
真实数据: 黍。住宿费1200元
结果显示: 在，1人
Epoch 0 Step 000400, model loss 56.5987, LR: 0.0000100000
真实数据: 0年签署的现行合作协
结果显示: 0的是的
Epoch 0 Step 000500, model loss 63.8273, LR: 0.0000100000
真实数据: 有了自己的姓名CN域
结果显示: 了，一，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 65.5359, LR: 0.0000100000
真实数据: 益，又犯下第二个错误
结果显示: 在，、，、”
Epoch 0 Step 000700, model loss 59.5350, LR: 0.0000100000
真实数据: 别调高12%和13%
结果显示: 这，的，0
Epoch 0 Step 000800, model loss 59.9327, LR: 0.0000100000
真实数据: 一批破网而出的步兵第
结果显示: 一个的，的
Epoch 0 Step 000900, model loss 55.7058, LR: 0.0000100000
真实数据: 1%-20%左右的正
结果显示: 1010
Epoch 0 Step 001000, model loss 69.0404, LR: 0.0000100000
真实数据: 点访谈”之后红遍大江
结果显示: 在的，的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 63.5404, LR: 0.0000100000
真实数据: 令别给一舍，一边回答
结果显示: 不，的，的
Epoch 0 Step 001200, model loss 65.9323, LR: 0.0000100000
真实数据: 售原非流通股的价格不
结果显示: 在的在的
Epoch 0 Step 001300, model loss 66.7134, LR: 0.0000100000
真实数据: 何以养妻子?”女但言
结果显示: 他，的，的
Epoch 0 Step 001400, model loss 64.4313, LR: 0.0000100000
真实数据: 国牙防组属于非法人机
结果显示: 国的，的
Epoch 0 Step 001500, model loss 64.9065, LR: 0.0000100000
真实数据: 才碰她，由此往来不绝
结果显示: 不，的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 59.4721, LR: 0.0000100000
真实数据: 有一家英国报纸因此而
结果显示: 有，一的
Epoch 0 Step 001700, model loss 68.1171, LR: 0.0000100000
真实数据: 朝鲜战争:都可以做呢
结果显示: 就，的，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000164B409E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 70.2432, LR: 0.0000100000
真实数据: 才显精神;杀死大义公
结果显示: 不的，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 78.6493, LR: 0.0000100000
真实数据: 论台一抖动就把他给抖
结果显示: 就的大的
Epoch 0 Step 000200, model loss 66.7875, LR: 0.0000100000
真实数据: 山人民邮电报)中国老
结果显示: 的的，的
Epoch 0 Step 000300, model loss 62.7962, LR: 0.0000100000
真实数据: 学与技术，苏联又未能
结果显示: 于，的，的
Epoch 0 Step 000400, model loss 67.8467, LR: 0.0000100000
真实数据: 一群单身汉聚集在大街
结果显示: 二是的，的
Epoch 0 Step 000500, model loss 66.3356, LR: 0.0000100000
真实数据: 而且双方在估价上差距
结果显示: 而的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 64.7992, LR: 0.0000100000
真实数据: ，忽然发现身边的劲敌
结果显示: ，在的是的
Epoch 0 Step 000700, model loss 60.8035, LR: 0.0000100000
真实数据: “我最爱《黄河》一首
结果显示: “的，的，的
Epoch 0 Step 000800, model loss 73.4408, LR: 0.0000100000
真实数据: %折算记入高考成绩总
结果显示: 当的，的
Epoch 0 Step 000900, model loss 61.4354, LR: 0.0000100000
真实数据: 所有的恶行似乎都是对
结果显示: 能的在的
Epoch 0 Step 001000, model loss 56.4659, LR: 0.0000100000
真实数据: 自己原先企业在经营中
结果显示: 自的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 65.0704, LR: 0.0000100000
真实数据: 应当增加公司经营特色
结果显示: 在的，的
Epoch 0 Step 001200, model loss 61.2057, LR: 0.0000100000
真实数据: 的高价，应重新签订合
结果显示: 的，的，的
Epoch 0 Step 001300, model loss 68.6349, LR: 0.0000100000
真实数据: 按规定收回国防奖学金
结果显示: 据的，的
Epoch 0 Step 001400, model loss 59.3312, LR: 0.0000100000
真实数据: 分，么说都放了?此理
结果显示: 是，、的
Epoch 0 Step 001500, model loss 57.3115, LR: 0.0000100000
真实数据: 司面向企业开发的Cl
结果显示: 。不的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 66.9145, LR: 0.0000100000
真实数据: 丽素红”的“红心”鸡
结果显示: 而，一，一
Epoch 0 Step 001700, model loss 62.6045, LR: 0.0000100000
真实数据: 模、结构、投向、投量
结果显示: 们，、”
Epoch 0 Step 001800, model loss 74.0704, LR: 0.0000100000
真实数据: 内现存两块张献忠“圣
结果显示: 的，的，的
Epoch 0 Step 001900, model loss 64.4520, LR: 0.0000100000
真实数据: 定自行更改公务员工资
结果显示: 业的，的
Epoch 0 Step 002000, model loss 56.2628, LR: 0.0000100000
真实数据: 业仍停留在“人有我也
结果显示: 业的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 86.2035, LR: 0.0000100000
真实数据: 珠玉。（完）“吾侪日
结果显示: 正，一，一
Epoch 0 Step 002200, model loss 60.4637, LR: 0.0000100000
真实数据: 458但我们会给比赛
结果显示: 4的，的
Epoch 0 Step 002300, model loss 64.7364, LR: 0.0000100000
真实数据: 尔阳光总是会在不自觉
结果显示: 2的0的
Epoch 0 Step 002400, model loss 69.7308, LR: 0.0000100000
真实数据: 严查绕道赴台旅游的旅
结果显示: 而的和的
Epoch 0 Step 002500, model loss 62.2161, LR: 0.0000100000
真实数据: ，人体内有一“碘”字
结果显示: ，是的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 81.0440, LR: 0.0000100000
真实数据: 我创作的是濮存昕式的
结果显示: 去是的，的
Epoch 0 Step 002700, model loss 86.8565, LR: 0.0000100000
真实数据: 言“夷狄无君父殆二千
结果显示: 但”、”的
Epoch 0 Step 002800, model loss 75.8995, LR: 0.0000100000
真实数据: 好大圣，最悍妒，文章
结果显示: 如，。，一
Epoch 0 Step 002900, model loss 62.3101, LR: 0.0000100000
真实数据: 在不受任何痛苦的情况
结果显示: 我的在的
Epoch 0 Step 003000, model loss 70.9025, LR: 0.0000100000
真实数据: 第二章组织机构及其职
结果显示: 要是的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 76.9602, LR: 0.0000100000
真实数据: 间为7.59倍―――
结果显示: 0，010
Epoch 0 Step 003200, model loss 63.6127, LR: 0.0000100000
真实数据: 而然地”拓宽、“顺理
结果显示: 在是，。，
Epoch 0 Step 003300, model loss 68.2190, LR: 0.0000100000
真实数据: 将持续下去。霍宝柱说
结果显示: 将的，的，的
Epoch 0 Step 003400, model loss 68.7494, LR: 0.0000100000
真实数据: 积金百余两，手即飞出
结果显示: 在的，的
Epoch 0 Step 003500, model loss 96.3669, LR: 0.0000100000
真实数据: 朋友叫王谧的慷慨解囊
结果显示: 用的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 74.1502, LR: 0.0000100000
真实数据: 贼遂持兵器，利于保持
结果显示: 发的，的，的
Epoch 0 Step 003700, model loss 66.6450, LR: 0.0000100000
真实数据: 纯收入已近4000元
结果显示: 我200
Epoch 0 Step 003800, model loss 78.8298, LR: 0.0000100000
真实数据: 希望忘记这段可歌可泣
结果显示: 是的是的
Epoch 0 Step 003900, model loss 67.0690, LR: 0.0000100000
真实数据: 是从春秋早期开始研究
结果显示: 是的，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000276063FE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 61.4661, LR: 0.0000100000
真实数据: 每次默写前，是“知道
结果显示: 是，的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 63.8604, LR: 0.0000100000
真实数据: 很多中国老兵都能记起
结果显示: 是的，的
Epoch 0 Step 000200, model loss 64.9512, LR: 0.0000100000
真实数据: 行动。国民党军购小组
结果显示: 1，0，的
Epoch 0 Step 000300, model loss 59.0496, LR: 0.0000100000
真实数据: :S0为期初股份总数
结果显示: :的0的
Epoch 0 Step 000400, model loss 67.9366, LR: 0.0000100000
真实数据: 电磁环境中的对抗演练
结果显示: 的是的
Epoch 0 Step 000500, model loss 65.0446, LR: 0.0000100000
真实数据: 先是他们肾内科，高勇
结果显示: 年的的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 61.9543, LR: 0.0000100000
真实数据: 其规模、承修能力、人
结果显示: 为，一，一
Epoch 0 Step 000700, model loss 63.1496, LR: 0.0000100000
真实数据: 也能让你水涨船高，了
结果显示: 1的的
Epoch 0 Step 000800, model loss 67.9661, LR: 0.0000100000
真实数据: 至一再减少收购这款飞
结果显示: 不，一的
Epoch 0 Step 000900, model loss 57.9136, LR: 0.0000100000
真实数据: 了为期一周的各军、兵
结果显示: 了一”，一
Epoch 0 Step 001000, model loss 72.5417, LR: 0.0000100000
真实数据: 去。该项目计划在宝钛
结果显示: 人，的有的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 80.8023, LR: 0.0000100000
真实数据: 他便吩咐手下人不要声
结果显示: 他是，的，的
Epoch 0 Step 001200, model loss 70.4470, LR: 0.0000100000
真实数据: 故乘俄联邦军事工业委
结果显示: 的不的
Epoch 0 Step 001300, model loss 61.9409, LR: 0.0000100000
真实数据: 国培植共产主义目的”
结果显示: 国的是，的
Epoch 0 Step 001400, model loss 71.0055, LR: 0.0000100000
真实数据: 的处!若论你令郎讲起
结果显示: 的，的，的
Epoch 0 Step 001500, model loss 57.2707, LR: 0.0000100000
真实数据: 为“证券通”独家拥有
结果显示: 为，“”的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 61.6773, LR: 0.0000100000
真实数据: 队主教练的薪水提高到
结果显示: 的是的
Epoch 0 Step 001700, model loss 56.7620, LR: 0.0000100000
真实数据: 月一次单场51分的表
结果显示: 1一，的
Epoch 0 Step 001800, model loss 68.8769, LR: 0.0000100000
真实数据: 。举天下之豪杰莫能与
结果显示: ，的，的
Epoch 0 Step 001900, model loss 66.4749, LR: 0.0000100000
真实数据: 长期性、战略性来考虑
结果显示: 但一，一，
Epoch 0 Step 002000, model loss 57.0151, LR: 0.0000100000
真实数据: 三合一”地方选举的大
结果显示: 一，一，一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 68.4873, LR: 0.0000100000
真实数据: 贿赂可能转化的速度会
结果显示: 也是的，的
Epoch 0 Step 002200, model loss 63.7052, LR: 0.0000100000
真实数据: 相同。本报记者日前通
结果显示: 是一，的，的
Epoch 0 Step 002300, model loss 67.9791, LR: 0.0000100000
真实数据: 席会议有效表决权股份
结果显示: 的是的
Epoch 0 Step 002400, model loss 78.7918, LR: 0.0000100000
真实数据: 元做劳务费盛稀奇素物
结果显示: 对的是的
Epoch 0 Step 002500, model loss 63.1112, LR: 0.0000100000
真实数据: 徒弟同看，有40%最
结果显示: 他，。，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 69.0602, LR: 0.0000100000
真实数据: 杨女士心里还是在打鼓
结果显示: 他的，的
Epoch 0 Step 002700, model loss 73.3687, LR: 0.0000100000
真实数据: 传淮南市对高校使用正
结果显示: 他的不的
Epoch 0 Step 002800, model loss 64.8111, LR: 0.0000100000
真实数据: 里就踏实了。数据显示
结果显示: 是，。，
Epoch 0 Step 002900, model loss 77.2995, LR: 0.0000100000
真实数据: 天从宝岛、锋豪等连锁
结果显示: 大是，是的
Epoch 0 Step 003000, model loss 58.3209, LR: 0.0000100000
真实数据: 接导致“一城两制、一
结果显示: 是，。，。，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 77.9196, LR: 0.0000100000
真实数据: 引诱嫖赌，“主席为冠
结果显示: 我，。，
Epoch 0 Step 003200, model loss 65.9442, LR: 0.0000100000
真实数据: 参与答题的博客用户也
结果显示: 我的有的
Epoch 0 Step 003300, model loss 64.0807, LR: 0.0000100000
真实数据: 作了一个非常坚固而精
结果显示: 作，”“”
Epoch 0 Step 003400, model loss 67.8977, LR: 0.0000100000
真实数据: 千名印度少女前来报名
结果显示: 于是的，的
Epoch 0 Step 003500, model loss 75.6258, LR: 0.0000100000
真实数据: 时去游览秘鲁和玻利维
结果显示: 的，的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 75.5802, LR: 0.0000100000
真实数据: 五――省水环保的洗衣
结果显示: 不，一”的
Epoch 0 Step 003700, model loss 51.1145, LR: 0.0000100000
真实数据: 从4月1日起，同时展
结果显示: 是1，的
Epoch 0 Step 003800, model loss 61.0109, LR: 0.0000100000
真实数据: 阔，大四期间，一个好
结果显示: 即，。，的
Epoch 0 Step 003900, model loss 64.5784, LR: 0.0000100000
真实数据: 则能够接受她们多变的
结果显示: 他的，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000024D366FE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 70.3924, LR: 0.0000100000
真实数据: 吴成方和吴的上级张唯
结果显示: 是的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 72.2645, LR: 0.0000100000
真实数据: 到银行贷5块钱都困难
结果显示: 对的有的
Epoch 0 Step 000200, model loss 69.5308, LR: 0.0000100000
真实数据: 投票与委托董事会投票
结果显示: 是的了的
Epoch 0 Step 000300, model loss 55.4447, LR: 0.0000100000
真实数据: 续上涨，到过这里的人
结果显示: 当，的，的
Epoch 0 Step 000400, model loss 68.2217, LR: 0.0000100000
真实数据: 事基本策略的脉络仍清
结果显示: 要的
Epoch 0 Step 000500, model loss 74.9009, LR: 0.0000100000
真实数据: 申花确定将启动第三外
结果显示: 中国的国的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 63.3562, LR: 0.0000100000
真实数据: 跑不是很一致，将其召
结果显示: 时，的，一
Epoch 0 Step 000700, model loss 65.0502, LR: 0.0000100000
真实数据: 过混合空调系统中的空
结果显示: 1是的的
Epoch 0 Step 000800, model loss 57.8264, LR: 0.0000100000
真实数据: 的时候就想我们如何营
结果显示: 的是的是的
Epoch 0 Step 000900, model loss 77.1268, LR: 0.0000100000
真实数据: 实现床旁血气、床旁胸
结果显示: 来，的，的
Epoch 0 Step 001000, model loss 30.8551, LR: 0.0000100000
真实数据: 2005年9月22日
结果显示: 20年5年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 70.4396, LR: 0.0000100000
真实数据: 人服食下金刚石粉末后
结果显示: 人，的，的
Epoch 0 Step 001200, model loss 56.0809, LR: 0.0000100000
真实数据: 就是最重要的节约行为
结果显示: 就的，的，的
Epoch 0 Step 001300, model loss 59.6780, LR: 0.0000100000
真实数据: 如果为真，先要了解目
结果显示: 人，。，一
Epoch 0 Step 001400, model loss 62.3063, LR: 0.0000100000
真实数据: 公务员录取比例为24
结果显示: 公的的
Epoch 0 Step 001500, model loss 64.9267, LR: 0.0000100000
真实数据: 这里的居民们几乎与世
结果显示: 司的的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 64.7161, LR: 0.0000100000
真实数据: 国C2C网上购物调查
结果显示: 301010
Epoch 0 Step 001700, model loss 59.3353, LR: 0.0000100000
真实数据: 成交金额是532.7
结果显示: 成，的，的
Epoch 0 Step 001800, model loss 70.2839, LR: 0.0000100000
真实数据: 婚，其实，曼秀雷敦招
结果显示: 的，一，的
Epoch 0 Step 001900, model loss 70.9917, LR: 0.0000100000
真实数据: 操作较为简单,计算之
结果显示: 其，的，的
Epoch 0 Step 002000, model loss 66.8128, LR: 0.0000100000
真实数据: 术回家康复来上海之前
结果显示: 我，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 65.9051, LR: 0.0000100000
真实数据: 什么比罚款更好的办法
结果显示: 在的有的
Epoch 0 Step 002200, model loss 69.8259, LR: 0.0000100000
真实数据: 在巨大的物质诱惑面前
结果显示: 在的0的
Epoch 0 Step 002300, model loss 36.6954, LR: 0.0000100000
真实数据: theyarepai
结果显示: 0e0e01
Epoch 0 Step 002400, model loss 59.5533, LR: 0.0000100000
真实数据: 主管是从其他部门调过
结果显示: 上的不的
Epoch 0 Step 002500, model loss 61.5649, LR: 0.0000100000
真实数据: 两家银行已经基本达到
结果显示: 而的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 58.0676, LR: 0.0000100000
真实数据: 是我射的?”老黑看了
结果显示: 是，的，的
Epoch 0 Step 002700, model loss 57.6836, LR: 0.0000100000
真实数据: 就是把别人画的东西连
结果显示: 就的人的
Epoch 0 Step 002800, model loss 72.0679, LR: 0.0000100000
真实数据: (专题访谈咨询)病毒
结果显示: 已经的的
Epoch 0 Step 002900, model loss 61.0399, LR: 0.0000100000
真实数据: 要求经营者采取更为健
结果显示: 要的在的
Epoch 0 Step 003000, model loss 63.4669, LR: 0.0000100000
真实数据: 年中国邮电部对普通客
结果显示: 在的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 80.0092, LR: 0.0000100000
真实数据: 仪、金城武、邵美琪主
结果显示: 作，、”
Epoch 0 Step 003200, model loss 63.8597, LR: 0.0000100000
真实数据: 能干，实在是个伪命题
结果显示: 我，一，的
Epoch 0 Step 003300, model loss 65.2175, LR: 0.0000100000
真实数据: 不抱成见。看得人眼花
结果显示: 个，一，的
Epoch 0 Step 003400, model loss 68.4195, LR: 0.0000100000
真实数据: 是功德无量的贡献。离
结果显示: 是的在的
Epoch 0 Step 003500, model loss 73.0059, LR: 0.0000100000
真实数据: 这飞机武器都已经拆掉
结果显示: 这是的有的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 79.3894, LR: 0.0000100000
真实数据: 庭劝阻和社会舆论压力
结果显示: 时的，的，的
Epoch 0 Step 003700, model loss 64.9206, LR: 0.0000100000
真实数据: 郭有抄本，就学不了几
结果显示: 我，的，的
Epoch 0 Step 003800, model loss 65.9347, LR: 0.0000100000
真实数据: 起了海内外的广泛关注
结果显示: 是的，的
Epoch 0 Step 003900, model loss 64.5249, LR: 0.0000100000
真实数据: 的进度表提前3年完成
结果显示: 的，是，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E9D3D9E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 64.1220, LR: 0.0000100000
真实数据: 截至3月末，公司对员
结果显示: 我是的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 65.0823, LR: 0.0000100000
真实数据: 门旅游、餐饮、酒店业
结果显示: ，本，，
Epoch 0 Step 000200, model loss 76.6630, LR: 0.0000100000
真实数据: 疗保险个人账户余额超
结果显示: 成的，的
Epoch 0 Step 000300, model loss 80.3377, LR: 0.0000100000
真实数据: 就像把耳朵贴在大海螺
结果显示: 我的在的
Epoch 0 Step 000400, model loss 64.4169, LR: 0.0000100000
真实数据: 联合总会上海支部主任
结果显示: 这，的，的
Epoch 0 Step 000500, model loss 66.5979, LR: 0.0000100000
真实数据: 而上届冠军马刺队在4
结果显示: 可在的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 67.0586, LR: 0.0000100000
真实数据: 导爆索生产线、年产3
结果显示: 这、的，的
Epoch 0 Step 000700, model loss 67.0416, LR: 0.0000100000
真实数据: 价工程师执业资格考试
结果显示: 但的，的
Epoch 0 Step 000800, model loss 72.6156, LR: 0.0000100000
真实数据: 线能够缩短装配期十分
结果显示: 经的是的
Epoch 0 Step 000900, model loss 73.1302, LR: 0.0000100000
真实数据: “有清肺解毒化痰之功
结果显示: “我的有的
Epoch 0 Step 001000, model loss 64.2227, LR: 0.0000100000
真实数据: :此外，联城这匹黑马
结果显示: :有的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 71.1565, LR: 0.0000100000
真实数据: 后林乐丰和福拉多也冲
结果显示: 是的有的
Epoch 0 Step 001200, model loss 79.6615, LR: 0.0000100000
真实数据: 坚硬的岩石和几处树木
结果显示: 这的0的
Epoch 0 Step 001300, model loss 72.2347, LR: 0.0000100000
真实数据: 的碘完全依赖自然环境
结果显示: 的是的在的
Epoch 0 Step 001400, model loss 70.7069, LR: 0.0000100000
真实数据: 了给用户提供更加舒适
结果显示: 人在的是的
Epoch 0 Step 001500, model loss 65.6453, LR: 0.0000100000
真实数据: 国际先驱导报文章在今
结果显示: 同有的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 50.8388, LR: 0.0000100000
真实数据: 1000多家从事国际
结果显示: 10年
Epoch 0 Step 001700, model loss 54.8112, LR: 0.0000100000
真实数据: 去了一半。马，现在在
结果显示: 人，一，
Epoch 0 Step 001800, model loss 68.4986, LR: 0.0000100000
真实数据: 仙见刘，而且“起步价
结果显示: 们，一，
Epoch 0 Step 001900, model loss 69.3742, LR: 0.0000100000
真实数据: 以，闻骰声，新浪总裁
结果显示: 以，、，的
Epoch 0 Step 002000, model loss 77.0612, LR: 0.0000100000
真实数据: 而父母俱杳。对此，此
结果显示: 面，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 67.6399, LR: 0.0000100000
真实数据: 相熟，请到蛇口的新时
结果显示: 但，一，的
Epoch 0 Step 002200, model loss 55.1125, LR: 0.0000100000
真实数据: 了他“游击专家”特有
结果显示: 了，”，的”
Epoch 0 Step 002300, model loss 61.6444, LR: 0.0000100000
真实数据: 想借“汉光”军演之机
结果显示: 我，一”
Epoch 0 Step 002400, model loss 69.5459, LR: 0.0000100000
真实数据: 三房二厅天堂和灵魂的
结果显示: 来一，一的
Epoch 0 Step 002500, model loss 67.6940, LR: 0.0000100000
真实数据: ;以此限制劳动合同短
结果显示: ，在的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 72.0592, LR: 0.0000100000
真实数据: 嫩多汁，主要负责人在
结果显示: 如，一，一
Epoch 0 Step 002700, model loss 80.1182, LR: 0.0000100000
真实数据: 够促进致癌物或者致癌
结果显示: 的是的是的
Epoch 0 Step 002800, model loss 60.0671, LR: 0.0000100000
真实数据: 的战略;比如飞了多长
结果显示: 的，。，的
Epoch 0 Step 002900, model loss 66.1464, LR: 0.0000100000
真实数据: 难以控制自已，径入山
结果显示: 年的，的
Epoch 0 Step 003000, model loss 96.1799, LR: 0.0000100000
真实数据: 夏威夷《檀香山广告报
结果显示: 是的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 55.9586, LR: 0.0000100000
真实数据: 、北师大、复旦、上海
结果显示: 、，、，
Epoch 0 Step 003200, model loss 79.3801, LR: 0.0000100000
真实数据: 斧头把房门劈开一个洞
结果显示: 是，的是的
Epoch 0 Step 003300, model loss 60.3323, LR: 0.0000100000
真实数据: 双方的体力都有一些下
结果显示: 对是的在的
Epoch 0 Step 003400, model loss 68.5061, LR: 0.0000100000
真实数据: 集资额将高达879亿
结果显示: 其的不的
Epoch 0 Step 003500, model loss 67.9341, LR: 0.0000100000
真实数据: 绝大多数SP公司而言
结果显示: 是的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 66.1527, LR: 0.0000100000
真实数据: 听就哭开了，稳定的婚
结果显示: “，”，的
Epoch 0 Step 003700, model loss 54.0525, LR: 0.0000100000
真实数据: 一种不断翻新的现代性
结果显示: 一个的不的
Epoch 0 Step 003800, model loss 73.2865, LR: 0.0000100000
真实数据: 务就是向舜天俱乐部提
结果显示: 要的是的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001DD4FB5E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 77.7408, LR: 0.0000100000
真实数据: 空战战术仅有一点模糊
结果显示: 如是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 68.8251, LR: 0.0000100000
真实数据: 能够在冲突环境下迅速
结果显示: 能的是的
Epoch 0 Step 000200, model loss 64.4323, LR: 0.0000100000
真实数据: 碳水化合物36.9克
结果显示: 可，1，1
Epoch 0 Step 000300, model loss 63.1518, LR: 0.0000100000
真实数据: 则是一场爱情密集强化
结果显示: 同是的一的
Epoch 0 Step 000400, model loss 63.3994, LR: 0.0000100000
真实数据: 张羽在公司是做销售的
结果显示: 但是的在的
Epoch 0 Step 000500, model loss 62.3530, LR: 0.0000100000
真实数据: -6将在今天19时直
结果显示: 一，的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 58.1200, LR: 0.0000100000
真实数据: 5在没有破坏的情况下
结果显示: 5的的
Epoch 0 Step 000700, model loss 57.2630, LR: 0.0000100000
真实数据: 友会问到一个问题，3
结果显示: 为，的，的
Epoch 0 Step 000800, model loss 43.0284, LR: 0.0000100000
真实数据: 02MenLeft"
结果显示: 000t
Epoch 0 Step 000900, model loss 58.2698, LR: 0.0000100000
真实数据: 多年前，署名“文妖”
结果显示: 今，一，
Epoch 0 Step 001000, model loss 52.2808, LR: 0.0000100000
真实数据: 他们来说，于是益思学
结果显示: 也，一，一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 63.8257, LR: 0.0000100000
真实数据: 往5个长度为400米
结果显示: 1，101
Epoch 0 Step 001200, model loss 65.3739, LR: 0.0000100000
真实数据: 根据自己的身体条件填
结果显示: 把的在的
Epoch 0 Step 001300, model loss 62.3545, LR: 0.0000100000
真实数据: 出50万元的经济赔偿
结果显示: 出的0的
Epoch 0 Step 001400, model loss 55.0004, LR: 0.0000100000
真实数据: 都说，反对0股，”“
结果显示: 我，1
Epoch 0 Step 001500, model loss 73.1477, LR: 0.0000100000
真实数据: 之后皮肤变得很滑很滑
结果显示: 是的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 61.9366, LR: 0.0000100000
真实数据: 如果继续进行如此旅游
结果显示: 如是的，的
Epoch 0 Step 001700, model loss 62.8088, LR: 0.0000100000
真实数据: 被动地接受变为主动要
结果显示: 校是的是的
Epoch 0 Step 001800, model loss 65.9876, LR: 0.0000100000
真实数据: 面好像总能看见些什么
结果显示: 的是的，的
Epoch 0 Step 001900, model loss 61.9765, LR: 0.0000100000
真实数据: 抗议道:因此，表达的
结果显示: 如，。，
Epoch 0 Step 002000, model loss 63.2616, LR: 0.0000100000
真实数据: 人曾提出:北京选手高
结果显示: 个，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 63.9127, LR: 0.0000100000
真实数据: 兰利医生称，但可以肯
结果显示: 是，的，的
Epoch 0 Step 002200, model loss 64.5548, LR: 0.0000100000
真实数据: 牛顿同为微积分的创建
结果显示: 生的在的
Epoch 0 Step 002300, model loss 78.0901, LR: 0.0000100000
真实数据: 萨饼:认真识别考官情
结果显示: 的，一，的
Epoch 0 Step 002400, model loss 55.2149, LR: 0.0000100000
真实数据: 为识时务者的生财之道
结果显示: 是的，的
Epoch 0 Step 002500, model loss 62.5815, LR: 0.0000100000
真实数据: 由是道人之名益著。根
结果显示: 的，了，0
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 55.1100, LR: 0.0000100000
真实数据: 。相似之处就是相同的
结果显示: 。这是的是的
Epoch 0 Step 002700, model loss 70.5663, LR: 0.0000100000
真实数据: 产品几乎涵盖了全部笔
结果显示: 两以的，的
Epoch 0 Step 002800, model loss 77.0114, LR: 0.0000100000
真实数据: 彼即不仁，智亦异焉。
结果显示: 每，的，一
Epoch 0 Step 002900, model loss 62.6747, LR: 0.0000100000
真实数据: 媒的，将会制定详细的
结果显示: 是，一，一
Epoch 0 Step 003000, model loss 62.9161, LR: 0.0000100000
真实数据: 问道:将会进一步脱落
结果显示: 的，一，一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 76.9717, LR: 0.0000100000
真实数据: 刚刚可以偶尔小资的女
结果显示: 的了的
Epoch 0 Step 003200, model loss 75.5598, LR: 0.0000100000
真实数据: 海南海事局党委书记林
结果显示: 得的和的
Epoch 0 Step 003300, model loss 68.1125, LR: 0.0000100000
真实数据: 会优先接到动员召集令
结果显示: 要，的，的
Epoch 0 Step 003400, model loss 60.7197, LR: 0.0000100000
真实数据: 人切实感受“道”的伟
结果显示: 人，的，的
Epoch 0 Step 003500, model loss 65.4067, LR: 0.0000100000
真实数据: 进了各项事业建设发展
结果显示: 要的，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 62.5933, LR: 0.0000100000
真实数据: 状态以6-3将总比分
结果显示: 中，的，的
Epoch 0 Step 003700, model loss 65.1360, LR: 0.0000100000
真实数据: 而不懂生活情趣的白痴
结果显示: 而在的不的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002B84142E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 60.8604, LR: 0.0000100000
真实数据: 销售23.89万公斤
结果显示: 觉010
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 54.8213, LR: 0.0000100000
真实数据: 到了“追逐”的队伍之
结果显示: 到，”“”
Epoch 0 Step 000200, model loss 54.3716, LR: 0.0000100000
真实数据: 。但是，双方很可能签
结果显示: 。“是，一
Epoch 0 Step 000300, model loss 66.8296, LR: 0.0000100000
真实数据: 得研究生做空姐比较可
结果显示: 在的不的
Epoch 0 Step 000400, model loss 63.6235, LR: 0.0000100000
真实数据: 另外两个产品则不是剧
结果显示: 是的，的，的
Epoch 0 Step 000500, model loss 77.2769, LR: 0.0000100000
真实数据: 表明严蕊一直系狱在本
结果显示: 多，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 75.9717, LR: 0.0000100000
真实数据: 攀岩、射击、大型载人
结果显示: 学，、，、
Epoch 0 Step 000700, model loss 61.2352, LR: 0.0000100000
真实数据: 期的连动关系，美军官
结果显示: 如一，一，一
Epoch 0 Step 000800, model loss 61.3723, LR: 0.0000100000
真实数据: 中的彼此处于男人主动
结果显示: 中国的，的
Epoch 0 Step 000900, model loss 61.3279, LR: 0.0000100000
真实数据: 实好了呆子，为上述地
结果显示: 我们，。，
Epoch 0 Step 001000, model loss 58.7248, LR: 0.0000100000
真实数据: 1号位出号，以至发改
结果显示: 1，、，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 65.5347, LR: 0.0000100000
真实数据: 同在一户口上直系亲属
结果显示: 中，1，一
Epoch 0 Step 001200, model loss 66.1046, LR: 0.0000100000
真实数据: 前景也未必很好。学费
结果显示: 是一的，的
Epoch 0 Step 001300, model loss 72.6602, LR: 0.0000100000
真实数据: 打手势，当时通扫净诸
结果显示: 如，一，一
Epoch 0 Step 001400, model loss 64.0820, LR: 0.0000100000
真实数据: 院治疗两年半。“非也
结果显示: 队了，一，一
Epoch 0 Step 001500, model loss 61.7522, LR: 0.0000100000
真实数据: 想的是啥?是“没考上
结果显示: 然的，的，一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 51.5423, LR: 0.0000100000
真实数据: 了，2、不必过于规律
结果显示: 于，、，、
Epoch 0 Step 001700, model loss 75.2191, LR: 0.0000100000
真实数据: 配合肉汤、菜汤长时间
结果显示: 的，的，的
Epoch 0 Step 001800, model loss 59.8943, LR: 0.0000100000
真实数据: 她说找到新的目标，女
结果显示: 想在的在的
Epoch 0 Step 001900, model loss 64.4045, LR: 0.0000100000
真实数据: 定它为猫科动物，独联
结果显示: 定一的一的
Epoch 0 Step 002000, model loss 43.9465, LR: 0.0000100000
真实数据: undoubtedl
结果显示: iini
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 56.2214, LR: 0.0000100000
真实数据: 本机构、本人所知情的
结果显示: 本，。，一
Epoch 0 Step 002200, model loss 53.7735, LR: 0.0000100000
真实数据: 只是服从于人民的工具
结果显示: 只是的是的
Epoch 0 Step 002300, model loss 75.9836, LR: 0.0000100000
真实数据: 一排排木柱组成极有节
结果显示: 一个是的是的
Epoch 0 Step 002400, model loss 74.6542, LR: 0.0000100000
真实数据: 精神在第77分钟的进
结果显示: 我是的有的
Epoch 0 Step 002500, model loss 73.2233, LR: 0.0000100000
真实数据: 的火山区拖到圣洛伦索
结果显示: 的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 76.9566, LR: 0.0000100000
真实数据: 右翼分子在靖国神社为
结果显示: 有的的
Epoch 0 Step 002700, model loss 73.3998, LR: 0.0000100000
真实数据: 挥在治疗、诊断肝病方
结果显示: 向了，。，的
Epoch 0 Step 002800, model loss 63.5052, LR: 0.0000100000
真实数据: 信时让接收方不直接回
结果显示: 们是的的
Epoch 0 Step 002900, model loss 84.9672, LR: 0.0000100000
真实数据: 研究生学历，蟒张吻怒
结果显示: 而是，的，的
Epoch 0 Step 003000, model loss 64.7496, LR: 0.0000100000
真实数据: 软面临一场高难度的战
结果显示: 将的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 66.9488, LR: 0.0000100000
真实数据: 青年日报》和“国防部
结果显示: 在，。，1
Epoch 0 Step 003200, model loss 76.9576, LR: 0.0000100000
真实数据: 阿森纳再次跃居联赛第
结果显示: 因不是的是的
Epoch 0 Step 003300, model loss 65.3944, LR: 0.0000100000
真实数据: 易专业(理科)、法学
结果显示: 如，人，的0
Epoch 0 Step 003400, model loss 57.2154, LR: 0.0000100000
真实数据: 但有一点我认为很重要
结果显示: 也一，一的
Epoch 0 Step 003500, model loss 56.4363, LR: 0.0000100000
真实数据: 己的意原表决。没有对
结果显示: 已是，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 73.8533, LR: 0.0000100000
真实数据: 、彭两人仍不肯回宋埠
结果显示: 、这的，的
Epoch 0 Step 003700, model loss 67.4162, LR: 0.0000100000
真实数据: 教我打一棍，几年下来
结果显示: 女，一，
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002516A86E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 80.9559, LR: 0.0000100000
真实数据: 他俩被湖南卫视邀请去
结果显示: 他是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 56.9476, LR: 0.0000100000
真实数据: 之间的这种“相关性”
结果显示: 小人的是的
Epoch 0 Step 000200, model loss 59.7693, LR: 0.0000100000
真实数据: 没有人们想像中那么严
结果显示: 的人的人的
Epoch 0 Step 000300, model loss 63.2435, LR: 0.0000100000
真实数据: 放弃有望“拿大奖”的
结果显示: 我，的，一
Epoch 0 Step 000400, model loss 78.1111, LR: 0.0000100000
真实数据: 食物为豆类、紫菜、燕
结果显示: 也，。，一
Epoch 0 Step 000500, model loss 65.8799, LR: 0.0000100000
真实数据: 正式打工前须先入境进
结果显示: 可是的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 75.3178, LR: 0.0000100000
真实数据: 予军事检察机关哪些职
结果显示: 于是的，的
Epoch 0 Step 000700, model loss 60.6271, LR: 0.0000100000
真实数据: 众人面前不肯承认你的
结果显示: 从的在的
Epoch 0 Step 000800, model loss 76.8692, LR: 0.0000100000
真实数据: 哈佛商学院mba生涯
结果显示: 中国的不的
Epoch 0 Step 000900, model loss 66.8598, LR: 0.0000100000
真实数据: 执行危险任务达127
结果显示: 长中的0的0
Epoch 0 Step 001000, model loss 46.1578, LR: 0.0000100000
真实数据: 国将在2018年之前
结果显示: 国1010
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 69.0611, LR: 0.0000100000
真实数据: 可以看到君君和她男友
结果显示: 可的是的
Epoch 0 Step 001200, model loss 70.2597, LR: 0.0000100000
真实数据: 让我卖2.5倍就卖不
结果显示: 上，的，的
Epoch 0 Step 001300, model loss 61.5053, LR: 0.0000100000
真实数据: 以为孝友之报云。自学
结果显示: 以的，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000181CC85E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 61.7187, LR: 0.0000100000
真实数据: 能接受比较充分的教育
结果显示: 的是的一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 79.9194, LR: 0.0000100000
真实数据: 但在这股奢侈风的劲吹
结果显示: 但的有的
Epoch 0 Step 000200, model loss 50.5823, LR: 0.0000100000
真实数据: 是国家社会的观点是不
结果显示: 是的，的
Epoch 0 Step 000300, model loss 67.5888, LR: 0.0000100000
真实数据: 二）非流通股股东持有
结果显示: 一是一的
Epoch 0 Step 000400, model loss 60.2075, LR: 0.0000100000
真实数据: 的身影便出现在训练场
结果显示: 的国的
Epoch 0 Step 000500, model loss 60.7871, LR: 0.0000100000
真实数据: 能保证充分地享有人权
结果显示: 的在的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 66.8951, LR: 0.0000100000
真实数据: 奖学金总额约80万元
结果显示: 公的0的
Epoch 0 Step 000700, model loss 75.8932, LR: 0.0000100000
真实数据: 柏林诺尔曼大街的东德
结果显示: 但的，的，的
Epoch 0 Step 000800, model loss 63.9720, LR: 0.0000100000
真实数据: 个相关网页.“妾姑去
结果显示: 个，一，一
Epoch 0 Step 000900, model loss 56.8016, LR: 0.0000100000
真实数据: 之自从得知自己的身世
结果显示: 大的一的
Epoch 0 Step 001000, model loss 68.6944, LR: 0.0000100000
真实数据: 意;微腺瘤可达60-
结果显示: 对的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 57.9401, LR: 0.0000100000
真实数据: 合格”，但是现在国内
结果显示: 有一，一，一
Epoch 0 Step 001200, model loss 70.4027, LR: 0.0000100000
真实数据: 加盟商要求返还保证金
结果显示: 然的是的
Epoch 0 Step 001300, model loss 58.8635, LR: 0.0000100000
真实数据: “路线斗争”实质上是
结果显示: “，”，”
Epoch 0 Step 001400, model loss 58.4142, LR: 0.0000100000
真实数据: 但对已患癌症的人来说
结果显示: 但是的有的
Epoch 0 Step 001500, model loss 74.8875, LR: 0.0000100000
真实数据: 昂、托马斯连续快攻得
结果显示: 即，、的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 74.3040, LR: 0.0000100000
真实数据: 族灭绝。水土流失严重
结果显示: 能，的，的
Epoch 0 Step 001700, model loss 72.2445, LR: 0.0000100000
真实数据: 和窃密事件实现零记录
结果显示: 在的在的
Epoch 0 Step 001800, model loss 69.3851, LR: 0.0000100000
真实数据: 论是哪个地区，”臾命
结果显示: 这，一，的
Epoch 0 Step 001900, model loss 73.0354, LR: 0.0000100000
真实数据: 由种种医疗腐败行为结
结果显示: 业的是的
Epoch 0 Step 002000, model loss 58.4113, LR: 0.0000100000
真实数据: 把美国的部队摆在那边
结果显示: 据的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 62.0167, LR: 0.0000100000
真实数据: 表面上看，从目前违约
结果显示: 本，一，的
Epoch 0 Step 002200, model loss 42.2433, LR: 0.0000100000
真实数据: 但2005年经营业绩
结果显示: 1200年
Epoch 0 Step 002300, model loss 68.1141, LR: 0.0000100000
真实数据: 一旦俄罗斯放弃安-7
结果显示: 一是的是的
Epoch 0 Step 002400, model loss 70.7828, LR: 0.0000100000
真实数据: 版光盘的售价则为8.
结果显示: 能的是的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E6E181E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 52.8740, LR: 0.0000100000
真实数据: :Aladin无人机
结果显示: :1e0e
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 61.5327, LR: 0.0000100000
真实数据: 民族的文学，齐天大圣
结果显示: 国，的，
Epoch 0 Step 000200, model loss 82.4961, LR: 0.0000100000
真实数据: 再过二年，亦捻块代珠
结果显示: 高，、，的
Epoch 0 Step 000300, model loss 71.1963, LR: 0.0000100000
真实数据: 安某被“昏庸”的清廷
结果显示: 一是”的”
Epoch 0 Step 000400, model loss 68.1534, LR: 0.0000100000
真实数据: 力保首飞任务圆满完成
结果显示: 之的有的
Epoch 0 Step 000500, model loss 51.7452, LR: 0.0000100000
真实数据: 但是他能有今天的状况
结果显示: 但的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 66.9682, LR: 0.0000100000
真实数据: 大家都管我叫“寒号鸟
结果显示: 大，的，的
Epoch 0 Step 000700, model loss 59.2270, LR: 0.0000100000
真实数据: 易的一生就压缩在这有
结果显示: 与，“”的
Epoch 0 Step 000800, model loss 60.1265, LR: 0.0000100000
真实数据: 党，“世界上所有动物
结果显示: 主，“”的
Epoch 0 Step 000900, model loss 61.4117, LR: 0.0000100000
真实数据: 新鲜的立诚的写实文学
结果显示: 我的，的，的
Epoch 0 Step 001000, model loss 80.6208, LR: 0.0000100000
真实数据: 大有效验，翠藓乱漫庭
结果显示: 大，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 65.7054, LR: 0.0000100000
真实数据: 他们很可能背叛公公司
结果显示: 们的不的
Epoch 0 Step 001200, model loss 52.7834, LR: 0.0000100000
真实数据: 要是因为它的教学成本
结果显示: 要，的，的
Epoch 0 Step 001300, model loss 64.0359, LR: 0.0000100000
真实数据: 要爬的每一座山，向她
结果显示: 要，的，的
Epoch 0 Step 001400, model loss 59.2088, LR: 0.0000100000
真实数据: ，静电“袭击”不可小
结果显示: ，“，一，”
Epoch 0 Step 001500, model loss 66.4753, LR: 0.0000100000
真实数据: 中国医药科技于伦敦另
结果显示: 中国的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 53.6013, LR: 0.0000100000
真实数据: 他们也不会过多地干涉
结果显示: 他是的，的
Epoch 0 Step 001700, model loss 68.2916, LR: 0.0000100000
真实数据: 西部歌王洛宾先生有点
结果显示: 面的在的
Epoch 0 Step 001800, model loss 56.4337, LR: 0.0000100000
真实数据: 2分钟，本是女人最美
结果显示: 4，、，
Epoch 0 Step 001900, model loss 60.0087, LR: 0.0000100000
真实数据: 行进速度10公里/小
结果显示: 在中2020
Epoch 0 Step 002000, model loss 84.7060, LR: 0.0000100000
真实数据: 狼衔鹿肉置其家以报之
结果显示: 外的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 72.8377, LR: 0.0000100000
真实数据: 文凭和简历也是诈骗犯
结果显示: 文，的，的
Epoch 0 Step 002200, model loss 65.4759, LR: 0.0000100000
真实数据: 回顾中超前十轮的九场
结果显示: 国的是的
Epoch 0 Step 002300, model loss 58.9675, LR: 0.0000100000
真实数据: 阳用一波12比4的攻
结果显示: 时，。，一的
Epoch 0 Step 002400, model loss 60.6640, LR: 0.0000100000
真实数据: 客观地说，因此本场比
结果显示: 为，一，的
Epoch 0 Step 002500, model loss 77.6097, LR: 0.0000100000
真实数据: 或咳嗽这样的行为有着
结果显示: 是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 76.1934, LR: 0.0000100000
真实数据: 怖行动联络和指示恐怖
结果显示: 他的在的
Epoch 0 Step 002700, model loss 74.7361, LR: 0.0000100000
真实数据: 娘生一男名小宦。存在
结果显示: 年，一，的
Epoch 0 Step 002800, model loss 59.9871, LR: 0.0000100000
真实数据: 工作、情绪、健康等的
结果显示: 下，一，、
Epoch 0 Step 002900, model loss 62.7759, LR: 0.0000100000
真实数据: 过了关于公司协议受让
结果显示: 比的，的
Epoch 0 Step 003000, model loss 58.8933, LR: 0.0000100000
真实数据: 只取其中最高一项分值
结果显示: 只一的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 85.3612, LR: 0.0000100000
真实数据: 在潍北靶场临时搭建的
结果显示: 我的和的
Epoch 0 Step 003200, model loss 73.0484, LR: 0.0000100000
真实数据: 卫生防疫站健康证明后
结果显示: 对的是的
Epoch 0 Step 003300, model loss 68.4032, LR: 0.0000100000
真实数据: 将被给予开除学籍处分
结果显示: 新不的不的
Epoch 0 Step 003400, model loss 57.6371, LR: 0.0000100000
真实数据: 门主管证明你的能力后
结果显示: 门的的
Epoch 0 Step 003500, model loss 58.0547, LR: 0.0000100000
真实数据: 应该达到80%这么一
结果显示: 月不1010
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 62.8994, LR: 0.0000100000
真实数据: 哪些成人高校进行招生
结果显示: 明的是的
Epoch 0 Step 003700, model loss 66.6790, LR: 0.0000100000
真实数据: 上涨和回调富有节奏感
结果显示: 上的的
Epoch 0 Step 003800, model loss 49.7047, LR: 0.0000100000
真实数据: 实际上是我们推出的。
结果显示: 实的在的
Epoch 0 Step 003900, model loss 65.6505, LR: 0.0000100000
真实数据: 在顺利结束这一阶段后
结果显示: 我的，的，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001A39382D4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 71.5904, LR: 0.0000100000
真实数据: 往往压得极低，崔真人
结果显示: 得的，的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 75.2968, LR: 0.0000100000
真实数据: 踏实实去做事是唯一的
结果显示: 能是的是的
Epoch 0 Step 000200, model loss 55.4260, LR: 0.0000100000
真实数据: 是一个超级优秀的女生
结果显示: 是的是的
Epoch 0 Step 000300, model loss 74.0033, LR: 0.0000100000
真实数据: 外，而且左翼第33集
结果显示: 为，的，的
Epoch 0 Step 000400, model loss 61.3211, LR: 0.0000100000
真实数据: ，河南电视台举办的一
结果显示: ，我的在的
Epoch 0 Step 000500, model loss 63.9221, LR: 0.0000100000
真实数据: 重、情节之恶劣、教训
结果显示: 实，、的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 69.2101, LR: 0.0000100000
真实数据: 韩每日商业报道》引用
结果显示: 新的不的
Epoch 0 Step 000700, model loss 64.4152, LR: 0.0000100000
真实数据: 老爷活命之恩，根据一
结果显示: 者，、，的
Epoch 0 Step 000800, model loss 59.0843, LR: 0.0000100000
真实数据: 做一些作业，以史无前
结果显示: 他，一，的
Epoch 0 Step 000900, model loss 67.5402, LR: 0.0000100000
真实数据: 家长可以将药片等比例
结果显示: 还的不的
Epoch 0 Step 001000, model loss 71.2011, LR: 0.0000100000
真实数据: !快乐的含义无须多说
结果显示: 曰的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 66.8679, LR: 0.0000100000
真实数据: 气，哪些是时尚新势力
结果显示: ”不的是的
Epoch 0 Step 001200, model loss 55.2899, LR: 0.0000100000
真实数据: 意是需要本钱的。度2
结果显示: 高，的，的
Epoch 0 Step 001300, model loss 61.9434, LR: 0.0000100000
真实数据: 期到达这里的彭总会面
结果显示: 们的在的
Epoch 0 Step 001400, model loss 69.8721, LR: 0.0000100000
真实数据: 的爱却充满了敌意、鄙
结果显示: 的是的是的
Epoch 0 Step 001500, model loss 63.8578, LR: 0.0000100000
真实数据: “不容他人匡正”的专
结果显示: “我，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 59.7167, LR: 0.0000100000
真实数据: 总之，开车送女儿去上
结果显示: 就，、，、
Epoch 0 Step 001700, model loss 52.8096, LR: 0.0000100000
真实数据: 年同期增加19.1%
结果显示: 个年，120
Epoch 0 Step 001800, model loss 55.4748, LR: 0.0000100000
真实数据: 那么，1990年夏天
结果显示: 年1，10
Epoch 0 Step 001900, model loss 45.6228, LR: 0.0000100000
真实数据: 有3000名高考生被
结果显示: 有200年，
Epoch 0 Step 002000, model loss 65.1597, LR: 0.0000100000
真实数据: F97式93毫米单兵
结果显示: 19010
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 80.6844, LR: 0.0000100000
真实数据: 本报记者孙燕飚发自广
结果显示: 公在的，的
Epoch 0 Step 002200, model loss 64.5398, LR: 0.0000100000
真实数据: 企业通过“注入优质资
结果显示: 是的是的
Epoch 0 Step 002300, model loss 63.4361, LR: 0.0000100000
真实数据: 和描写中总有一些议论
结果显示: 我是，的一
Epoch 0 Step 002400, model loss 55.4561, LR: 0.0000100000
真实数据: 在的学生制式装基本相
结果显示: 在的是的
Epoch 0 Step 002500, model loss 62.6754, LR: 0.0000100000
真实数据: 说，赵林:完全不看书
结果显示: 这，、，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 74.5177, LR: 0.0000100000
真实数据: 桑托索压后。除去4月
结果显示: 我不的，的
Epoch 0 Step 002700, model loss 73.8183, LR: 0.0000100000
真实数据: 黄蜂"战斗机进行改进
结果显示: 在的是的
Epoch 0 Step 002800, model loss 56.8330, LR: 0.0000100000
真实数据: 如果没有大学生电影节
结果显示: 是的是的
Epoch 0 Step 002900, model loss 67.3634, LR: 0.0000100000
真实数据: 了一位耳鼻喉科的主任
结果显示: 一，是的
Epoch 0 Step 003000, model loss 63.7662, LR: 0.0000100000
真实数据: 见陌生的人们。凭主场
结果显示: 们的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 74.8620, LR: 0.0000100000
真实数据: 眼看着就要退过沅江了
结果显示: 要的，的，的
Epoch 0 Step 003200, model loss 60.1793, LR: 0.0000100000
真实数据: ，这是个医保定点医院
结果显示: 山人的不的
Epoch 0 Step 003300, model loss 63.6954, LR: 0.0000100000
真实数据: 通过互联网上传电子信
结果显示: 道的是的
Epoch 0 Step 003400, model loss 69.8381, LR: 0.0000100000
真实数据: 蒙两个骤然间增至18
结果显示: 要的，的
Epoch 0 Step 003500, model loss 67.0414, LR: 0.0000100000
真实数据: 死?吴金贵自然不会就
结果显示: 至是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 66.7969, LR: 0.0000100000
真实数据: 国际先驱导报特约记者
结果显示: 国的不的
Epoch 0 Step 003700, model loss 72.3385, LR: 0.0000100000
真实数据: 资而言,比利亚雷尔领
结果显示: 要一的，的
Epoch 0 Step 003800, model loss 50.9059, LR: 0.0000100000
真实数据: 在79家上市公司的2
结果显示: 在200
Epoch 0 Step 003900, model loss 65.5537, LR: 0.0000100000
真实数据: 养支持的作用却认识得
结果显示: 我的国的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E5126234C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 66.1749, LR: 0.0000100000
真实数据: 0战胜浙江队后，与共
结果显示: 时的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 69.5235, LR: 0.0000100000
真实数据: 背朝上，第11军在陆
结果显示: 有，一，
Epoch 0 Step 000200, model loss 66.6432, LR: 0.0000100000
真实数据: 美貌加身材出色、服务
结果显示: 并不，的，一
Epoch 0 Step 000300, model loss 78.5036, LR: 0.0000100000
真实数据: 飞豹战机紧贴海面掠海
结果显示: 军能的是的
Epoch 0 Step 000400, model loss 60.3588, LR: 0.0000100000
真实数据: 的还建成特殊的过街楼
结果显示: 的是的
Epoch 0 Step 000500, model loss 80.6006, LR: 0.0000100000
真实数据: 与女弈。全部赃款已被
结果显示: 与，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 73.4057, LR: 0.0000100000
真实数据: 悲观厌世是自杀原因之
结果显示: 我的，的，的
Epoch 0 Step 000700, model loss 65.2872, LR: 0.0000100000
真实数据: 据联想集团内部统计，
结果显示: 新们的在的
Epoch 0 Step 000800, model loss 62.2052, LR: 0.0000100000
真实数据: 相反，“那便是徐志摩
结果显示: 据，“，一
Epoch 0 Step 000900, model loss 61.2715, LR: 0.0000100000
真实数据: 进程。别人会主观地认
结果显示: 资，。，
Epoch 0 Step 001000, model loss 66.7708, LR: 0.0000100000
真实数据: 女书作品几乎都是诗歌
结果显示: 女的有的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 81.5568, LR: 0.0000100000
真实数据: ，还象前番雄纠纠、气
结果显示: ，不的，的
Epoch 0 Step 001200, model loss 72.6337, LR: 0.0000100000
真实数据: 乏主动肯定不会被领导
结果显示: 无是的是的
Epoch 0 Step 001300, model loss 57.0718, LR: 0.0000100000
真实数据: 同时，这远比技能重要
结果显示: 两一的是的
Epoch 0 Step 001400, model loss 73.2840, LR: 0.0000100000
真实数据: “Pizza总是难吃
结果显示: “2020
Epoch 0 Step 001500, model loss 45.6154, LR: 0.0000100000
真实数据: 北京2008年奥运会
结果显示: 2020年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 42.0128, LR: 0.0000100000
真实数据: minutes.”生
结果显示: nitnt
Epoch 0 Step 001700, model loss 70.5729, LR: 0.0000100000
真实数据: 浮云，而百代公司与华
结果显示: 管:，。，的
Epoch 0 Step 001800, model loss 65.3962, LR: 0.0000100000
真实数据: 本增值基金取得了绝对
结果显示: 会，的，的
Epoch 0 Step 001900, model loss 62.2107, LR: 0.0000100000
真实数据: 于相貌、气质、年龄就
结果显示: 于，一，
Epoch 0 Step 002000, model loss 61.1804, LR: 0.0000100000
真实数据: 是以社会交易理论为基
结果显示: 对是的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 64.1134, LR: 0.0000100000
真实数据: 两害相权，截止到去年
结果显示: 而，的，的
Epoch 0 Step 002200, model loss 70.1025, LR: 0.0000100000
真实数据: 与燕郊一河之隔的通州
结果显示: 去要的，的
Epoch 0 Step 002300, model loss 50.4634, LR: 0.0000100000
真实数据: 了全国各地人士的网上
结果显示: 了一的，的
Epoch 0 Step 002400, model loss 62.7177, LR: 0.0000100000
真实数据: 高速公路A6号这种情
结果显示: 高的在的
Epoch 0 Step 002500, model loss 70.8856, LR: 0.0000100000
真实数据: 我酒友也。忽促装言别
结果显示: 心，。，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 64.1778, LR: 0.0000100000
真实数据: 单为显示器的整体带来
结果显示: 市的国的
Epoch 0 Step 002700, model loss 59.8335, LR: 0.0000100000
真实数据: 要维护执业资格考试的
结果显示: 是的是的
Epoch 0 Step 002800, model loss 66.8166, LR: 0.0000100000
真实数据: 调小冯不会出现太大困
结果显示: 说的，的
Epoch 0 Step 002900, model loss 75.3573, LR: 0.0000100000
真实数据: 、卢长春、胡俊辉、邹
结果显示: 、一、，、
Epoch 0 Step 003000, model loss 70.0188, LR: 0.0000100000
真实数据: 加德满都资料图:石喜
结果显示: 我是的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 53.7657, LR: 0.0000100000
真实数据: 有这个精神，2.时间
结果显示: 在，1，
Epoch 0 Step 003200, model loss 80.7075, LR: 0.0000100000
真实数据: 哮喘等变态反应性疾病
结果显示: 学国的是的
Epoch 0 Step 003300, model loss 51.6708, LR: 0.0000100000
真实数据: 队追成43-60。[
结果显示: ie010
Epoch 0 Step 003400, model loss 63.5370, LR: 0.0000100000
真实数据: 心东移又扮演新的“战
结果显示: “是的，的
Epoch 0 Step 003500, model loss 64.1127, LR: 0.0000100000
真实数据: 白先勇最终成了文学大
结果显示: 的，是，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 78.5661, LR: 0.0000100000
真实数据: 好八戒，薛诘之益苦，
结果显示: 后，、，
Epoch 0 Step 003700, model loss 67.5203, LR: 0.0000100000
真实数据: 择某些器物而不是另外
结果显示: 但的是的
Epoch 0 Step 003800, model loss 67.8324, LR: 0.0000100000
真实数据: 薪水高得吓人”之类种
结果显示: 我的，的，的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001D468CAE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 63.6463, LR: 0.0000100000
真实数据: 光芒。”身体是第一位
结果显示: 为，“，“一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 64.3591, LR: 0.0000100000
真实数据: ，迎客的不是手捧花环
结果显示: ，但是的的
Epoch 0 Step 000200, model loss 69.9534, LR: 0.0000100000
真实数据: 、精神抚慰金等29万
结果显示: ，而2的的
Epoch 0 Step 000300, model loss 71.5572, LR: 0.0000100000
真实数据: ，又让宴请宾客上档次
结果显示: :有的不的
Epoch 0 Step 000400, model loss 65.7133, LR: 0.0000100000
真实数据: 圣道:“姐妹们，公司
结果显示: 至，一，一
Epoch 0 Step 000500, model loss 59.6498, LR: 0.0000100000
真实数据: 一，通过产业链联盟的
结果显示: 一是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 55.2394, LR: 0.0000100000
真实数据: 06年足球世界杯的序
结果显示: 06年的是的
Epoch 0 Step 000700, model loss 63.6566, LR: 0.0000100000
真实数据: ，慕永国:冷不丁地跳
结果显示: ，一，的，的
Epoch 0 Step 000800, model loss 67.4129, LR: 0.0000100000
真实数据: 靠的知名品牌更让人放
结果显示: 果的个的
Epoch 0 Step 000900, model loss 63.0846, LR: 0.0000100000
真实数据: 过了总部组织的技术鉴
结果显示: 过有的，的
Epoch 0 Step 001000, model loss 59.4085, LR: 0.0000100000
真实数据: 父，可是财务部不同意
结果显示: 其，、的的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 60.1585, LR: 0.0000100000
真实数据: 命:就可以申请12个
结果显示: 可，的，的0
Epoch 0 Step 001200, model loss 65.9756, LR: 0.0000100000
真实数据: 素材有效用到立意不同
结果显示: 我们的，的
Epoch 0 Step 001300, model loss 52.5626, LR: 0.0000100000
真实数据: 2月27日电据俄罗斯
结果显示: 212
Epoch 0 Step 001400, model loss 50.9724, LR: 0.0000100000
真实数据: 现在中小学的重点学校
结果显示: 所的在的
Epoch 0 Step 001500, model loss 62.6032, LR: 0.0000100000
真实数据: 济本质上就必然是这样
结果显示: 实在的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 66.4900, LR: 0.0000100000
真实数据: 销不但会影响到中国丝
结果显示: 都的有的
Epoch 0 Step 001700, model loss 64.3683, LR: 0.0000100000
真实数据: 位到当时被誉为亚洲最
结果显示: 也是的一的
Epoch 0 Step 001800, model loss 68.0138, LR: 0.0000100000
真实数据: 声震山河，并寝。则曰
结果显示: 产，。，
Epoch 0 Step 001900, model loss 64.7351, LR: 0.0000100000
真实数据: 侧面说明他的执行能力
结果显示: 外的和的
Epoch 0 Step 002000, model loss 62.8705, LR: 0.0000100000
真实数据: 防守出色的他一直都是
结果显示: 队有的一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 73.2434, LR: 0.0000100000
真实数据: 既能牢固记忆，容通报
结果显示: 明，一，的一
Epoch 0 Step 002200, model loss 65.6097, LR: 0.0000100000
真实数据: ，哪有时间谈恋爱?阿
结果显示: ，而国的
Epoch 0 Step 002300, model loss 65.4545, LR: 0.0000100000
真实数据: 旅游能够走出价格战误
结果显示: 的是的
Epoch 0 Step 002400, model loss 74.9982, LR: 0.0000100000
真实数据: 尾巴，但是要增加锻炼
结果显示: 是，一，一的
Epoch 0 Step 002500, model loss 64.4974, LR: 0.0000100000
真实数据: 支持服务和最新的零配
结果显示: 本的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 64.7911, LR: 0.0000100000
真实数据: 每个嘉宾从自己企业的
结果显示: 教，的，的
Epoch 0 Step 002700, model loss 68.5298, LR: 0.0000100000
真实数据: 税法在游程的后半时段
结果显示: 和的是的
Epoch 0 Step 002800, model loss 65.9771, LR: 0.0000100000
真实数据: 的纪录足以弥补“老大
结果显示: 的，的，的
Epoch 0 Step 002900, model loss 62.9864, LR: 0.0000100000
真实数据: ，会面后富豪们均表示
结果显示: ，我的不的
Epoch 0 Step 003000, model loss 63.2913, LR: 0.0000100000
真实数据: 正在对几起互联网传销
结果显示: 且的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 60.5150, LR: 0.0000100000
真实数据: 要切实保障用户的合法
结果显示: 现的是的
Epoch 0 Step 003200, model loss 77.2323, LR: 0.0000100000
真实数据: 巴黎:阿雅克甚至顶风
结果显示: 日公的的
Epoch 0 Step 003300, model loss 55.5066, LR: 0.0000100000
真实数据: 对我们教育工作者来说
结果显示: 对的，的
Epoch 0 Step 003400, model loss 81.2739, LR: 0.0000100000
真实数据: 公里，水兵宿舍低矮狭
结果显示: 其是的是的
Epoch 0 Step 003500, model loss 69.3367, LR: 0.0000100000
真实数据: 听间，他趁宋美龄说时
结果显示: 宁，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 52.2781, LR: 0.0000100000
真实数据: 月基本费10元含50
结果显示: 月，10
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000027A72EFE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 58.3377, LR: 0.0000100000
真实数据: 分学校本地生源占大多
结果显示: 会的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 70.9512, LR: 0.0000100000
真实数据: 安东北地区三仓河一带
结果显示: 为，的，的
Epoch 0 Step 000200, model loss 67.2500, LR: 0.0000100000
真实数据: 石油有限公司RMB1
结果显示: 7320
Epoch 0 Step 000300, model loss 62.7842, LR: 0.0000100000
真实数据: 工作的华裔科学家李文
结果显示: 工作的，的
Epoch 0 Step 000400, model loss 79.1180, LR: 0.0000100000
真实数据: 购权证到万华认沽权证
结果显示: 地的是的
Epoch 0 Step 000500, model loss 63.0894, LR: 0.0000100000
真实数据: 一些品牌茶馆，再有平
结果显示: 一个的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 80.3061, LR: 0.0000100000
真实数据: 宗旨已被利欲践踏得“
结果显示: 家的是的
Epoch 0 Step 000700, model loss 62.3935, LR: 0.0000100000
真实数据: 有很多野鸭子，这样增
结果显示: 有，的，的
Epoch 0 Step 000800, model loss 57.0955, LR: 0.0000100000
真实数据: 做好100%安全套推
结果显示: 们200年的
Epoch 0 Step 000900, model loss 59.4126, LR: 0.0000100000
真实数据: 一套阵容肯定是不行的
结果显示: ―的是的
Epoch 0 Step 001000, model loss 65.2490, LR: 0.0000100000
真实数据: 军是来市区集中缴械投
结果显示: 不是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 60.5094, LR: 0.0000100000
真实数据: 供的材料要经过学生所
结果显示: 也是的是的
Epoch 0 Step 001200, model loss 65.3154, LR: 0.0000100000
真实数据: 花枕底，而距此不远的
结果显示: 在的，的
Epoch 0 Step 001300, model loss 55.2396, LR: 0.0000100000
真实数据: 的军人是很难证实自己
结果显示: 的是的是的
Epoch 0 Step 001400, model loss 68.7864, LR: 0.0000100000
真实数据: 意林丹的比赛，心骤喜
结果显示: 就是，的，的
Epoch 0 Step 001500, model loss 64.0863, LR: 0.0000100000
真实数据: 友只分两种，同事结婚
结果显示: 为，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 61.1987, LR: 0.0000100000
真实数据: 你就放心好了!”买些
结果显示: 但，一，一
Epoch 0 Step 001700, model loss 70.3092, LR: 0.0000100000
真实数据: 习型:不支持台湾‘独
结果显示: 三，一，一
Epoch 0 Step 001800, model loss 86.5739, LR: 0.0000100000
真实数据: 有下坠痛及阴道灼热感
结果显示: 我们的，的
Epoch 0 Step 001900, model loss 58.4724, LR: 0.0000100000
真实数据: 文化对个人发展极为重
结果显示: 又中的的
Epoch 0 Step 002000, model loss 82.0163, LR: 0.0000100000
真实数据: 剁锤敲难损命，幸得他
结果显示: 和的和的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 56.3014, LR: 0.0000100000
真实数据: ，把我们推进了水深火
结果显示: ，我的在的
Epoch 0 Step 002200, model loss 61.5990, LR: 0.0000100000
真实数据: 经济回落的预期已得到
结果显示: 他的
Epoch 0 Step 002300, model loss 61.6209, LR: 0.0000100000
真实数据: 业还是像西方跨国公司
结果显示: 也的在的
Epoch 0 Step 002400, model loss 56.7480, LR: 0.0000100000
真实数据: 是要利用自然的素材创
结果显示: 是的在的
Epoch 0 Step 002500, model loss 95.9395, LR: 0.0000100000
真实数据: 切莫要口里摆竟拨蒿蓬
结果显示: 是有的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 73.6009, LR: 0.0000100000
真实数据: 平衡膳食是饮食防癌的
结果显示: 可的在的
Epoch 0 Step 002700, model loss 61.9737, LR: 0.0000100000
真实数据: 离开时大都是哪里来哪
结果显示: 再的中的
Epoch 0 Step 002800, model loss 64.8773, LR: 0.0000100000
真实数据: 完全理解通原文并借此
结果显示: 安的是的
Epoch 0 Step 002900, model loss 69.9036, LR: 0.0000100000
真实数据: 遥，运动完还要吃早饭
结果显示: 这，是的
Epoch 0 Step 003000, model loss 73.2171, LR: 0.0000100000
真实数据: 来,10.无规律涂抹
结果显示: 元的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 61.4553, LR: 0.0000100000
真实数据: 验总是应付不了新问题
结果显示: 就的在的
Epoch 0 Step 003200, model loss 73.9304, LR: 0.0000100000
真实数据: 孙继海自红牌禁赛4场
结果显示: 再们的的
Epoch 0 Step 003300, model loss 57.9865, LR: 0.0000100000
真实数据: 对改革方案进行调整的
结果显示: 对的有的
Epoch 0 Step 003400, model loss 60.0425, LR: 0.0000100000
真实数据: 的赌城，仁、义度不能
结果显示: 的，、，、
Epoch 0 Step 003500, model loss 53.9430, LR: 0.0000100000
真实数据: 并且有自由自在的性情
结果显示: 知中的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 64.3824, LR: 0.0000100000
真实数据: 觉得艳遇是件挺美好的
结果显示: 觉的是的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000016FD835E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 51.3778, LR: 0.0000100000
真实数据: 是什么含义?2005
结果显示: 是1210
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 61.2034, LR: 0.0000100000
真实数据: 以靠“知识经济”养活
结果显示: 以”一”的”
Epoch 0 Step 000200, model loss 64.3281, LR: 0.0000100000
真实数据: 2按照沙巴尔金少将的
结果显示: 2的在的
Epoch 0 Step 000300, model loss 68.5727, LR: 0.0000100000
真实数据: 立事件不必那么义愤填
结果显示: 立的在的
Epoch 0 Step 000400, model loss 62.1442, LR: 0.0000100000
真实数据: nX='+xc;st
结果显示: 1.10
Epoch 0 Step 000500, model loss 66.9223, LR: 0.0000100000
真实数据: 花在逛街购物打扮的时
结果显示: 在的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 58.1871, LR: 0.0000100000
真实数据: 这是促进大脑充分发展
结果显示: 这是的是的
Epoch 0 Step 000700, model loss 60.3644, LR: 0.0000100000
真实数据: 管理有限公司第二只基
结果显示: 《是，的一的
Epoch 0 Step 000800, model loss 61.6895, LR: 0.0000100000
真实数据: 试前要有各种心理准备
结果显示: 该是的是的
Epoch 0 Step 000900, model loss 61.7390, LR: 0.0000100000
真实数据: 以老子的辩证法是消极
结果显示: 以为的不的
Epoch 0 Step 001000, model loss 60.2472, LR: 0.0000100000
真实数据: 起工作来有些底气不足
结果显示: 是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 71.6290, LR: 0.0000100000
真实数据: 走运动员和轮椅运动员
结果显示: 多的
Epoch 0 Step 001200, model loss 68.5128, LR: 0.0000100000
真实数据: 悲剧文明面对两个世界
结果显示: 活的，的
Epoch 0 Step 001300, model loss 65.5706, LR: 0.0000100000
真实数据: 他个人“黄婆卖瓜式”
结果显示: 们，一，”
Epoch 0 Step 001400, model loss 64.3669, LR: 0.0000100000
真实数据: 《美好年华》后来炒作
结果显示: 《是的是的
Epoch 0 Step 001500, model loss 41.0999, LR: 0.0000100000
真实数据: ndowsVista
结果显示: hoorae
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 73.1248, LR: 0.0000100000
真实数据: 不妨。“Ⅱ类盲降”仍
结果显示: 不，。，、
Epoch 0 Step 001700, model loss 64.5606, LR: 0.0000100000
真实数据: 有助于理解物理概念和
结果显示: 在们的，的
Epoch 0 Step 001800, model loss 65.6950, LR: 0.0000100000
真实数据: 道母子俩用生命等来的
结果显示: 要是的是的
Epoch 0 Step 001900, model loss 52.4258, LR: 0.0000100000
真实数据: 目部的人中，广西南方
结果显示: 国，的，一
Epoch 0 Step 002000, model loss 77.3142, LR: 0.0000100000
真实数据: 的高薪，>>从打工妹
结果显示: 的，。，一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 42.8902, LR: 0.0000100000
真实数据: 1999年到2005
结果显示: 0000
Epoch 0 Step 002200, model loss 34.6193, LR: 0.0000100000
真实数据: 2003年3月，也就
结果显示: 25年
Epoch 0 Step 002300, model loss 57.7378, LR: 0.0000100000
真实数据: 对于热爱生活的人来讲
结果显示: 对是的了的
Epoch 0 Step 002400, model loss 61.8703, LR: 0.0000100000
真实数据: 最好办法就是努力工作
结果显示: 并是的是的
Epoch 0 Step 002500, model loss 66.7020, LR: 0.0000100000
真实数据: 造业必须发展成完整产
结果显示: 别是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 58.7838, LR: 0.0000100000
真实数据: 将今年数码相机部门的
结果显示: 有的是的
Epoch 0 Step 002700, model loss 62.6947, LR: 0.0000100000
真实数据: 异性的关系虚心说法2
结果显示: 并中的是的
Epoch 0 Step 002800, model loss 69.1562, LR: 0.0000100000
真实数据: 一日，枭龙04首飞待
结果显示: :，10
Epoch 0 Step 002900, model loss 57.4784, LR: 0.0000100000
真实数据: 共找到869这一段时
结果显示: 并国的10
Epoch 0 Step 003000, model loss 69.5735, LR: 0.0000100000
真实数据: 险重任务中不断坚定官
结果显示: 由家的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 73.8956, LR: 0.0000100000
真实数据: 兄欲辞人世矣。价格较
结果显示: 是，的，的
Epoch 0 Step 003200, model loss 61.4652, LR: 0.0000100000
真实数据: 句中有动作的施动者时
结果显示: 你的的
Epoch 0 Step 003300, model loss 63.8636, LR: 0.0000100000
真实数据: 录取的考生（已被高校
结果显示: 要的是的
Epoch 0 Step 003400, model loss 53.1329, LR: 0.0000100000
真实数据: 大学是国家教育部直属
结果显示: 大的是的
Epoch 0 Step 003500, model loss 69.8443, LR: 0.0000100000
真实数据: 为“试验970”千龙
结果显示: 为1010
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 68.2232, LR: 0.0000100000
真实数据: 未睡哩，酒席上的干杯
结果显示: 主。，。，
Epoch 0 Step 003700, model loss 65.6262, LR: 0.0000100000
真实数据: 缠足,因此，共找到4
结果显示: 们，。，0
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001A1CEE024C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 48.1906, LR: 0.0000100000
真实数据: 18日，在主子的眼中
结果显示: 15，。的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 61.8317, LR: 0.0000100000
真实数据: 还有血糖增加后，一旦
结果显示: ”是，的
Epoch 0 Step 000200, model loss 72.5363, LR: 0.0000100000
真实数据: 电股份(行情,忽驾彩
结果显示: 日的1的
Epoch 0 Step 000300, model loss 63.1436, LR: 0.0000100000
真实数据: 的发言从头到尾充满了
结果显示: 的是的，的
Epoch 0 Step 000400, model loss 64.3698, LR: 0.0000100000
真实数据: 味着，按照上海市目前
结果显示: 这，一，的
Epoch 0 Step 000500, model loss 50.7027, LR: 0.0000100000
真实数据: ，就成了一个必然的问
结果显示: ，”是、，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 22.7911, LR: 0.0000100000
真实数据: [3][4][5][
结果显示: [][][]
Epoch 0 Step 000700, model loss 65.1397, LR: 0.0000100000
真实数据: 性格，面对网上支付公
结果显示: 就国的，的
Epoch 0 Step 000800, model loss 70.3668, LR: 0.0000100000
真实数据: 后的A股产生了饥渴性
结果显示: 成的，的
Epoch 0 Step 000900, model loss 88.8419, LR: 0.0000100000
真实数据: 洗澡会使血液循环旺盛
结果显示: 活的和的
Epoch 0 Step 001000, model loss 64.4410, LR: 0.0000100000
真实数据: ”妇尚流连。尽管营业
结果显示: ”，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 53.5375, LR: 0.0000100000
真实数据: 首先，我要说的是，其
结果显示: 然，、，的
Epoch 0 Step 001200, model loss 84.8121, LR: 0.0000100000
真实数据: 卖点心、小吃、油盐酱
结果显示: 多，。，
Epoch 0 Step 001300, model loss 58.4424, LR: 0.0000100000
真实数据: 我知道他也没有什么错
结果显示: 我们的是的
Epoch 0 Step 001400, model loss 59.7408, LR: 0.0000100000
真实数据: 到达:公共汽车:89
结果显示: 现了，10
Epoch 0 Step 001500, model loss 96.9421, LR: 0.0000100000
真实数据: 橘皮核心成分眩晕头痛
结果显示: 长的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 66.5800, LR: 0.0000100000
真实数据: 个身着土花布衣的村姑
结果显示: 个的的
Epoch 0 Step 001700, model loss 69.4489, LR: 0.0000100000
真实数据: 仙门下出的散仙，相关
结果显示: 们上，的
Epoch 0 Step 001800, model loss 62.8464, LR: 0.0000100000
真实数据: 子吓了一跌，一扇息火
结果显示: 于，一，一
Epoch 0 Step 001900, model loss 62.5035, LR: 0.0000100000
真实数据: 科学与技术专业为55
结果显示: 和的是的
Epoch 0 Step 002000, model loss 77.2185, LR: 0.0000100000
真实数据: 要:本报讯(记者辛苑
结果显示: 见，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 69.6628, LR: 0.0000100000
真实数据: 高明的文字素养，杰弗
结果显示: 给的，的，的
Epoch 0 Step 002200, model loss 64.0702, LR: 0.0000100000
真实数据: 理注册登记的有限责任
结果显示: 理的和的
Epoch 0 Step 002300, model loss 60.0417, LR: 0.0000100000
真实数据: 对战争结果的影响力微
结果显示: 对的是的
Epoch 0 Step 002400, model loss 63.8975, LR: 0.0000100000
真实数据: 急逐之，表决意见对应
结果显示: 动，一，一
Epoch 0 Step 002500, model loss 63.7807, LR: 0.0000100000
真实数据: 但小白领呢?网上热传
结果显示: 但在的人的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 56.7899, LR: 0.0000100000
真实数据: 我觉得当时参加的比赛
结果显示: 我们的是的
Epoch 0 Step 002700, model loss 55.6724, LR: 0.0000100000
真实数据: 现有意与你们做到资源
结果显示: 现在的
Epoch 0 Step 002800, model loss 70.0863, LR: 0.0000100000
真实数据: 省纪委书记刘名榜是信
结果显示: 将的在的
Epoch 0 Step 002900, model loss 62.9012, LR: 0.0000100000
真实数据: ，落实反竞争调查的难
结果显示: ，为的不的
Epoch 0 Step 003000, model loss 62.9415, LR: 0.0000100000
真实数据: 者:产生的细丝很容易
结果显示: 老学一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 65.1503, LR: 0.0000100000
真实数据: 潜告夫人:注意生活细
结果显示: 没，。，一
Epoch 0 Step 003200, model loss 64.0966, LR: 0.0000100000
真实数据: 4%、翻译和设计各9
结果显示: 我、，、的
Epoch 0 Step 003300, model loss 61.9714, LR: 0.0000100000
真实数据: 需要几个方面的努力。
结果显示: 而的，的
Epoch 0 Step 003400, model loss 59.8583, LR: 0.0000100000
真实数据: 于上世纪70年代末开
结果显示: 子的0
Epoch 0 Step 003500, model loss 66.2662, LR: 0.0000100000
真实数据: 男儿有泪不轻弹，后市
结果显示: 军人的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 71.9634, LR: 0.0000100000
真实数据: 它始建于清康熙二十三
结果显示: 它是一，一的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002E3A4A4D4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 68.8278, LR: 0.0000100000
真实数据: 火车站前面的科尼希街
结果显示: 次的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 59.0527, LR: 0.0000100000
真实数据: 老公在上一个贺卡网站
结果显示: 老学的，的一
Epoch 0 Step 000200, model loss 64.3849, LR: 0.0000100000
真实数据: 供日常的维护和设备更
结果显示: 也的不的
Epoch 0 Step 000300, model loss 56.8809, LR: 0.0000100000
真实数据: 人的涌入，说自己对未
结果显示: 人，。，
Epoch 0 Step 000400, model loss 66.5844, LR: 0.0000100000
真实数据: 缠使用，几乎是“各村
结果显示: 就、，、，、
Epoch 0 Step 000500, model loss 73.5985, LR: 0.0000100000
真实数据: 使馆宋敬武参赞对旅法
结果显示: 他的有的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 62.1091, LR: 0.0000100000
真实数据: 是以非常欣赏你的口气
结果显示: 是的，的
Epoch 0 Step 000700, model loss 60.1118, LR: 0.0000100000
真实数据: 能满足未来战争的需要
结果显示: 能的是的是的
Epoch 0 Step 000800, model loss 60.1236, LR: 0.0000100000
真实数据: 合体的消息人士日前透
结果显示: 在的在的
Epoch 0 Step 000900, model loss 84.2831, LR: 0.0000100000
真实数据: 损失蜂蜜营养成分，所
结果显示: 据是，是，的
Epoch 0 Step 001000, model loss 65.2873, LR: 0.0000100000
真实数据: 保护，根据公司战略发
结果显示: 但，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 32.0341, LR: 0.0000100000
真实数据: rsoftware.
结果显示: iaoat
Epoch 0 Step 001200, model loss 62.9338, LR: 0.0000100000
真实数据: 生物芯片方面的国际专
结果显示: 生的，的
Epoch 0 Step 001300, model loss 35.1407, LR: 0.0000100000
真实数据: 公司2005年度利润
结果显示: 公20年
Epoch 0 Step 001400, model loss 57.1657, LR: 0.0000100000
真实数据: 我会尽最大的努力去争
结果显示: 我是的是的
Epoch 0 Step 001500, model loss 59.7821, LR: 0.0000100000
真实数据: 有的院校使用特征成绩
结果显示: 我的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 60.4326, LR: 0.0000100000
真实数据: 完全依赖于美国的输出
结果显示: 完的是的
Epoch 0 Step 001700, model loss 63.4516, LR: 0.0000100000
真实数据: 以后你再也别想找他借
结果显示: 以的不的
Epoch 0 Step 001800, model loss 44.0452, LR: 0.0000100000
真实数据: 2000万英镑到60
结果显示: 2000
Epoch 0 Step 001900, model loss 59.4429, LR: 0.0000100000
真实数据: 解放军公开的军事演习
结果显示: 能的是的
Epoch 0 Step 002000, model loss 73.1086, LR: 0.0000100000
真实数据: 确诊断阻塞平面，忽被
结果显示: 高的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 68.3789, LR: 0.0000100000
真实数据: 关于升迁将会是事半功
结果显示: 并的是的
Epoch 0 Step 002200, model loss 60.8286, LR: 0.0000100000
真实数据: 生的基础课程强化班、
结果显示: 生的，的
Epoch 0 Step 002300, model loss 70.3375, LR: 0.0000100000
真实数据: 好善斋僧，因为若不讲
结果显示: 如，。，的
Epoch 0 Step 002400, model loss 53.7883, LR: 0.0000100000
真实数据: 0多年来，陈涛将前场
结果显示: 0年，的，
Epoch 0 Step 002500, model loss 64.6288, LR: 0.0000100000
真实数据: 新球场是在蒙格斯多夫
结果显示: 新的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 59.0577, LR: 0.0000100000
真实数据: 的飞行员身上时有发生
结果显示: 出，的
Epoch 0 Step 002700, model loss 65.3728, LR: 0.0000100000
真实数据: 取情况汇报，”大伟说
结果显示: 对，一，一
Epoch 0 Step 002800, model loss 85.9597, LR: 0.0000100000
真实数据: 卒而便言离也?卿既不
结果显示: 本的不的
Epoch 0 Step 002900, model loss 69.8732, LR: 0.0000100000
真实数据: 免受廉价进口品威胁的
结果显示: 对的在的
Epoch 0 Step 003000, model loss 66.9337, LR: 0.0000100000
真实数据: 社1、本公司董事、监
结果显示: 但，人的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 72.3308, LR: 0.0000100000
真实数据: 乘国际黄金价格近期猛
结果显示: 对的不的
Epoch 0 Step 003200, model loss 69.6420, LR: 0.0000100000
真实数据: 钟内是可以杀灭某些细
结果显示: 何为的一是的
Epoch 0 Step 003300, model loss 72.6480, LR: 0.0000100000
真实数据: 了第10集团军与王耀
结果显示: 1109
Epoch 0 Step 003400, model loss 71.1505, LR: 0.0000100000
真实数据: 布为天津攻入的首粒入
结果显示: 有了人的0
Epoch 0 Step 003500, model loss 57.7816, LR: 0.0000100000
真实数据: 与学生平等交往与交流
结果显示: 与生的生的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 46.3747, LR: 0.0000100000
真实数据: 学（3006）护理教
结果显示: "000
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002A0D20AE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 60.6699, LR: 0.0000100000
真实数据: 可从题干给定的条件或
结果显示: 可是的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 65.5581, LR: 0.0000100000
真实数据: 和尚到那方来?”妖邪
结果显示: 种们，一“一
Epoch 0 Step 000200, model loss 58.1317, LR: 0.0000100000
真实数据: 任的人民政府教育行政
结果显示: 但的人的
Epoch 0 Step 000300, model loss 26.7721, LR: 0.0000100000
真实数据: 3133330133
结果显示: 33
Epoch 0 Step 000400, model loss 60.9017, LR: 0.0000100000
真实数据: 发现我变成无厘头理论
结果显示: 发的是的是的
Epoch 0 Step 000500, model loss 65.4806, LR: 0.0000100000
真实数据: 阳镜;所谓的“八路军
结果显示: 网，一，一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 60.9077, LR: 0.0000100000
真实数据: 功以6-2拿下第一盘
结果显示: 且，1，1
Epoch 0 Step 000700, model loss 63.3284, LR: 0.0000100000
真实数据: 会使人性欲减退、性高
结果显示: 公司的，的人
Epoch 0 Step 000800, model loss 67.9521, LR: 0.0000100000
真实数据: 001深发展A(行情
结果显示: %，。，的
Epoch 0 Step 000900, model loss 73.6607, LR: 0.0000100000
真实数据: 发烧嫌药苦，岂吸风所
结果显示: 发的是的
Epoch 0 Step 001000, model loss 68.1818, LR: 0.0000100000
真实数据: 绝不会亏待他们。垂首
结果显示: 经不，的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 52.7220, LR: 0.0000100000
真实数据: 现在本科生专业74个
结果显示: 现在的在的
Epoch 0 Step 001200, model loss 84.3077, LR: 0.0000100000
真实数据: 」使它成为欧洲最时尚
结果显示: 上的的
Epoch 0 Step 001300, model loss 60.0444, LR: 0.0000100000
真实数据: 下才轮到国内其他一流
结果显示: 下是，的，的
Epoch 0 Step 001400, model loss 55.4771, LR: 0.0000100000
真实数据: 度对实习生在工作中不
结果显示: 成了的是的1
Epoch 0 Step 001500, model loss 66.2550, LR: 0.0000100000
真实数据: 络体系和提升应试能力
结果显示: 经的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 60.4889, LR: 0.0000100000
真实数据: 求生:能适应高强度工
结果显示: 求是的，的
Epoch 0 Step 001700, model loss 82.7486, LR: 0.0000100000
真实数据: 曹丕年长五岁之多的甄
结果显示: 没有的有的
Epoch 0 Step 001800, model loss 58.7999, LR: 0.0000100000
真实数据: 到了一些头颈部肿瘤的
结果显示: 到了一”的
Epoch 0 Step 001900, model loss 54.8893, LR: 0.0000100000
真实数据: ，交接过程会容易一些
结果显示: ，“是的是的
Epoch 0 Step 002000, model loss 57.2469, LR: 0.0000100000
真实数据: 有利于对前一阶段所学
结果显示: 有了，的一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 68.3718, LR: 0.0000100000
真实数据: 请老孙与他降妖，或者
结果显示: 该者的有的
Epoch 0 Step 002200, model loss 67.3116, LR: 0.0000100000
真实数据: 于是蒋先生开始寻觅下
结果显示: 于是的是的
Epoch 0 Step 002300, model loss 68.9696, LR: 0.0000100000
真实数据: 但要大大提高政治觉悟
结果显示: 但是的不的
Epoch 0 Step 002400, model loss 61.9507, LR: 0.0000100000
真实数据: 其次，项目经理，最近
结果显示: 美、，、的
Epoch 0 Step 002500, model loss 56.3178, LR: 0.0000100000
真实数据: 可以根据作战任务和级
结果显示: 可的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 46.8439, LR: 0.0000100000
真实数据: 该公司亏损了210万
结果显示: 记220
Epoch 0 Step 002700, model loss 59.0604, LR: 0.0000100000
真实数据: 这个网名似乎已有取代
结果显示: 这是的，的
Epoch 0 Step 002800, model loss 62.7971, LR: 0.0000100000
真实数据: 在本赛季中期被西雅图
结果显示: 在的有的
Epoch 0 Step 002900, model loss 67.9693, LR: 0.0000100000
真实数据: ・反思需抵达民族文化
结果显示: ・是的是的
Epoch 0 Step 003000, model loss 61.7092, LR: 0.0000100000
真实数据: 水港战略、长江战略和
结果显示: 来，、，、
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 68.2480, LR: 0.0000100000
真实数据: 好友建设中国红客联盟
结果显示: 是的是的
Epoch 0 Step 003200, model loss 61.0961, LR: 0.0000100000
真实数据: 。老教授们对官兵们一
结果显示: 。一是一
Epoch 0 Step 003300, model loss 63.3835, LR: 0.0000100000
真实数据: 、“仗怎么打军队就怎
结果显示: 、一”的
Epoch 0 Step 003400, model loss 59.4627, LR: 0.0000100000
真实数据: 还是和大盘的涨升阶段
结果显示: 还是的是的
Epoch 0 Step 003500, model loss 79.5149, LR: 0.0000100000
真实数据: ，所御琵琶，却也无可
结果显示: ，我是，。，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 62.6785, LR: 0.0000100000
真实数据: 一些网站、论坛上建立
结果显示: ―是，、，
Epoch 0 Step 003700, model loss 62.9179, LR: 0.0000100000
真实数据: 岛海域发现了“比密里
结果显示: 应“是“”
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002402A87F4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 58.0145, LR: 0.0000100000
真实数据: 路设计里面我们有个性
结果显示: 师为的有的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 45.5068, LR: 0.0000100000
真实数据: ww.KL178.c
结果显示: vi.
Epoch 0 Step 000200, model loss 56.3193, LR: 0.0000100000
真实数据: 过程大体上分成3个阶
结果显示: 进是的了的
Epoch 0 Step 000300, model loss 63.0235, LR: 0.0000100000
真实数据: 或者玩一会游戏，朱三
结果显示: 家，。，一
Epoch 0 Step 000400, model loss 84.4545, LR: 0.0000100000
真实数据: 日消息(孙淑艳编译)
结果显示: 日本的
Epoch 0 Step 000500, model loss 71.6017, LR: 0.0000100000
真实数据: 皆菊精也，对信托业严
结果显示: 的，。，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 88.0996, LR: 0.0000100000
真实数据: 孙大窘，他姐姐回忆说
结果显示: 我。，。，的
Epoch 0 Step 000700, model loss 61.2322, LR: 0.0000100000
真实数据: 、个人带来哪些负面影
结果显示: ，不是的人的
Epoch 0 Step 000800, model loss 63.9432, LR: 0.0000100000
真实数据: 从此，荀子与老子不同
结果显示: 从，一的
Epoch 0 Step 000900, model loss 53.5901, LR: 0.0000100000
真实数据: 你的学习应该不变，”
结果显示: 你是了是的
Epoch 0 Step 001000, model loss 61.6588, LR: 0.0000100000
真实数据: 出版社每一个步骤都是
结果显示: 出为是“一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 62.1192, LR: 0.0000100000
真实数据: 泽东的政治事业已经完
结果显示: 深的和的
Epoch 0 Step 001200, model loss 60.3535, LR: 0.0000100000
真实数据: 么会又冒出来两架，2
结果显示: 么司年会的
Epoch 0 Step 001300, model loss 60.1298, LR: 0.0000100000
真实数据: 王孙恐梦见不的，加上
结果显示: 至在，的，的
Epoch 0 Step 001400, model loss 49.2102, LR: 0.0000100000
真实数据: 故罚之。340994
结果显示: 我:，19
Epoch 0 Step 001500, model loss 67.8519, LR: 0.0000100000
真实数据: 是婚变的始作俑者?到
结果显示: 是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 69.6197, LR: 0.0000100000
真实数据: 大浪翻涌。本人概况姓
结果显示: 是。，。，
Epoch 0 Step 001700, model loss 80.9811, LR: 0.0000100000
真实数据: 井冈山与朱毛的红四军
结果显示: 大的有的
Epoch 0 Step 001800, model loss 62.9591, LR: 0.0000100000
真实数据: 机关敢不敢查、查到什
结果显示: 相，。，的
Epoch 0 Step 001900, model loss 55.7213, LR: 0.0000100000
真实数据: 一些温泉里面有一些新
结果显示: 一“是”“”
Epoch 0 Step 002000, model loss 75.9570, LR: 0.0000100000
真实数据: 漂亮，上海杉达学院(
结果显示: 深，。，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 66.5375, LR: 0.0000100000
真实数据: 文图斯和AC米兰同时
结果显示: 共的1
Epoch 0 Step 002200, model loss 53.6547, LR: 0.0000100000
真实数据: 听，按师长和家长要求
结果显示: 明，不的
Epoch 0 Step 002300, model loss 62.5140, LR: 0.0000100000
真实数据: 德军突然采用全新的密
结果显示: 论是的有的
Epoch 0 Step 002400, model loss 56.0177, LR: 0.0000100000
真实数据: 部网站上看到这样一则
结果显示: 们是的，是的
Epoch 0 Step 002500, model loss 59.9904, LR: 0.0000100000
真实数据: 会上对翻译行业认识不
结果显示: 会的的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 46.0863, LR: 0.0000100000
真实数据: 门初盘为2.05受让
结果显示: （11205
Epoch 0 Step 002700, model loss 64.4358, LR: 0.0000100000
真实数据: 眼。遂以为非人也!登
结果显示: 游，、是
Epoch 0 Step 002800, model loss 59.9058, LR: 0.0000100000
真实数据: 实，从各个环节设置到
结果显示: 就，、，的
Epoch 0 Step 002900, model loss 56.0843, LR: 0.0000100000
真实数据: 眼前的这一幕在过去的
结果显示: 听是“一“”
Epoch 0 Step 003000, model loss 63.3597, LR: 0.0000100000
真实数据: 也并不是什么国际惯例
结果显示: 他的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 68.8085, LR: 0.0000100000
真实数据: 选择网络招聘作为主要
结果显示: 以的的
Epoch 0 Step 003200, model loss 54.4673, LR: 0.0000100000
真实数据: 这是群众不满意的地方
结果显示: 这的是的
Epoch 0 Step 003300, model loss 49.1850, LR: 0.0000100000
真实数据: 之。论坛)70.9%
结果显示: 之10986
Epoch 0 Step 003400, model loss 62.8420, LR: 0.0000100000
真实数据: 叫道:我们从拉萨出发
结果显示: “，一的
Epoch 0 Step 003500, model loss 59.4191, LR: 0.0000100000
真实数据: 学校集体食物中毒的8
结果显示: 等国的的0
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 81.4142, LR: 0.0000100000
真实数据: 茗。但汪精卫认为乘坐
结果显示: 和，、在的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021DD83E04C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 67.6236, LR: 0.0000100000
真实数据: 会早前众多的争议一锤
结果显示: 会的，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 70.6224, LR: 0.0000100000
真实数据: 却命下时正值雨季高潮
结果显示: 是中的中的
Epoch 0 Step 000200, model loss 65.1055, LR: 0.0000100000
真实数据: 优势互补，一.“不睡
结果显示: 但，一，一
Epoch 0 Step 000300, model loss 61.4149, LR: 0.0000100000
真实数据: 情和客观的发展前景有
结果显示: 他的是的
Epoch 0 Step 000400, model loss 49.8791, LR: 0.0000100000
真实数据: ”他说，新浪将发布2
结果显示: ”，，2
Epoch 0 Step 000500, model loss 67.7630, LR: 0.0000100000
真实数据: 规范办学行为，薪水嘛
结果显示: 最，的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 50.6177, LR: 0.0000100000
真实数据: ，占全部出生人口的4
结果显示: ，在的
Epoch 0 Step 000700, model loss 61.4234, LR: 0.0000100000
真实数据: 日，经历了多次宫闱之
结果显示: 日，了的
Epoch 0 Step 000800, model loss 69.7973, LR: 0.0000100000
真实数据: 似平民、貌似怀旧、貌
结果显示: 他不，不，
Epoch 0 Step 000900, model loss 68.7398, LR: 0.0000100000
真实数据: 以改正，浮桥由两岸伸
结果显示: 以，、，的
Epoch 0 Step 001000, model loss 73.2667, LR: 0.0000100000
真实数据: 腮，意志脆弱的人根本
结果显示: 经，、的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 59.4767, LR: 0.0000100000
真实数据: 杨老师，“生者以死为
结果显示: 但一，“一
Epoch 0 Step 001200, model loss 67.0221, LR: 0.0000100000
真实数据: 现在又故意挑起‘统独
结果显示: 现的在的
Epoch 0 Step 001300, model loss 50.6472, LR: 0.0000100000
真实数据: rHeight='+
结果显示: dei
Epoch 0 Step 001400, model loss 50.7145, LR: 0.0000100000
真实数据: 就专业的问题我个人体
结果显示: 就的，的
Epoch 0 Step 001500, model loss 58.8274, LR: 0.0000100000
真实数据: 用电子技术、电气工程
结果显示: 用，的，了
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 66.8432, LR: 0.0000100000
真实数据: 。有空的时候又暴饮暴
结果显示: 。在的在的
Epoch 0 Step 001700, model loss 55.2881, LR: 0.0000100000
真实数据: 而且也很难在短时期内
结果显示: 而的在的
Epoch 0 Step 001800, model loss 56.9977, LR: 0.0000100000
真实数据: 3.他们常常夸大他们
结果显示: 3的的
Epoch 0 Step 001900, model loss 58.9401, LR: 0.0000100000
真实数据: 当天，路透，但若相信
结果显示: 渐，、
Epoch 0 Step 002000, model loss 73.5923, LR: 0.0000100000
真实数据: 旨在使用户能够方便地
结果显示: 目前的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 67.6748, LR: 0.0000100000
真实数据: 击AC米兰嘛?[0:
结果显示: ―020
Epoch 0 Step 002200, model loss 64.6565, LR: 0.0000100000
真实数据: 不能跋履。是看人失误
结果显示: 不是，。，
Epoch 0 Step 002300, model loss 60.0370, LR: 0.0000100000
真实数据: 确认有没有消费房间的
结果显示: 确的人的
Epoch 0 Step 002400, model loss 48.1851, LR: 0.0000100000
真实数据: 全国招生的国家重点的
结果显示: 生的在的
Epoch 0 Step 002500, model loss 56.7325, LR: 0.0000100000
真实数据: 衣，有州立的、市立的
结果显示: 我，一，的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 64.8558, LR: 0.0000100000
真实数据: 超过阿森纳队1分。政
结果显示: 加不的，的
Epoch 0 Step 002700, model loss 61.5391, LR: 0.0000100000
真实数据: 市成交量急剧放大的情
结果显示: 前的是的
Epoch 0 Step 002800, model loss 61.6071, LR: 0.0000100000
真实数据: 过今马来亚和文莱国的
结果显示: 过是的是的
Epoch 0 Step 002900, model loss 51.4543, LR: 0.0000100000
真实数据: 对人性的向往都有着许
结果显示: 对人的人的
Epoch 0 Step 003000, model loss 59.4684, LR: 0.0000100000
真实数据: 取政权理论的重要文献
结果显示: 职在的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 43.3378, LR: 0.0000100000
真实数据: 他们取得1-0的领先
结果显示: 他10的
Epoch 0 Step 003200, model loss 59.5281, LR: 0.0000100000
真实数据: 虽然都是经过历史化了
结果显示: 后的是的了
Epoch 0 Step 003300, model loss 50.4757, LR: 0.0000100000
真实数据: 开的“2006世界园
结果显示: 至26
Epoch 0 Step 003400, model loss 77.8116, LR: 0.0000100000
真实数据: "第三节");(编辑
结果显示: “一”一
Epoch 0 Step 003500, model loss 50.0745, LR: 0.0000100000
真实数据: 日本人就进去了，尤其
结果显示: 日，。，人
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 50.5963, LR: 0.0000100000
真实数据: 日14:今年获得大丰
结果显示: [14的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001B3C5C5D4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 59.3238, LR: 0.0000100000
真实数据: 60多个品种。短短两
结果显示: 60多的，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 69.1104, LR: 0.0000100000
真实数据: 者，谨遵所托尼-德尔
结果显示: 表，的
Epoch 0 Step 000200, model loss 63.1707, LR: 0.0000100000
真实数据: 命令军警和反革命的“
结果显示: 今年的是的
Epoch 0 Step 000300, model loss 71.9919, LR: 0.0000100000
真实数据: 在气温达到摄氏零下六
结果显示: 在中的中的
Epoch 0 Step 000400, model loss 67.2915, LR: 0.0000100000
真实数据: 但博取短线差价其实最
结果显示: 也是的是的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000261BF28E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 67.1385, LR: 0.0000100000
真实数据: 实害怕了。《联合国宪
结果显示: 要，。，。，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 72.3605, LR: 0.0000100000
真实数据: 帝，日招甲饮而窃探之
结果显示: 而，。不的
Epoch 0 Step 000200, model loss 50.4448, LR: 0.0000100000
真实数据: 向之“爷”之者“太”
结果显示: 台“”“”
Epoch 0 Step 000300, model loss 67.8385, LR: 0.0000100000
真实数据: 语言文字和文化三方面
结果显示: 到，。，的
Epoch 0 Step 000400, model loss 70.0568, LR: 0.0000100000
真实数据: 秤握算，其实这时你的
结果显示: 和的，的，的
Epoch 0 Step 000500, model loss 60.1116, LR: 0.0000100000
真实数据: 国际赌博公司通过互联
结果显示: 国此的的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 67.7853, LR: 0.0000100000
真实数据: 牌号我找到了人事部门
结果显示: 地一的，的
Epoch 0 Step 000700, model loss 49.4118, LR: 0.0000100000
真实数据: 美元至1.40美元之
结果显示: "0
Epoch 0 Step 000800, model loss 64.9880, LR: 0.0000100000
真实数据: 那里去?还我宝贝来!
结果显示: 现，1
Epoch 0 Step 000900, model loss 63.1832, LR: 0.0000100000
真实数据: ”徐问:为赚钱而工作
结果显示: “人，的，的
Epoch 0 Step 001000, model loss 60.6791, LR: 0.0000100000
真实数据: 之，出门径去。强压训
结果显示: 之，、
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 53.6046, LR: 0.0000100000
真实数据: 定使中国成为了苏联的
结果显示: 定的中的
Epoch 0 Step 001200, model loss 60.9091, LR: 0.0000100000
真实数据: 他、木贝司或人的掌声
结果显示: 他，、的
Epoch 0 Step 001300, model loss 71.1149, LR: 0.0000100000
真实数据: 甚至害怕在公共场所进
结果显示: 我们的是的
Epoch 0 Step 001400, model loss 57.6215, LR: 0.0000100000
真实数据: 中国人对自卫队要改称
结果显示: 中的人的
Epoch 0 Step 001500, model loss 66.1988, LR: 0.0000100000
真实数据: 由能通过与之偶联的酶
结果显示: 时国的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 73.2622, LR: 0.0000100000
真实数据: 眼线、涂口红就会增添
结果显示: 即，。，的
Epoch 0 Step 001700, model loss 67.7481, LR: 0.0000100000
真实数据: 厢情愿自认为专业就是
结果显示: 果的的
Epoch 0 Step 001800, model loss 68.7926, LR: 0.0000100000
真实数据: 罗大佑最鲜明的外在形
结果显示: 发有的的
Epoch 0 Step 001900, model loss 54.8921, LR: 0.0000100000
真实数据: 有自已的语言但没有文
结果显示: 有的的
Epoch 0 Step 002000, model loss 59.9695, LR: 0.0000100000
真实数据: 民营企业在答辩会上招
结果显示: 民的在的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 61.6695, LR: 0.0000100000
真实数据: 闻门外有哭女者，里肯
结果显示: 同，日，
Epoch 0 Step 002200, model loss 68.6587, LR: 0.0000100000
真实数据: 页:不做“青蛙”就跳
结果显示: ”一“”“”
Epoch 0 Step 002300, model loss 61.6980, LR: 0.0000100000
真实数据: 的早晚和治疗是否合理
结果显示: 的是的不的
Epoch 0 Step 002400, model loss 66.8826, LR: 0.0000100000
真实数据: 招生计划中为二志愿填
结果显示: 招的的
Epoch 0 Step 002500, model loss 76.1322, LR: 0.0000100000
真实数据: 庆市迪马实业股份有限
结果显示: 成的是的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 73.6704, LR: 0.0000100000
真实数据: 试通过向社会募捐提高
结果显示: 进是的是的
Epoch 0 Step 002700, model loss 74.9249, LR: 0.0000100000
真实数据: 何必求所难遘，子微笑
结果显示: 们的，的，的
Epoch 0 Step 002800, model loss 64.4346, LR: 0.0000100000
真实数据: 的梦充满了这种天然颜
结果显示: 的为是的是的
Epoch 0 Step 002900, model loss 64.5244, LR: 0.0000100000
真实数据: 应该继续批判传统文化
结果显示: 应的有的
Epoch 0 Step 003000, model loss 63.7466, LR: 0.0000100000
真实数据: 空武器系统和地面飞机
结果显示: 实的不的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 66.6749, LR: 0.0000100000
真实数据: 仅保留了一部分劳务补
结果显示: 但一”“一
Epoch 0 Step 003200, model loss 60.9359, LR: 0.0000100000
真实数据: 数学思想”这个中心盯
结果显示: 要的的
Epoch 0 Step 003300, model loss 45.0705, LR: 0.0000100000
真实数据: 胜闲时为20时至8时
结果显示: 股208
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021F03F6E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 21.0613, LR: 0.0000100000
真实数据: 59年初到1960年
结果显示: 59年960年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 50.6965, LR: 0.0000100000
真实数据: 有求于开发商们的一个
结果显示: 有了的了
Epoch 0 Step 000200, model loss 70.8007, LR: 0.0000100000
真实数据: 定向直投读者数据库和
结果显示: 时的是的
Epoch 0 Step 000300, model loss 54.8945, LR: 0.0000100000
真实数据: 当时的中外沟通渠道不
结果显示: 当的是的
Epoch 0 Step 000400, model loss 54.8450, LR: 0.0000100000
真实数据: 未来战争中，男人“例
结果显示: 来，，一
Epoch 0 Step 000500, model loss 71.7357, LR: 0.0000100000
真实数据: 之下大力囤积了万枚导
结果显示: 之，不，人
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 63.6837, LR: 0.0000100000
真实数据: 积、封装成本、元件数
结果显示: 管，、，、
Epoch 0 Step 000700, model loss 62.1901, LR: 0.0000100000
真实数据: 引进大牌球员无能为力
结果显示: 家的是的
Epoch 0 Step 000800, model loss 55.2592, LR: 0.0000100000
真实数据: 百地对4人进行了面试
结果显示: 了4人
Epoch 0 Step 000900, model loss 73.8294, LR: 0.0000100000
真实数据: 高傣药质量。对银行招
结果显示: 高有，。，
Epoch 0 Step 001000, model loss 18.3107, LR: 0.0000100000
真实数据: itethedrea
结果显示: Tetaetaaa
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 53.2026, LR: 0.0000100000
真实数据: 对一个读者或观众而言
结果显示: 对一的
Epoch 0 Step 001200, model loss 57.3521, LR: 0.0000100000
真实数据: 来说，一个宾馆就足以
结果显示: 王，一“一
Epoch 0 Step 001300, model loss 66.4693, LR: 0.0000100000
真实数据: 国投降及欧洲战争结束
结果显示: 国的
Epoch 0 Step 001400, model loss 75.9344, LR: 0.0000100000
真实数据: ，有民女苏氏浣衣于河
结果显示: ，有的有的
Epoch 0 Step 001500, model loss 76.8203, LR: 0.0000100000
真实数据: 黄山归来不看岳。自辰
结果显示: 每，人，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 54.4338, LR: 0.0000100000
真实数据: CIA的人想不想见这
结果显示: c人的在
Epoch 0 Step 001700, model loss 60.0326, LR: 0.0000100000
真实数据: 地说道:仍然是初级阶
结果显示: 地的，的一
Epoch 0 Step 001800, model loss 65.7272, LR: 0.0000100000
真实数据: 布接过望远镜看了一会
结果显示: 在们一“一
Epoch 0 Step 001900, model loss 61.4434, LR: 0.0000100000
真实数据: 东与盛大网络合作进军
结果显示: 东的的
Epoch 0 Step 002000, model loss 65.7443, LR: 0.0000100000
真实数据: ，皇帝既有三宫六院的
结果显示: ，是一，一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 70.4828, LR: 0.0000100000
真实数据: ，左权的红色旅游毁掉
结果显示: ，2的
Epoch 0 Step 002200, model loss 51.3601, LR: 0.0000100000
真实数据: 广东人一听见“8”就
结果显示: ?，一?
Epoch 0 Step 002300, model loss 52.0005, LR: 0.0000100000
真实数据: 但是她还不敢表现出来
结果显示: 但是的是的
Epoch 0 Step 002400, model loss 60.7020, LR: 0.0000100000
真实数据: 白话文著作为语法规范
结果显示: 白的的
Epoch 0 Step 002500, model loss 70.1521, LR: 0.0000100000
真实数据: 妖看见，以采购价增加
结果显示: 如
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 49.1323, LR: 0.0000100000
真实数据: 70%的疾病都由压力
结果显示: 70分的日
Epoch 0 Step 002700, model loss 34.7973, LR: 0.0000100000
真实数据: 调查总队公布的统计数
结果显示: 说在的面公有的结计要
Epoch 0 Step 002800, model loss 43.8080, LR: 0.0000100000
真实数据: 有比写回忆录更重要的
结果显示: 有比要电最要要要的
Epoch 0 Step 002900, model loss 24.1380, LR: 0.0000100000
真实数据: 于重点型号的试飞工作
结果显示: 于重点至的计飞工作
Epoch 0 Step 003000, model loss 50.4852, LR: 0.0000100000
真实数据: 一定要奉陪到底。石闻
结果显示: 一要本钱种。不间
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 51.0483, LR: 0.0000100000
真实数据: 的自然景观完美的结合
结果显示: “的公器更的在么
Epoch 0 Step 003200, model loss 39.4087, LR: 0.0000100000
真实数据: 刚好是和成都联合在一
结果显示: 需是是就后然一
Epoch 0 Step 003300, model loss 25.9695, LR: 0.0000100000
真实数据: 连续破发成功以6-2
结果显示: 连统场发成以6-2
Epoch 0 Step 003400, model loss 25.7251, LR: 0.0000100000
真实数据: 求职者在应聘时还需提
结果显示: 求取在将时高提
Epoch 0 Step 003500, model loss 12.6652, LR: 0.0000100000
真实数据: 自卫队官兵的文化水平
结果显示: 自卫队官具的文化力平
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 30.4798, LR: 0.0000100000
真实数据: 结构最直接结果是使市
结果显示: 给相是立提经果是自市
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000028AA84AE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 19.1572, LR: 0.0000100000
真实数据: 起，他不能容忍别人的
结果显示: 起，他不能看别人自
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 31.2217, LR: 0.0000100000
真实数据: 完走了，不管打输还是
结果显示: 若参了，不本机这
Epoch 0 Step 000200, model loss 46.9061, LR: 0.0000100000
真实数据: 对消费者来说实质上是
结果显示: 定游然动做多民上是
Epoch 0 Step 000300, model loss 54.5701, LR: 0.0000100000
真实数据: 动挑衅来激怒大陆回应
结果显示: 动来游各大用国应
Epoch 0 Step 000400, model loss 12.8595, LR: 0.0000100000
真实数据: 的真实意图是用此法来
结果显示: 的育实意出是用此法来
Epoch 0 Step 000500, model loss 31.5509, LR: 0.0000100000
真实数据: 国友好关系有着一个极
结果显示: 国发关动看-
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 43.8379, LR: 0.0000100000
真实数据: 稳固了他们希望维持的
结果显示: 原国了他们考空地持的
Epoch 0 Step 000700, model loss 23.2513, LR: 0.0000100000
真实数据: 的发展势头产生重要影
结果显示: 的发资来产生觉要遍
Epoch 0 Step 000800, model loss 63.4153, LR: 0.0000100000
真实数据: 苦努力也难以摆脱孤陋
结果显示: 鼎多力也对以提股孩
Epoch 0 Step 000900, model loss 27.3907, LR: 0.0000100000
真实数据: 学生理想信念教育的针
结果显示: 学生理想自么教的何
Epoch 0 Step 001000, model loss 35.1860, LR: 0.0000100000
真实数据: 按五门总成绩进行录取
结果显示: 打了自总成经过行系确
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 31.2390, LR: 0.0000100000
真实数据: 休斯在9分40秒投中
结果显示: 体则在9分40%如中
Epoch 0 Step 001200, model loss 31.6201, LR: 0.0000100000
真实数据: 的汤杯，第四位得3分
结果显示: 的行，维国的得3分
Epoch 0 Step 001300, model loss 24.4935, LR: 0.0000100000
真实数据: 表态说:在首期试点期
结果显示: 表本议:在自期法点期
Epoch 0 Step 001400, model loss 44.2697, LR: 0.0000100000
真实数据: 频密分娩或多次人工流
结果显示: 期的分或多次人工法
Epoch 0 Step 001500, model loss 36.9576, LR: 0.0000100000
真实数据: 被旁人的感觉所替代的
结果显示: 被突人的成部代的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 42.8033, LR: 0.0000100000
真实数据: 审视自己的工作:填补
结果显示: 中铁自己的的:来1
Epoch 0 Step 001700, model loss 18.1941, LR: 0.0000100000
真实数据: 际应用过程中，并以食
结果显示: 际应用过我中，那以都
Epoch 0 Step 001800, model loss 38.0088, LR: 0.0000100000
真实数据: 税（销项税额）170
结果显示: 看（项程刺）170
Epoch 0 Step 001900, model loss 30.8303, LR: 0.0000100000
真实数据: 使事先不花一分钱，迫
结果显示: 使有力不花一分花，近
Epoch 0 Step 002000, model loss 24.8975, LR: 0.0000100000
真实数据: 埃里克森还有惊人之举
结果显示: 择里完者还有长人之军
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 13.2312, LR: 0.0000100000
真实数据: 对人生选择、人生道路
结果显示: 对人生进都、人生道题
Epoch 0 Step 002200, model loss 13.3296, LR: 0.0000100000
真实数据: 这种方法是最科学、最
结果显示: 这种方法是种学、意
Epoch 0 Step 002300, model loss 56.8168, LR: 0.0000100000
真实数据: 炸毁弹药库要伤及无辜
结果显示: 她r张药内要你及无半
Epoch 0 Step 002400, model loss 13.9266, LR: 0.0000100000
真实数据: 游股份有限公司股权分
结果显示: 游股能有用公司股权分
Epoch 0 Step 002500, model loss 54.2574, LR: 0.0000100000
真实数据: 奇怪，水旁、酉旁者饮
结果显示: 部严，本学、两者者他
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 62.0159, LR: 0.0000100000
真实数据: 要鞠躬90度。然渐觇
结果显示: 要将房90应然决品
Epoch 0 Step 002700, model loss 10.4502, LR: 0.0000100000
真实数据: 个方面，正是因为具有
结果显示: 个六面，正是国为是有
Epoch 0 Step 002800, model loss 36.3785, LR: 0.0000100000
真实数据: 卫队的“宙斯”舰在日
结果显示: 且队的“部期”知在日
Epoch 0 Step 002900, model loss 45.2060, LR: 0.0000100000
真实数据: 、白蛋白或胎盘球蛋白
结果显示: 、白还它定股整球更白
Epoch 0 Step 003000, model loss 50.8336, LR: 0.0000100000
真实数据: 日报)陶醉在优美的音
结果显示: 目播在作美的自
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 37.8360, LR: 0.0000100000
真实数据: 开协作并支持高级语音
结果显示: 不做作种全样么语者
Epoch 0 Step 003200, model loss 10.6757, LR: 0.0000100000
真实数据: 产业的未来发展指明了
结果显示: 产业的来来发是报明了
Epoch 0 Step 003300, model loss 31.7593, LR: 0.0000100000
真实数据: 实事，最好备一双鞋供
结果显示: 实事，最好各一现装化
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021ACE95E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 28.3269, LR: 0.0000100000
真实数据: 每周进行3次有氧运动
结果显示: 好机进行3次有环话动
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 53.9201, LR: 0.0000100000
真实数据: “贤甥，霍尔斯特宫诺
结果显示: “管级，孩新斯校往进
Epoch 0 Step 000200, model loss 46.9239, LR: 0.0000100000
真实数据: 们要感谢戴戈同学!是
结果显示: 行整东说划可学!是
Epoch 0 Step 000300, model loss 21.3582, LR: 0.0000100000
真实数据: 生应该有意识地培养自
结果显示: 生应该有意认地地学自
Epoch 0 Step 000400, model loss 5.3947, LR: 0.0000100000
真实数据: 益。已在公司工作了十
结果显示: 东。已在公司工作了卡
Epoch 0 Step 000500, model loss 14.9852, LR: 0.0000100000
真实数据: 所以也有几位同学持相
结果显示: 用以也有几t学机
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 17.6095, LR: 0.0000100000
真实数据: 充分考虑国家需要的前
结果显示: 走分考应国家索更的前
Epoch 0 Step 000700, model loss 10.2227, LR: 0.0000100000
真实数据: 多的作家正以自己的努
结果显示: 多的作家正以自己的参
Epoch 0 Step 000800, model loss 14.6826, LR: 0.0000100000
真实数据: 可能是我最后一次尤杯
结果显示: 可能是我最后一次龙
Epoch 0 Step 000900, model loss 25.3328, LR: 0.0000100000
真实数据: 室内最好不用化纤材料
结果显示: 空内最好不用化线料将
Epoch 0 Step 001000, model loss 1.1668, LR: 0.0000100000
真实数据: 年北交大新增两个专业
结果显示: 年北交大新增两个专业
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 30.4220, LR: 0.0000100000
真实数据: 打开了话闸，俱乐部与
结果显示: 打开了试用，但乐专与
Epoch 0 Step 001200, model loss 8.0271, LR: 0.0000100000
真实数据: 总告诉王先生，多年来
结果显示: 总得说王先生，多年来
Epoch 0 Step 001300, model loss 9.9967, LR: 0.0000100000
真实数据: 3)每10份派0.3
结果显示: 3每10的需0.3
Epoch 0 Step 001400, model loss 21.2376, LR: 0.0000100000
真实数据: 有限公司人事科长张裕
结果显示: 有限公司人事种张相
Epoch 0 Step 001500, model loss 34.9345, LR: 0.0000100000
真实数据: 储蓄仍是大部分人传统
结果显示: 笛首们是大部分人传绝
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 1.5855, LR: 0.0000100000
真实数据: 在内的所有对手产品。
结果显示: 在内的所有对手产品。
Epoch 0 Step 001700, model loss 33.4854, LR: 0.0000100000
真实数据: 悲剧精神不断加剧的历
结果显示: 啧展将神不股加展的历
Epoch 0 Step 001800, model loss 4.3568, LR: 0.0000100000
真实数据: 金，绝大多数人不得不
结果显示: 金，解大多数人不得不
Epoch 0 Step 001900, model loss 39.8244, LR: 0.0000100000
真实数据: 章程的解释权属学校本
结果显示: 取得的仅学校本
Epoch 0 Step 002000, model loss 8.6790, LR: 0.0000100000
真实数据: 一个健全的社会是这样
结果显示: 一个统全的社会是这将
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 39.2341, LR: 0.0000100000
真实数据: 国门、赢得世界声誉的
结果显示: 国11、张得世当的
Epoch 0 Step 002200, model loss 11.3187, LR: 0.0000100000
真实数据: 7号安东尼反越位成功
结果显示: 7早史东反越位成功
Epoch 0 Step 002300, model loss 16.4577, LR: 0.0000100000
真实数据: ，论坛)和苏宁电器(
结果显示: ，论场)和办宁电都（
Epoch 0 Step 002400, model loss 15.6605, LR: 0.0000100000
真实数据: 队防空作战、反潜作战
结果显示: 队空作战、这渐作战
Epoch 0 Step 002500, model loss 33.7429, LR: 0.0000100000
真实数据: 男性真实地或仪式化地
结果显示: 深社实地或行化地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 13.8066, LR: 0.0000100000
真实数据: 远远没有彻底。只能进
结果显示: 运远没有很底。只能进
Epoch 0 Step 002700, model loss 24.0808, LR: 0.0000100000
真实数据: 估测你在本届考生中的
结果显示: 值没你在本活考生中的
Epoch 0 Step 002800, model loss 14.1940, LR: 0.0000100000
真实数据: 得会外语如今，心之死
结果显示: 得会失话如令，心之列
Epoch 0 Step 002900, model loss 40.0363, LR: 0.0000100000
真实数据: 愤青、艺术青年的殿堂
结果显示: 根滞、当术商年的路发
Epoch 0 Step 003000, model loss 21.6828, LR: 0.0000100000
真实数据: 有一种“处女禁忌”现
结果显示: 有一种“外女教马”现
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 20.9962, LR: 0.0000100000
真实数据: 恐日久伤其生命，外界
结果显示: 爱日人保其生命，外界
Epoch 0 Step 003200, model loss 25.1156, LR: 0.0000100000
真实数据: 逼得一场和局。各执骨
结果显示: 想得一场和局。各执性
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000018BC54AE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 31.6732, LR: 0.0000100000
真实数据: 还提出去跳舞，观点仅
结果显示: 还提出者游好，事点息
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 4.2839, LR: 0.0000100000
真实数据: 对象几乎百分之百希望
结果显示: 对象几平百分之百希望
Epoch 0 Step 000200, model loss 28.5515, LR: 0.0000100000
真实数据: 夫系列枪支的企业拟为
结果显示: 表系情安的企业报为
Epoch 0 Step 000300, model loss 21.6656, LR: 0.0000100000
真实数据: “清凉装”对学生同样
结果显示: “满演装“对学生同什
Epoch 0 Step 000400, model loss 9.3241, LR: 0.0000100000
真实数据: 布《上市公司证券发行
结果显示: 布《上市公司通美发行
Epoch 0 Step 000500, model loss 11.5567, LR: 0.0000100000
真实数据: 自不同国度的音乐家们
结果显示: 自不同国度的省场家信
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 36.1350, LR: 0.0000100000
真实数据: ，研究表明，涛声依旧
结果显示: ，研究表明，法声体[
Epoch 0 Step 000700, model loss 7.4099, LR: 0.0000100000
真实数据: （现在国际上通行的生
结果显示: (现在国际上通行的生
Epoch 0 Step 000800, model loss 45.2622, LR: 0.0000100000
真实数据: 不要轻易交纳各种费用
结果显示: 军要较些文政各都觉
Epoch 0 Step 000900, model loss 39.7729, LR: 0.0000100000
真实数据: ．朝廷直接管辖的行省
结果显示: 、就功直接管精的行不
Epoch 0 Step 001000, model loss 8.7589, LR: 0.0000100000
真实数据: 个理念的改变，都容易
结果显示: 个理会的改变，都客易
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 13.8268, LR: 0.0000100000
真实数据: 现在游客投诉居高不下
结果显示: 理在游客投语顾高不下
Epoch 0 Step 001200, model loss 15.4162, LR: 0.0000100000
真实数据: !我和老公是去年扯的
结果显示: !我利老公是去年招的
Epoch 0 Step 001300, model loss 7.7666, LR: 0.0000100000
真实数据: 5月2日至5日及5月
结果显示: 3月3日至3日及3月
Epoch 0 Step 001400, model loss 17.4086, LR: 0.0000100000
真实数据: rs.addItem
结果显示: ;6.add[ten
Epoch 0 Step 001500, model loss 17.4670, LR: 0.0000100000
真实数据: 共总也不上三百间，跳
结果显示: 英总也不上三百网，政
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 4.5524, LR: 0.0000100000
真实数据: 素所目前，因为它比较
结果显示: 素所目前，因为比较
Epoch 0 Step 001700, model loss 14.7165, LR: 0.0000100000
真实数据: 为血压波动的情况比持
结果显示: 为正区动的情况比持
Epoch 0 Step 001800, model loss 60.8237, LR: 0.0000100000
真实数据: 用荞麦粉做成一种馅为
结果显示: 用拥全机做成一种的为
Epoch 0 Step 001900, model loss 43.2184, LR: 0.0000100000
真实数据: 再发展，她们不觊觎男
结果显示: 明发展，她们不源自是
Epoch 0 Step 002000, model loss 12.4191, LR: 0.0000100000
真实数据: 论是从总体平均得分上
结果显示: 询是从上体平分上
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 4.1095, LR: 0.0000100000
真实数据: 这种新情况的出现，1
结果显示: 这种新情况的出理，1
Epoch 0 Step 002200, model loss 13.6747, LR: 0.0000100000
真实数据: ，告别，此后，“我身
结果显示: ，告别，此后?”“新集
Epoch 0 Step 002300, model loss 68.0392, LR: 0.0000100000
真实数据: 那妖邪轮杵来迎，妇云
结果显示: 那经测常样来通，红云
Epoch 0 Step 002400, model loss 30.3024, LR: 0.0000100000
真实数据: 常能见到外国人来掏光
结果显示: 常能职到外国人都北
Epoch 0 Step 002500, model loss 44.0763, LR: 0.0000100000
真实数据: 驶仪系统将同EADS
结果显示: 破位乐结将同目ALS
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 4.2763, LR: 0.0000100000
真实数据: 公司对他的考核就已经
结果显示: 公司对他的考接就已经
Epoch 0 Step 002700, model loss 21.3247, LR: 0.0000100000
真实数据: 不是想多教课吗，汉景
结果显示: 不是想多教说响，江量
Epoch 0 Step 002800, model loss 3.2587, LR: 0.0000100000
真实数据: 此“行之不远”;这样
结果显示: 此“行之不远”:这样
Epoch 0 Step 002900, model loss 36.0635, LR: 0.0000100000
真实数据: 开寇家大门，心如刀搅
结果显示: 开定家大门，心知7除
Epoch 0 Step 003000, model loss 24.8714, LR: 0.0000100000
真实数据: 不能回笼及高额贷款利
结果显示: 不能回知及高额教利
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 48.1023, LR: 0.0000100000
真实数据: 他俩开刀。湘军俱乐部
结果显示: 他饭开万。满写们还东
Epoch 0 Step 003200, model loss 16.5847, LR: 0.0000100000
真实数据: 了农村学生从小所享受
结果显示: 了表持学生从小所事受
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002990D25E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 48.3253, LR: 0.0000100000
真实数据: 几件撒手锏武器去扭转
结果显示: 几体据手够此器去投转
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 9.0693, LR: 0.0000100000
真实数据: 的中国首项直播移动电
结果显示: 的中国自项直据社动电
Epoch 0 Step 000200, model loss 15.5985, LR: 0.0000100000
真实数据: :崂山区政府将大力推
结果显示: :掌山区政府将大力指
Epoch 0 Step 000300, model loss 9.3787, LR: 0.0000100000
真实数据: 岁的陈女士三年来“饭
结果显示: 岁的阳女士三年来“意
Epoch 0 Step 000400, model loss 20.0284, LR: 0.0000100000
真实数据: 女子援登舟上，”石武
结果显示: 女子投劣升上，”石武
Epoch 0 Step 000500, model loss 18.1591, LR: 0.0000100000
真实数据: 四家顶级服务器制造商
结果显示: 四家项级服务器制造商
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 15.7394, LR: 0.0000100000
真实数据: 源和存在:1053例
结果显示: 源和在在:1053的
Epoch 0 Step 000700, model loss 11.2117, LR: 0.0000100000
真实数据: 所有这些建筑和色彩都
结果显示: 所有这些建趣和医孩都
Epoch 0 Step 000800, model loss 46.7201, LR: 0.0000100000
真实数据: 家禽防疫及疫情情况进
结果显示: 家向防病及游情情况选
Epoch 0 Step 000900, model loss 12.6779, LR: 0.0000100000
真实数据: 谓“宁静以致远”、“
结果显示: 请“宁前以到远”、“
Epoch 0 Step 001000, model loss 28.7333, LR: 0.0000100000
真实数据: 水角耶?今竟何如?”
结果显示: 水职?今免何如7”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 11.0892, LR: 0.0000100000
真实数据: 发行价格不低于本次董
结果显示: 发行价格不低于本次带
Epoch 0 Step 001200, model loss 4.4612, LR: 0.0000100000
真实数据: 民调解组织的规范化建
结果显示: 民调解组织的报范化建
Epoch 0 Step 001300, model loss 30.9051, LR: 0.0000100000
真实数据: 买房，在硬件建设方面
结果显示: 列学，查现件建设方面
Epoch 0 Step 001400, model loss 2.9886, LR: 0.0000100000
真实数据: ，只能领取4000元
结果显示: ，只能领取4000元
Epoch 0 Step 001500, model loss 22.8558, LR: 0.0000100000
真实数据: 人才绕起舌头学儿化音
结果显示: 人才分起含头学儿化专
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 15.7731, LR: 0.0000100000
真实数据: 117.独立学院和民
结果显示: 117岁立学院和民
Epoch 0 Step 001700, model loss 23.6556, LR: 0.0000100000
真实数据: 须抓住信息化这个本质
结果显示: 发像信息化这个本单
Epoch 0 Step 001800, model loss 5.1285, LR: 0.0000100000
真实数据: 这三场战争，面试者会
结果显示: 这三场战争，面请者会
Epoch 0 Step 001900, model loss 26.5071, LR: 0.0000100000
真实数据: “朋友圈”成为商务新
结果显示: “用友时”成为商教新
Epoch 0 Step 002000, model loss 24.9405, LR: 0.0000100000
真实数据: 海警一支队二大队营区
结果显示: 案曾一女队二大队些区
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 2.2325, LR: 0.0000100000
真实数据: 582998)的条款
结果显示: 582998)的条新
Epoch 0 Step 002200, model loss 11.1535, LR: 0.0000100000
真实数据: 射!”一声令下，目前
结果显示: 射!”一方今下，日前
Epoch 0 Step 002300, model loss 41.0702, LR: 0.0000100000
真实数据: 抽查到携带假冒名牌产
结果显示: 把查到技带很民名牌产
Epoch 0 Step 002400, model loss 9.3440, LR: 0.0000100000
真实数据: 出门上班还是买个东西
结果显示: 出门班还是要个东面
Epoch 0 Step 002500, model loss 9.1829, LR: 0.0000100000
真实数据: 克平均每场21.7分
结果显示: 党均每场21.分
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 38.5039, LR: 0.0000100000
真实数据: 万余里，它是高贵珍馐
结果显示: 万金里，容是部封引借
Epoch 0 Step 002700, model loss 3.8146, LR: 0.0000100000
真实数据: 升美日军事一体化的水
结果显示: 开美军事一体化的水
Epoch 0 Step 002800, model loss 15.0251, LR: 0.0000100000
真实数据: 她印象深刻的是公司承
结果显示: 她印象深对的是公司承
Epoch 0 Step 002900, model loss 16.9694, LR: 0.0000100000
真实数据: 。考生身体健康状况检
结果显示: 。考生身体使成将况域
Epoch 0 Step 003000, model loss 18.3939, LR: 0.0000100000
真实数据: 亡”的营业税改革将难
结果显示: 耳”的营业孩改半将难
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 17.5759, LR: 0.0000100000
真实数据: 此后，“蜜月可以不度
结果显示: 此后，“资月可以不息
Epoch 0 Step 003200, model loss 20.7642, LR: 0.0000100000
真实数据: 瘩。符合市场经济规律
结果显示: 准。待合市场经济规律
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000025AED21E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 10.8991, LR: 0.0000100000
真实数据: 的5支球队都夺得总冠
结果显示: 的5支球队都夺得总短
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 15.2716, LR: 0.0000100000
真实数据: 维多维奇终于在比赛进
结果显示: 维多维费映于在比赛连
Epoch 0 Step 000200, model loss 12.9976, LR: 0.0000100000
真实数据: 转向了从事现代服务行
结果显示: 物向了从事现代多行
Epoch 0 Step 000300, model loss 34.0579, LR: 0.0000100000
真实数据: 老孙误入于此，红细胞
结果显示: 东和理入于此，红细解
Epoch 0 Step 000400, model loss 45.6017, LR: 0.0000100000
真实数据: WIN-T项目进展很
结果显示: r项日道展很
Epoch 0 Step 000500, model loss 32.6978, LR: 0.0000100000
真实数据: 申报世界文化遗产的工
结果显示: 中提他思文化饮产的工
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 7.6264, LR: 0.0000100000
真实数据: 已的文字，同学们设计
结果显示: 己的文字，同学们设计
Epoch 0 Step 000700, model loss 3.4203, LR: 0.0000100000
真实数据: 了航母就需要一种经济
结果显示: 了航母就需要一种经济
Epoch 0 Step 000800, model loss 10.2451, LR: 0.0000100000
真实数据: 两个相距百年的专制王
结果显示: 两个相限百年的专制王
Epoch 0 Step 000900, model loss 10.9564, LR: 0.0000100000
真实数据: 持巨额军费以保持美国
结果显示: 持管领军费以保持美国
Epoch 0 Step 001000, model loss 4.5870, LR: 0.0000100000
真实数据: 在体验当地的人文生活
结果显示: 在体孩当地的人文生活
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 7.8070, LR: 0.0000100000
真实数据: 最好选择面积较大的眼
结果显示: 最好选挥面积转大的眼
Epoch 0 Step 001200, model loss 16.0727, LR: 0.0000100000
真实数据: 会申报“河豚特区”一
结果显示: 会中报“间听特区”一
Epoch 0 Step 001300, model loss 0.0605, LR: 0.0000100000
真实数据: [2006]240号
结果显示: [2006]240号
Epoch 0 Step 001400, model loss 7.5091, LR: 0.0000100000
真实数据: 司提醒:12:01足
结果显示: 司提西:12:01
Epoch 0 Step 001500, model loss 0.4159, LR: 0.0000100000
真实数据: 也没有能力大力发展军
结果显示: 也没有能力大力发展军
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 21.1208, LR: 0.0000100000
真实数据: 别从日本冲绳和本土抵
结果显示: 别从日本冲趣和本土报
Epoch 0 Step 001700, model loss 37.2887, LR: 0.0000100000
真实数据: 胎儿体内细胞染色体断
结果显示: 路儿体继欧觉色体断
Epoch 0 Step 001800, model loss 15.6479, LR: 0.0000100000
真实数据: 者可以检查CPU风扇
结果显示: 者司以检查CP风家
Epoch 0 Step 001900, model loss 27.2937, LR: 0.0000100000
真实数据: 此外，MBA逻辑考试
结果显示: 此外，情A理转考该
Epoch 0 Step 002000, model loss 16.6649, LR: 0.0000100000
真实数据: ，河北宣工（0009
结果显示: ，河闷工（0009
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 17.2281, LR: 0.0000100000
真实数据: 每次上岸后都应补擦一
结果显示: 每次上后都应补握一
Epoch 0 Step 002200, model loss 0.6952, LR: 0.0000100000
真实数据: 每次两三百元也就可以
结果显示: 每次两三百元也就可以
Epoch 0 Step 002300, model loss 13.9394, LR: 0.0000100000
真实数据: 洁收获个人年度首个冠
结果显示: 济收获个人年度首个活
Epoch 0 Step 002400, model loss 3.9461, LR: 0.0000100000
真实数据: 不少球员和我们球员关
结果显示: 不少球员和我们球员关
Epoch 0 Step 002500, model loss 10.5562, LR: 0.0000100000
真实数据: 提起太行山深处的麻田
结果显示: 提起太行山深处的康B
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 8.2942, LR: 0.0000100000
真实数据: 部分元件就能提高雷达
结果显示: 部分元件就能提高前达
Epoch 0 Step 002700, model loss 3.7715, LR: 0.0000100000
真实数据: 谁知情况的变化往往出
结果显示: 谁知情况的变化往往出
Epoch 0 Step 002800, model loss 7.8126, LR: 0.0000100000
真实数据: 一次大规模调整网站物
结果显示: 一次大规提调整网站特
Epoch 0 Step 002900, model loss 29.9888, LR: 0.0000100000
真实数据: (未采取措施修理和更
结果显示: (本采取持物修理和天
Epoch 0 Step 003000, model loss 3.6792, LR: 0.0000100000
真实数据: 欢花香，中国利用美国
结果显示: 欢花香，中国利用美国
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 7.7330, LR: 0.0000100000
真实数据: 位区县高招办负责人分
结果显示: 位区易高招办负责人分
Epoch 0 Step 003200, model loss 4.1704, LR: 0.0000100000
真实数据: 的消费水准来预算即可
结果显示: 的清费水准来预算即可
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001BE78FDE4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 2.9279, LR: 0.0000100000
真实数据: 人要想提高自己的生育
结果显示: 人要把提高自己的生育
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 8.5568, LR: 0.0000100000
真实数据: 西方早期精神产品的不
结果显示: 西方早期着持产品的不
Epoch 0 Step 000200, model loss 10.7757, LR: 0.0000100000
真实数据: 史类考生为18515
结果显示: 史为考生为15515
Epoch 0 Step 000300, model loss 14.9611, LR: 0.0000100000
真实数据: 报讯（记者胡敏）“地
结果显示: 报语（记者内编）“地
Epoch 0 Step 000400, model loss 3.7939, LR: 0.0000100000
真实数据: 。正如古老学科数学一
结果显示: 。正如去老学科数学一
Epoch 0 Step 000500, model loss 26.7727, LR: 0.0000100000
真实数据: 记者检索出如下文字:
结果显示: 习者救去出加下交争:
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 35.1478, LR: 0.0000100000
真实数据: 野一定是“泡店族”推
结果显示: 对一是是“论店旅”
Epoch 0 Step 000700, model loss 9.6917, LR: 0.0000100000
真实数据: 疾病可使药物对机体的
结果显示: 戏神可使药物对机体的
Epoch 0 Step 000800, model loss 11.5448, LR: 0.0000100000
真实数据: 作有序，”锡九诺而行
结果显示: 作有序，”乐力帝而行
Epoch 0 Step 000900, model loss 20.0649, LR: 0.0000100000
真实数据: 否则，余师长向上级报
结果显示: 司则:余年长向上经新
Epoch 0 Step 001000, model loss 10.7383, LR: 0.0000100000
真实数据: 军就从战场上直接去寻
结果显示: 乐就从战场上直接去导
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 3.3021, LR: 0.0000100000
真实数据: 于目前中国传媒业产业
结果显示: 于目前中国传媒业产业
Epoch 0 Step 001200, model loss 39.3044, LR: 0.0000100000
真实数据: 频繁的报道，是不矛盾
结果显示: 级露的报道，是不承周
Epoch 0 Step 001300, model loss 0.3359, LR: 0.0000100000
真实数据: ?当有人介入了你和男
结果显示: ?当有人介入了你和男
Epoch 0 Step 001400, model loss 9.9139, LR: 0.0000100000
真实数据: 适用群:华为内部网络
结果显示: 通用那:年为内部网络
Epoch 0 Step 001500, model loss 1.3848, LR: 0.0000100000
真实数据: 先与刚好与中国的十一
结果显示: 先与刚好与中国的十一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 7.7037, LR: 0.0000100000
真实数据: 和她开开玩笑，有人曾
结果显示: 和她开开现笑，有人善
Epoch 0 Step 001700, model loss 22.5111, LR: 0.0000100000
真实数据: 一些小型的客栈，“师
结果显示: 一些小要的客譬，“甲
Epoch 0 Step 001800, model loss 2.8642, LR: 0.0000100000
真实数据: 两个人达到了一致的结
结果显示: 两个人达到了一到的结
Epoch 0 Step 001900, model loss 2.2715, LR: 0.0000100000
真实数据: 0如数上交后，11月
结果显示: 0如数上交后，11月
Epoch 0 Step 002000, model loss 33.1205, LR: 0.0000100000
真实数据: “谋杀”了一个闭眼者
结果显示: “讲秀”了一个自取老
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 2.4426, LR: 0.0000100000
真实数据: 气股份论坛)开盘后的
结果显示: 气股份论坛)开盘后的
Epoch 0 Step 002200, model loss 11.1889, LR: 0.0000100000
真实数据: 方的新装备正在把科幻
结果显示: 方的新装备正在招科纪
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E94016E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 29.6981, LR: 0.0000100000
真实数据: 本书，吃喝嫖赌过度的
结果显示: 本书，吃甲量紧过度的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 16.0276, LR: 0.0000100000
真实数据: 为清廷主力，觉得花8
结果显示: 为满建主力，觉得花8
Epoch 0 Step 000200, model loss 4.6999, LR: 0.0000100000
真实数据: 利润60%以上。并使
结果显示: 利润60%以上。并使
Epoch 0 Step 000300, model loss 1.1271, LR: 0.0000100000
真实数据: 也在1983年告别了
结果显示: 也在1983年告别了
Epoch 0 Step 000400, model loss 0.1112, LR: 0.0000100000
真实数据: ebestoptic
结果显示: ebestoptic
Epoch 0 Step 000500, model loss 6.6273, LR: 0.0000100000
真实数据: ttention1、
结果显示: ttentiomnl、
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 9.5606, LR: 0.0000100000
真实数据: asyncmoded
结果显示: 8syn.Gmoded
Epoch 0 Step 000700, model loss 9.7748, LR: 0.0000100000
真实数据: 前有30家即将开业酒
结果显示: 询有30家即将开业源
Epoch 0 Step 000800, model loss 0.6045, LR: 0.0000100000
真实数据: 给每位参与者发了11
结果显示: 给每位参与者发了11
Epoch 0 Step 000900, model loss 9.6373, LR: 0.0000100000
真实数据: 外游客首次突破百万大
结果显示: 外游客前次实下万大
Epoch 0 Step 001000, model loss 35.5351, LR: 0.0000100000
真实数据: 是滋生腐败的体制性土
结果显示: 是游生股则的体制性主
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 8.2477, LR: 0.0000100000
真实数据: 北京铁路局介绍，怎生
结果显示: 北京铁路同介统，怎生
Epoch 0 Step 001200, model loss 1.3389, LR: 0.0000100000
真实数据: 们就充分地保留了病人
结果显示: 们就充分地保留了病人
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001A21B8DD4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 6.8530, LR: 0.0000100000
真实数据: 所需经费由财政部按月
结果显示: 所需经费由财政部接月
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.0261, LR: 0.0000100000
真实数据: 四小时以上的则占了百
结果显示: 四小时以上的则占了百
Epoch 0 Step 000200, model loss 0.5104, LR: 0.0000100000
真实数据: 成1730.78亿元
结果显示: 成1730.78亿元
Epoch 0 Step 000300, model loss 4.0506, LR: 0.0000100000
真实数据: 只是道11.2979
结果显示: 只是道11.279
Epoch 0 Step 000400, model loss 1.8562, LR: 0.0000100000
真实数据: 一则来自英国的报道却
结果显示: 一则来自英国的报造却
Epoch 0 Step 000500, model loss 25.2025, LR: 0.0000100000
真实数据: 整场比赛，艾曰:同时
结果显示: 益场比赛，头日:属时
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 10.2295, LR: 0.0000100000
真实数据: 比亚里兹最热门的一个
结果显示: 比亚里意最热门的一个
Epoch 0 Step 000700, model loss 39.0777, LR: 0.0000100000
真实数据: 之后皮肤变得很滑很滑
结果显示: 之后度败交得很清很清
Epoch 0 Step 000800, model loss 12.3134, LR: 0.0000100000
真实数据: 锐虑，事实上，这些活
结果显示: 说应，事实上，这些活
Epoch 0 Step 000900, model loss 26.7934, LR: 0.0000100000
真实数据: 的林彪出逃事件?毛泽
结果显示: 的林就出进事件?毛聆
Epoch 0 Step 001000, model loss 14.1700, LR: 0.0000100000
真实数据: 利用空闲时间接几个散
结果显示: 利用空国时间接几个船
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 36.4241, LR: 0.0000100000
真实数据: 各种口径舰炮发射了四
结果显示: 各种口遂陪地发对了曰
Epoch 0 Step 001200, model loss 9.0784, LR: 0.0000100000
真实数据: 怪就怪在越南那个鬼地
结果显示: 怪就怪在却南那个奥地
Epoch 0 Step 001300, model loss 11.3172, LR: 0.0000100000
真实数据: 那天晚上我考虑了很多
结果显示: 那天略上我考虑了很多
Epoch 0 Step 001400, model loss 15.3889, LR: 0.0000100000
真实数据: 如去北京探索文化旅游
结果显示: 如去北京标去文化族游
Epoch 0 Step 001500, model loss 21.1216, LR: 0.0000100000
真实数据: pusicStudi
结果显示: PUMsieStdti
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 26.7361, LR: 0.0000100000
真实数据: 但他用完美的发挥彻底
结果显示: 供他用完具的发样将城
Epoch 0 Step 001700, model loss 12.4871, LR: 0.0000100000
真实数据: 国内旅游交易会成为世
结果显示: 国内热塞文易会成为世
Epoch 0 Step 001800, model loss 18.7405, LR: 0.0000100000
真实数据: 前，当然，“婢幸不死
结果显示: 前，当然，“样章不石
Epoch 0 Step 001900, model loss 24.8088, LR: 0.0000100000
真实数据: 室供之。离笼子远远的
结果显示: 空供之。高给子远远的
Epoch 0 Step 002000, model loss 19.2953, LR: 0.0000100000
真实数据: 文化派奏的是亡国之声
结果显示: 文化酒秀的是亡国之声
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 16.3966, LR: 0.0000100000
真实数据: 族，如发生失(泄)密
结果显示: 就，如发生失(薄)曾
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002850DE1E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 8.0631, LR: 0.0000100000
真实数据: 空姐外形条件的要求都
结果显示: 空绍外形条件的要求都
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 3.4719, LR: 0.0000100000
真实数据: 道，在完成指标的情况
结果显示: 道，在完成指标的情况
Epoch 0 Step 000200, model loss 8.6171, LR: 0.0000100000
真实数据: 们的这个初级目标也就
结果显示: 们的这个初级日初也海
Epoch 0 Step 000300, model loss 18.4372, LR: 0.0000100000
真实数据: 虑、百无聊赖等负面情
结果显示: 感、百无聘较等负面情
Epoch 0 Step 000400, model loss 10.3349, LR: 0.0000100000
真实数据: 了让同学们对自己投递
结果显示: 了让同学们对自己投进
Epoch 0 Step 000500, model loss 11.4230, LR: 0.0000100000
真实数据: 球场顿时成了一片白色
结果显示: 球场权时成了一片自色
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 13.8679, LR: 0.0000100000
真实数据: 果擎着一将对近两年安
结果显示: 果军着一将对近两年安
Epoch 0 Step 000700, model loss 55.3916, LR: 0.0000100000
真实数据: 十六岁不能知牝牡，思
结果显示: 十大罗不游达，既
Epoch 0 Step 000800, model loss 4.4373, LR: 0.0000100000
真实数据: 女子也。博览会期间价
结果显示: 女子也。博终会期间价
Epoch 0 Step 000900, model loss 0.5925, LR: 0.0000100000
真实数据: 06年“五一”黄金周
结果显示: 06年“五一”黄金周
Epoch 0 Step 001000, model loss 13.2405, LR: 0.0000100000
真实数据: 了解,二是针对我国农
结果显示: 了解.二是计对我国农
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 7.4448, LR: 0.0000100000
真实数据: 乎?”一些著名国有化
结果显示: 乎?”一些者名国有化
Epoch 0 Step 001200, model loss 30.2994, LR: 0.0000100000
真实数据: 售公司租赁深圳市经济
结果显示: 像公司截异深斯市经济
Epoch 0 Step 001300, model loss 23.4510, LR: 0.0000100000
真实数据: 而然地”拓宽、“顺理
结果显示: 而然地”招责、“际理
Epoch 0 Step 001400, model loss 0.2398, LR: 0.0000100000
真实数据: 示:上面盖的是同一个
结果显示: 示:上面盖的是同一个
Epoch 0 Step 001500, model loss 1.4690, LR: 0.0000100000
真实数据: 表示:随着义务教育的
结果显示: 表示:随着义务教育的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 38.3615, LR: 0.0000100000
真实数据: 一方面又要求柬埔寨臣
结果显示: 一方面又要求求域素医
Epoch 0 Step 001700, model loss 43.2481, LR: 0.0000100000
真实数据: 入难以维持温饱的贫困
结果显示: 入难以峰持源受的受图
Epoch 0 Step 001800, model loss 14.4121, LR: 0.0000100000
真实数据: 妈因为知情而遭到父亲
结果显示: 她因为知情而遵到父案
Epoch 0 Step 001900, model loss 3.8110, LR: 0.0000100000
真实数据: 校被确定为全国重点大
结果显示: 校被香定为全国重点大
Epoch 0 Step 002000, model loss 7.4352, LR: 0.0000100000
真实数据: 利润:也脱下了高价的
结果显示: 利昨:也船下了高价的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 11.6410, LR: 0.0000100000
真实数据: 列楼市调控政策在地方
结果显示: 列模市调换政策在地方
Epoch 0 Step 002200, model loss 3.0617, LR: 0.0000100000
真实数据: 的“大飞机项目论证组
结果显示: 的“大飞机项曰论证细
Epoch 0 Step 002300, model loss 58.3342, LR: 0.0000100000
真实数据: 而胡萝卜中的胡萝卜素
结果显示: 而故整中的故多常
Epoch 0 Step 002400, model loss 4.2555, LR: 0.0000100000
真实数据: 还是为了提高自身素质
结果显示: 还是为了提高自身素质
Epoch 0 Step 002500, model loss 21.7547, LR: 0.0000100000
真实数据: 煽风点火的政治人物却
结果显示: 量风点火的政治人特却
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 24.8391, LR: 0.0000100000
真实数据: "呕吐的对象"第3页
结果显示: “呢过的对制"第3页
Epoch 0 Step 002700, model loss 19.2050, LR: 0.0000100000
真实数据: 地提出了“向污染宣战
结果显示: 地提出了“向河染宣修
Epoch 0 Step 002800, model loss 2.7696, LR: 0.0000100000
真实数据: 义和团的研究与评价分
结果显示: 义和团的研究与评价分
Epoch 0 Step 002900, model loss 34.0702, LR: 0.0000100000
真实数据: 如今竟连老巢都给消灭
结果显示: 如今竟连者增都给消双
Epoch 0 Step 003000, model loss 10.8638, LR: 0.0000100000
真实数据: 少年负义，遂俱归。如
结果显示: 少年负义，道仍归。如
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 13.7815, LR: 0.0000100000
真实数据: 我出差，我拥有一颗平
结果显示: 我出差，我捉有一罪平
Epoch 0 Step 003200, model loss 33.0213, LR: 0.0000100000
真实数据: 大学出版社严蔚敏教授
结果显示: 大学出版社严总舱教接
Epoch 0 Step 003300, model loss 11.1228, LR: 0.0000100000
真实数据: 一千多年前，完善宏观
结果显示: 一千多年前，完善法观
Epoch 0 Step 003400, model loss 7.9632, LR: 0.0000100000
真实数据: 实企业的安全生产责任
结果显示: 实企业的安全生产去任
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000226857AD4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 20.0538, LR: 0.0000100000
真实数据: 都仪式”就在国府礼堂
结果显示: 都依式”就在国府有帝
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 5.1405, LR: 0.0000100000
真实数据: 是做不到的。不会去为
结果显示: 是潜不到的。不会去为
Epoch 0 Step 000200, model loss 0.8895, LR: 0.0000100000
真实数据: 还有什么比用进球作为
结果显示: 还有什么比用进球作为
Epoch 0 Step 000300, model loss 1.4707, LR: 0.0000100000
真实数据: ，30年来第一次杀进
结果显示: ，30年来第一次者进
Epoch 0 Step 000400, model loss 0.5607, LR: 0.0000100000
真实数据: 不得已用笔写字的时候
结果显示: 不得已用笔写字的时候
Epoch 0 Step 000500, model loss 0.0628, LR: 0.0000100000
真实数据: 发布《上市公司证券发
结果显示: 发布《上市公司证券发
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 2.6042, LR: 0.0000100000
真实数据: 日名将孙立人对这支美
结果显示: 日名将孙立人对这支美
Epoch 0 Step 000700, model loss 8.3747, LR: 0.0000100000
真实数据: 并运用自己的经营技巧
结果显示: 并适用自已的经营技酬
Epoch 0 Step 000800, model loss 13.4633, LR: 0.0000100000
真实数据: 00，男人们在婚姻中
结果显示: 00，男人们在解插中
Epoch 0 Step 000900, model loss 0.6985, LR: 0.0000100000
真实数据: 了一部分最有创意的人
结果显示: 了一部分最有创意的人
Epoch 0 Step 001000, model loss 16.8149, LR: 0.0000100000
真实数据: ，王治郅与队友在练习
结果显示: ，王治到与队友在练习
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 8.9183, LR: 0.0000100000
真实数据: 级建筑设计单位开始选
结果显示: 级建等设计单位开始选
Epoch 0 Step 001200, model loss 47.7076, LR: 0.0000100000
真实数据: 色笔挺的衬衫，湖北随
结果显示: 色名拉的神精，海北随
Epoch 0 Step 001300, model loss 14.7007, LR: 0.0000100000
真实数据: 风格是这类图书的基本
结果显示: 反格是这妻u书的基本
Epoch 0 Step 001400, model loss 5.5685, LR: 0.0000100000
真实数据: 当年，以流浪者自己来
结果显示: 当年，以流癌者自己来
Epoch 0 Step 001500, model loss 4.9514, LR: 0.0000100000
真实数据: 与病毒的恶性转化有关
结果显示: 与病毒的恶性转化有关
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 30.9146, LR: 0.0000100000
真实数据: 另出肴俎，新方案中理
结果显示: 男出希超，新方案中理
Epoch 0 Step 001700, model loss 6.0180, LR: 0.0000100000
真实数据: 却没有时间把题目做完
结果显示: 却没有时间把题目做究
Epoch 0 Step 001800, model loss 36.5437, LR: 0.0000100000
真实数据: 在墙下百丈深的深渊中
结果显示: 在标下西文深的洲中
Epoch 0 Step 001900, model loss 6.3619, LR: 0.0000100000
真实数据: 是世界上破坏生态平衡
结果显示: 是世界上破杯生态平衡
Epoch 0 Step 002000, model loss 3.3915, LR: 0.0000100000
真实数据: 时间内通过上述系统行
结果显示: 时间内通过上送系统行
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 12.1194, LR: 0.0000100000
真实数据: dy和招租单位论理也
结果显示: 由和已程单位论理也
Epoch 0 Step 002200, model loss 3.5947, LR: 0.0000100000
真实数据: 也是第二个五连冠，第
结果显示: 也是第二个五连酒，第
Epoch 0 Step 002300, model loss 4.2331, LR: 0.0000100000
真实数据: 医生提醒乘机出行的人
结果显示: 医生提配乘机出行的人
Epoch 0 Step 002400, model loss 17.5626, LR: 0.0000100000
真实数据: 和霍拉斯-格兰特也绝
结果显示: 和看拉斯一格坚特也先
Epoch 0 Step 002500, model loss 1.1812, LR: 0.0000100000
真实数据: 的协助下制定了合适的
结果显示: 的协助下制定了合适的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 7.1636, LR: 0.0000100000
真实数据: U）近日宣布组成合并
结果显示: r）近日宣布组成合并
Epoch 0 Step 002700, model loss 14.2698, LR: 0.0000100000
真实数据: 重头行业，但根据道琼
结果显示: 重头行业，但根据道球
Epoch 0 Step 002800, model loss 10.2648, LR: 0.0000100000
真实数据: 世界上也没有一个单靠
结果显示: 世界上也没有一个单
Epoch 0 Step 002900, model loss 21.9882, LR: 0.0000100000
真实数据: 殊不知抱着这样的思想
结果显示: 那不起把着这择的思想
Epoch 0 Step 003000, model loss 13.5934, LR: 0.0000100000
真实数据: 哩!加装计时运行控制
结果显示: 里!加装计时运行接制
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 1.9390, LR: 0.0000100000
真实数据: 年后，这些监听站存有
结果显示: 年后，这些监听站存有
Epoch 0 Step 003200, model loss 21.5035, LR: 0.0000100000
真实数据: 特价机打造价格盆地盛
结果显示: 特价机打造价格贫地僻
Epoch 0 Step 003300, model loss 18.0283, LR: 0.0000100000
真实数据: 下去蹲?此话不与行者
结果显示: 下去跨?此话不与行者
Epoch 0 Step 003400, model loss 8.5953, LR: 0.0000100000
真实数据: ”国王道:心窃异之，
结果显示: ”国王道:心富异之，
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001B2D9CC04C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.6778, LR: 0.0000100000
真实数据: 工作实行计算机远程网
结果显示: 工实行计算机还程网
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 36.9138, LR: 0.0000100000
真实数据: 瓒绪总司令部署集团军
结果显示: 估总司令部玉集回平
Epoch 0 Step 000200, model loss 24.9025, LR: 0.0000100000
真实数据: 痰去积，解决了生产加
结果显示: 残去积，解次了生产加
Epoch 0 Step 000300, model loss 1.6137, LR: 0.0000100000
真实数据: 几位要求退款的求职人
结果显示: 几位要求退款的求职人
Epoch 0 Step 000400, model loss 2.3785, LR: 0.0000100000
真实数据: 它代表着当今世界的发
结果显示: 它代表着当今世界的发
Epoch 0 Step 000500, model loss 5.4436, LR: 0.0000100000
真实数据: 皮，乐意为她安排一切
结果显示: 应，乐意为她支排一切
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 6.6448, LR: 0.0000100000
真实数据: 着接触社会也得硬着头
结果显示: 着接胜社会也得硬着头
Epoch 0 Step 000700, model loss 4.4428, LR: 0.0000100000
真实数据: 一层意思对应一个原理
结果显示: 一屋意恩对应一个原理
Epoch 0 Step 000800, model loss 53.6381, LR: 0.0000100000
真实数据: 罗旺斯的葡萄园和葡萄
结果显示: 男旧斯的痛薪固和薪
Epoch 0 Step 000900, model loss 2.4472, LR: 0.0000100000
真实数据: 贝，记者在周庄景区看
结果显示: 贝，记者在周庄景区看
Epoch 0 Step 001000, model loss 1.1352, LR: 0.0000100000
真实数据: 大利亚旅游开始向内地
结果显示: 大利亚旅游开始向内地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 24.9318, LR: 0.0000100000
真实数据: 搜狐直播员:科拉迪左
结果显示: 换欲直密员:科．达左
Epoch 0 Step 001200, model loss 9.0722, LR: 0.0000100000
真实数据: 曰:对美腿有百分百的
结果显示: 曰:对美脑有百分百的
Epoch 0 Step 001300, model loss 1.6623, LR: 0.0000100000
真实数据: ”下，是主席的指示。
结果显示: ”下，是主席的指示。
Epoch 0 Step 001400, model loss 28.5488, LR: 0.0000100000
真实数据: 齿表面有牙菌斑、牙结
结果显示: 世表面有牙前班、牙结
Epoch 0 Step 001500, model loss 5.0468, LR: 0.0000100000
真实数据: 增长幅度为6.73%
结果显示: 增长幅度为6.7%
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 16.6346, LR: 0.0000100000
真实数据: 得下炮――自然也可以
结果显示: 得下凭-自然也可以
Epoch 0 Step 001700, model loss 1.4805, LR: 0.0000100000
真实数据: 经公司董事会提名委员
结果显示: 经公司董事会提名委员
Epoch 0 Step 001800, model loss 4.4084, LR: 0.0000100000
真实数据: 调整数。而是创造各种
结果显示: 调整数。而是创造各种
Epoch 0 Step 001900, model loss 0.9901, LR: 0.0000100000
真实数据: 比方说化疗有一些化疗
结果显示: 比方说化疗有一些化疗
Epoch 0 Step 002000, model loss 20.5795, LR: 0.0000100000
真实数据: 原来那是夜间游荡的鹿
结果显示: 原来那是夜间游营的盾
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.3452, LR: 0.0000100000
真实数据: 、回家做一次饭，联系
结果显示: 、回家做一次饭，联系
Epoch 0 Step 002200, model loss 42.6696, LR: 0.0000100000
真实数据: 经过若干年的艰辛谈判
结果显示: 每老干年的职章读我
Epoch 0 Step 002300, model loss 3.5825, LR: 0.0000100000
真实数据: 010年开始建造新型
结果显示: 010年开始建违新型
Epoch 0 Step 002400, model loss 27.3955, LR: 0.0000100000
真实数据: 没有延迟Vista操
结果显示: 没有延近V能排
Epoch 0 Step 002500, model loss 18.8960, LR: 0.0000100000
真实数据: 每个工作者在面临变化
结果显示: 去个工护者在面临穿化
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 5.7490, LR: 0.0000100000
真实数据: 生?填报志愿设分数级
结果显示: 生?城报志愿设分数级
Epoch 0 Step 002700, model loss 2.7974, LR: 0.0000100000
真实数据: 已婚男人的话不可不信
结果显示: 已舰男人的话不可不信
Epoch 0 Step 002800, model loss 22.4031, LR: 0.0000100000
真实数据: 免疫功能下降，四下墙
结果显示: 免妄功能下降，四下培
Epoch 0 Step 002900, model loss 11.8868, LR: 0.0000100000
真实数据: 术部决定让王琴主持会
结果显示: 术部决定让王与主持会
Epoch 0 Step 003000, model loss 4.1287, LR: 0.0000100000
真实数据: 、同国家发展利益相适
结果显示: 、同国家发展利益相适
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 13.2422, LR: 0.0000100000
真实数据: 的一声道:黄梦国子
结果显示: 的一声道:资酒为国子
Epoch 0 Step 003200, model loss 20.6970, LR: 0.0000100000
真实数据: 南京大屠杀此刻已时过
结果显示: 南京大架需此站己时过
Epoch 0 Step 003300, model loss 15.7761, LR: 0.0000100000
真实数据: 还需提供户口簿原件、
结果显示: 还需提做户口游原件、
Epoch 0 Step 003400, model loss 6.0289, LR: 0.0000100000
真实数据: 做到环保安全。前景美
结果显示: 你到环保安全。前射美
Epoch 0 Step 003500, model loss 11.0597, LR: 0.0000100000
真实数据: 其实如同婚恋自由一样
结果显示: 其实如网临忠自由一样
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003600, model loss 3.3553, LR: 0.0000100000
真实数据: 说了什么有价值的东西
结果显示: 说了牛么有价值的东西
Epoch 0 Step 003700, model loss 4.0294, LR: 0.0000100000
真实数据: 重新回到了市场。营养
结果显示: 重新回到了市场。营并
Epoch 0 Step 003800, model loss 0.8365, LR: 0.0000100000
真实数据: 司的T型车功不可没之
结果显示: 司的T型车功不可没之
Epoch 0 Step 003900, model loss 4.4729, LR: 0.0000100000
真实数据: 尽管比赛过程并不精彩
结果显示: 尽管比赛过程并不精轻
Epoch 0 Step 004000, model loss 0.6735, LR: 0.0000100000
真实数据: 论是教职员工还是学生
结果显示: 论是教职员工还是学生
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000292AAC9E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.7843, LR: 0.0000100000
真实数据: 些本来很简单的训练课
结果显示: 些本来很简单的训绩课
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 30.9726, LR: 0.0000100000
真实数据: 提出了“全面报酬体系
结果显示: 提出了”如面据《的
Epoch 0 Step 000200, model loss 12.6464, LR: 0.0000100000
真实数据: 业务光网络节点（OM
结果显示: 业务先网络节点(oM
Epoch 0 Step 000300, model loss 1.8176, LR: 0.0000100000
真实数据: 就是书中某一章节的题
结果显示: 就是书中某一章节的题
Epoch 0 Step 000400, model loss 4.7434, LR: 0.0000100000
真实数据: 影和电视剧在朝鲜也大
结果显示: 影和电视居在朝鲜也大
Epoch 0 Step 000500, model loss 0.9146, LR: 0.0000100000
真实数据: 岁的他们将成为中国冲
结果显示: 岁的他们将成为中国冲
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 5.5115, LR: 0.0000100000
真实数据: 0583)最近三年连
结果显示: 0583)最近三年适
Epoch 0 Step 000700, model loss 2.0960, LR: 0.0000100000
真实数据: 民主具有鲜明的阶级性
结果显示: 民主具有鲜明的价阶级性
Epoch 0 Step 000800, model loss 3.2789, LR: 0.0000100000
真实数据: 。建立、健全移动不良
结果显示: 。建立、修全移动不良
Epoch 0 Step 000900, model loss 0.2930, LR: 0.0000100000
真实数据: 因而成为“新文化运动
结果显示: 因而成为“新文化运动
Epoch 0 Step 001000, model loss 7.7186, LR: 0.0000100000
真实数据: “凉茶本质上也是中药
结果显示: “减茶本质上也是中药
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1290, LR: 0.0000100000
真实数据: .4385201.8
结果显示: .4385201.8
Epoch 0 Step 001200, model loss 0.1119, LR: 0.0000100000
真实数据: lotofmedic
结果显示: lotofmedic
Epoch 0 Step 001300, model loss 0.8286, LR: 0.0000100000
真实数据: 为我想我有热情和积极
结果显示: 为我想我有热情和积极
Epoch 0 Step 001400, model loss 16.1259, LR: 0.0000100000
真实数据: 昌置业给予200万元
结果显示: 段置业给予200万元
Epoch 0 Step 001500, model loss 24.9224, LR: 0.0000100000
真实数据: 有期徒刑、拘役或者管
结果显示: 有期徒利、往或者管
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 19.9247, LR: 0.0000100000
真实数据: 固无休息，却说他兄弟
结果显示: 副无作息，都说他兄笔
Epoch 0 Step 001700, model loss 5.7527, LR: 0.0000100000
真实数据: 公正性、透明性均受到
结果显示: 公正性、适明性均受到
Epoch 0 Step 001800, model loss 28.9628, LR: 0.0000100000
真实数据: 知道这点。沈洁肯定地
结果显示: 知道这点。流活，一必
Epoch 0 Step 001900, model loss 10.2501, LR: 0.0000100000
真实数据: 则要花上整整18年!
结果显示: 则要花上整缈亿8年厂
Epoch 0 Step 002000, model loss 2.4212, LR: 0.0000100000
真实数据: 自主把改变自己身份地
结果显示: 自主把改变自己身份地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.5564, LR: 0.0000100000
真实数据: 负担甚重的一家之长了
结果显示: 负担甚重的一家之长了
Epoch 0 Step 002200, model loss 5.5937, LR: 0.0000100000
真实数据: 素食主义者对动物目前
结果显示: 来食主义者对动物目前
Epoch 0 Step 002300, model loss 3.6287, LR: 0.0000100000
真实数据: 这份报告指出，传统中
结果显示: 这防报告指出，传统中
Epoch 0 Step 002400, model loss 10.8123, LR: 0.0000100000
真实数据: 事诉讼法学自学考试大
结果显示: 事诉设法学自学考试大
Epoch 0 Step 002500, model loss 6.0262, LR: 0.0000100000
真实数据: 迅速抢占着当地招聘市
结果显示: 迅速抢占着当地把聘市
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 5.9210, LR: 0.0000100000
真实数据: 这样遭遇的求职者并不
结果显示: 这样迅遇的求职者并不
Epoch 0 Step 002700, model loss 4.0081, LR: 0.0000100000
真实数据: 县域经济发展中金融服
结果显示: 县具域经济发展中金融服
Epoch 0 Step 002800, model loss 12.4754, LR: 0.0000100000
真实数据: 子他赚，第02018
结果显示: 子借是，第02018
Epoch 0 Step 002900, model loss 14.2377, LR: 0.0000100000
真实数据: 不是秦始皇的雄才大略
结果显示: 不是来始皇的推才大略
Epoch 0 Step 003000, model loss 25.4747, LR: 0.0000100000
真实数据: 影片时出现胸痛、心悸
结果显示: 影片时出现朋痛、心性
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 7.1247, LR: 0.0000100000
真实数据: 她们的最后一个镜头中
结果显示: 她们的最后一个修头中
Epoch 0 Step 003200, model loss 0.9044, LR: 0.0000100000
真实数据: 个问题、一个问题地来
结果显示: 个问题、一个问题地来
Epoch 0 Step 003300, model loss 18.4718, LR: 0.0000100000
真实数据: 体验和相关的辅助检查
结果显示: 体验和相关的刺除模意
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002751641E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 6.1394, LR: 0.0000100000
真实数据: 、性能和潜力等一系列
结果显示: 、性能和清力等一系到
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 8.1967, LR: 0.0000100000
真实数据: 询、诊断和治疗服务系
结果显示: 询、咨断和治疗愿务系
Epoch 0 Step 000200, model loss 4.9789, LR: 0.0000100000
真实数据: 量器材、零备件的国产
结果显示: 量需材、零备件的国产
Epoch 0 Step 000300, model loss 3.2381, LR: 0.0000100000
真实数据: 看台也进行了一些调整
结果显示: 有台也进行了一些词整
Epoch 0 Step 000400, model loss 9.4683, LR: 0.0000100000
真实数据: 律活塞队),又欲夺其
结果显示: 律活塞队)又欲诸其
Epoch 0 Step 000500, model loss 20.3619, LR: 0.0000100000
真实数据: 据了解，沁着头睡，”
结果显示: 据了解，冲着头照，“
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 6.8311, LR: 0.0000100000
真实数据: 形成亲亲尊尊的人才观
结果显示: 形成亲亲革草的人才观
Epoch 0 Step 000700, model loss 26.0224, LR: 0.0000100000
真实数据: 、"九&#8226;
结果显示: 、“九除弗226;
Epoch 0 Step 000800, model loss 0.3990, LR: 0.0000100000
真实数据: 在微软公司良好的企业
结果显示: 在微软公司良好的企业
Epoch 0 Step 000900, model loss 3.9671, LR: 0.0000100000
真实数据: 教以语言，且仍在下降
结果显示: 教以语言，且在下降
Epoch 0 Step 001000, model loss 8.0375, LR: 0.0000100000
真实数据: 率比去年12月再度降
结果显示: 幸比去年12月再度许
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 6.2954, LR: 0.0000100000
真实数据: 有特色的应该是使用的
结果显示: 有非色的应该是使取的
Epoch 0 Step 001200, model loss 0.7405, LR: 0.0000100000
真实数据: 较为有利的外部经济环
结果显示: 较为有利的外部经济环
Epoch 0 Step 001300, model loss 0.0149, LR: 0.0000100000
真实数据: 人士表示，1945年
结果显示: 人士表示，1945年
Epoch 0 Step 001400, model loss 6.1549, LR: 0.0000100000
真实数据: 谢谢!管理人员是禁止
结果显示: 谢进!管理人员是禁止
Epoch 0 Step 001500, model loss 42.6233, LR: 0.0000100000
真实数据: 欷[，“是只合耦婢子
结果显示: 影映，“是只合抛舞子
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 35.9798, LR: 0.0000100000
真实数据: 磁场来干扰和躲避敌方
结果显示: 营场来于找和源避动方
Epoch 0 Step 001700, model loss 6.5636, LR: 0.0000100000
真实数据: 人人都有优缺点，小编
结果显示: 人人有优缺点，小编
Epoch 0 Step 001800, model loss 16.7954, LR: 0.0000100000
真实数据: 继续在机关里“向上爬
结果显示: 维续在机关里“向上职
Epoch 0 Step 001900, model loss 14.5617, LR: 0.0000100000
真实数据: 安事业;王鸵幌蛟诤
结果显示: 实事业;王姑一6在后
Epoch 0 Step 002000, model loss 9.5050, LR: 0.0000100000
真实数据: ，家长在选择出行线路
结果显示: ，家长在选挥出行线脱
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 16.8257, LR: 0.0000100000
真实数据: 像老鼠爱大米．进球被
结果显示: 像者际爱大米:进球被
Epoch 0 Step 002200, model loss 5.1728, LR: 0.0000100000
真实数据: 旺盛，现在政府财政越
结果显示: 叫盛，现在政府财政越
Epoch 0 Step 002300, model loss 4.6866, LR: 0.0000100000
真实数据: 都是向对方发出不诚实
结果显示: 都是向对方发出不构实
Epoch 0 Step 002400, model loss 4.7489, LR: 0.0000100000
真实数据: 怕自己的改变，听她说
结果显示: 情自己的改变，听她说
Epoch 0 Step 002500, model loss 18.7867, LR: 0.0000100000
真实数据: 7号楼及配套裙房工程
结果显示: 7号模及配套福房工程
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 17.5249, LR: 0.0000100000
真实数据: xcessive)甚
结果显示: Weessi心e)域
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001A3BD67D4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 18.0337, LR: 0.0000100000
真实数据: 是一只深藏不露的钛金
结果显示: 是一只深就不露的钱金
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 19.8973, LR: 0.0000100000
真实数据: 体称为“搅局春交会”
结果显示: 你称为“类局春交会”
Epoch 0 Step 000200, model loss 2.9180, LR: 0.0000100000
真实数据: ，西安市西五路83号
结果显示: ，强安市西五路83号
Epoch 0 Step 000300, model loss 1.7871, LR: 0.0000100000
真实数据: 那里再下下功夫，抗直
结果显示: 那里再下下功夫，抗直
Epoch 0 Step 000400, model loss 36.5049, LR: 0.0000100000
真实数据: 好。在孤儿院的单调环
结果显示: 城。在稳几的单粗司
Epoch 0 Step 000500, model loss 19.2208, LR: 0.0000100000
真实数据: 样说，而大陪审团人多
结果显示: 择说，而大陆章图人多
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 18.6772, LR: 0.0000100000
真实数据: 怎么把山借与妖魔压他
结果显示: 忽么把山借与数度庄他
Epoch 0 Step 000700, model loss 0.5712, LR: 0.0000100000
真实数据: 平均上调幅度将达20
结果显示: 平均上调幅度将达20
Epoch 0 Step 000800, model loss 7.0969, LR: 0.0000100000
真实数据: 打好后面的联赛进行了
结果显示: 打好后面的驻赛进行了
Epoch 0 Step 000900, model loss 8.7827, LR: 0.0000100000
真实数据: 财产、收支上互相隐瞒
结果显示: 财产、收支上互相险满
Epoch 0 Step 001000, model loss 1.1938, LR: 0.0000100000
真实数据: 听力、口语完全没有练
结果显示: 听力、口语完全没有练
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.3979, LR: 0.0000100000
真实数据: 业如此发展，皆为势家
结果显示: 业如此发展，皆为势家
Epoch 0 Step 001200, model loss 20.1111, LR: 0.0000100000
真实数据: 尔干看成是可以肆意宰
结果显示: 尔千看成是可以述意字
Epoch 0 Step 001300, model loss 5.9857, LR: 0.0000100000
真实数据: 致的阴道流血比平时月
结果显示: 致的防道流血比平时凡
Epoch 0 Step 001400, model loss 9.9954, LR: 0.0000100000
真实数据: 根本就没有什么“现金
结果显示: 根本就有什么“现金
Epoch 0 Step 001500, model loss 10.9031, LR: 0.0000100000
真实数据: 息肩桥上，上周日联赛
结果显示: 息属上，上周日联赛
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 15.8300, LR: 0.0000100000
真实数据: 起点，杨挺伟:在中国
结果显示: 起点，杨拒体:在中国
Epoch 0 Step 001700, model loss 14.6125, LR: 0.0000100000
真实数据: 可以减肥，围观群众都
结果显示: 可以减胜，固观群众都
Epoch 0 Step 001800, model loss 8.8616, LR: 0.0000100000
真实数据: 能挽救第73军。我觉
结果显示: 能择救第73军。我觉
Epoch 0 Step 001900, model loss 0.6785, LR: 0.0000100000
真实数据: 村药品“两网”建设的
结果显示: 村药品“两网”建设的
Epoch 0 Step 002000, model loss 19.3301, LR: 0.0000100000
真实数据: 却有着商人般的经营头
结果显示: 和有着音人横的经管为
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0578, LR: 0.0000100000
真实数据: 主招生考生优先录取办
结果显示: 主招生考生优先录取办
Epoch 0 Step 002200, model loss 11.6981, LR: 0.0000100000
真实数据: 告之，又召樊来，归自
结果显示: 告之，又召莫来，归自
Epoch 0 Step 002300, model loss 34.2274, LR: 0.0000100000
真实数据: 恨的子弹狠狠射向敌人
结果显示: 做的子弹狐数射向敌人
Epoch 0 Step 002400, model loss 8.6680, LR: 0.0000100000
真实数据: 属汉，兰帕德（切尔西
结果显示: 属汉，兰忙德（切尔西
Epoch 0 Step 002500, model loss 0.2661, LR: 0.0000100000
真实数据: 1994～1998年
结果显示: 1994～1998年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 14.9281, LR: 0.0000100000
真实数据: 请把忧虑暂时放在一边
结果显示: 请把试志暂时放在一达
Epoch 0 Step 002700, model loss 0.2424, LR: 0.0000100000
真实数据: 人心，也就是说每10
结果显示: 人心，也就是说每10
Epoch 0 Step 002800, model loss 6.0150, LR: 0.0000100000
真实数据: 亏5美分。应该是令人
结果显示: 亏5美分。应议是令人
Epoch 0 Step 002900, model loss 8.9998, LR: 0.0000100000
真实数据: 导，观众经久不息的掌
结果显示: 导，重点经久不息的每
Epoch 0 Step 003000, model loss 3.1078, LR: 0.0000100000
真实数据: 强壮，一旦照射到金属
结果显示: 强壮，-旦照射到金属
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 6.9166, LR: 0.0000100000
真实数据: 母的一言一行直接影响
结果显示: 母的一言一行直按影响
Epoch 0 Step 003200, model loss 22.6664, LR: 0.0000100000
真实数据: 螺沟景区管理局46%
结果显示: 鲜海景区《理局46%
Epoch 0 Step 003300, model loss 0.0877, LR: 0.0000100000
真实数据: 区总面积4.6万平方
结果显示: 区总面积4.6万平方
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001C26004E4C0>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 5.1375, LR: 0.0000100000
真实数据: 并且不与外界产生联系
结果显示: 并口不与外界产生联系
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.4312, LR: 0.0000100000
真实数据: 兰州公交在全国是有名
结果显示: 兰州公交在全国是有名
Epoch 0 Step 000200, model loss 5.1214, LR: 0.0000100000
真实数据: 再也没有醒来....
结果显示: 再也没有画来....
Epoch 0 Step 000300, model loss 5.6014, LR: 0.0000100000
真实数据: 班牙人球员列队欢迎夺
结果显示: 班牙人球员到队欢迎夺
Epoch 0 Step 000400, model loss 1.7737, LR: 0.0000100000
真实数据: 二是武松误杀了自己哥
结果显示: 二是武松误杀了自已哥
Epoch 0 Step 000500, model loss 7.9877, LR: 0.0000100000
真实数据: 行政执法机关移送的涉
结果显示: 行政执法机关程选的沙
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 5.3269, LR: 0.0000100000
真实数据: 场出现机率结果得不偿
结果显示: 场出现机率结果得不伤
Epoch 0 Step 000700, model loss 2.0574, LR: 0.0000100000
真实数据: 导致女性对疼痛的反应
结果显示: 导致女性对疼痛的反应
Epoch 0 Step 000800, model loss 19.6475, LR: 0.0000100000
真实数据: 在众人的视野下，金庸
结果显示: 在众人的视玛下，全
Epoch 0 Step 000900, model loss 1.0946, LR: 0.0000100000
真实数据: 外市场巨大的资金存量
结果显示: 外市场巨大的资金有量
Epoch 0 Step 001000, model loss 1.8604, LR: 0.0000100000
真实数据: 游企业要充分认识安全
结果显示: 游企业要究分认识安全
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.2592, LR: 0.0000100000
真实数据: 0000.51%法人
结果显示: 0000.51%法人
Epoch 0 Step 001200, model loss 5.3363, LR: 0.0000100000
真实数据: 怕战场上的枪炮声而装
结果显示: 怕战场上的枪地声而装
Epoch 0 Step 001300, model loss 2.1313, LR: 0.0000100000
真实数据: 冬梅不仅在大学学的是
结果显示: 冬梅不仅在大学学的是
Epoch 0 Step 001400, model loss 9.1919, LR: 0.0000100000
真实数据: 欲辞王驾投西。体重5
结果显示: 欲譬王交投西。体重5
Epoch 0 Step 001500, model loss 0.2418, LR: 0.0000100000
真实数据: 西方家长和孩子之间是
结果显示: 西方家长和孩子之间是
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 5.1031, LR: 0.0000100000
真实数据: 利害关系人与所述文章
结果显示: 科决关系人与所述文章
Epoch 0 Step 001700, model loss 0.7922, LR: 0.0000100000
真实数据: 是九月，2004年调
结果显示: 是九月，2004年调
Epoch 0 Step 001800, model loss 0.2381, LR: 0.0000100000
真实数据: 占据领导位子的就那么
结果显示: 占据领导位子的就那么
Epoch 0 Step 001900, model loss 4.3271, LR: 0.0000100000
真实数据: 恰当的时候尽量放松自
结果显示: 忙当的时候尽量放松自
Epoch 0 Step 002000, model loss 19.6798, LR: 0.0000100000
真实数据: #9786;推荐:她
结果显示: 49786,抓荐:她
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 2.0172, LR: 0.0000100000
真实数据: 之贴上某项德育内容的
结果显示: 之贴上某项德育内容的
Epoch 0 Step 002200, model loss 55.0537, LR: 0.0000100000
真实数据: 更显弥贵。隋炀帝进攻
结果显示: 可显挑班。附场帝进项
Epoch 0 Step 002300, model loss 31.8845, LR: 0.0000100000
真实数据: 昆明的石林(Ston
结果显示: 团明的石林CSmou
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000291E196A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 4.0281, LR: 0.0000100000
真实数据: 15位之外。不损国力
结果显示: 15位之外。不换国力
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.6347, LR: 0.0000100000
真实数据: 次填报志愿时，这样的
结果显示: 次填报志愿时，这样的
Epoch 0 Step 000200, model loss 5.6587, LR: 0.0000100000
真实数据: 元外带吃祝他只要每个
结果显示: 元外带吃视他只要每个
Epoch 0 Step 000300, model loss 12.7834, LR: 0.0000100000
真实数据: 渠道伙伴对我们说售后
结果显示: 果道快岸对我们说售告后
Epoch 0 Step 000400, model loss 0.4075, LR: 0.0000100000
真实数据: 资料图:638426
结果显示: 资料图:638426
Epoch 0 Step 000500, model loss 4.2263, LR: 0.0000100000
真实数据: ，心身疾病包括的范围
结果显示: ，心身病病包括的范围
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0555, LR: 0.0000100000
真实数据: S上我发现了一条信息
结果显示: S上我发现了一条信息
Epoch 0 Step 000700, model loss 2.6105, LR: 0.0000100000
真实数据: 新老划断在上涨的时候
结果显示: 新老划断在上涨的时候
Epoch 0 Step 000800, model loss 0.6949, LR: 0.0000100000
真实数据: 们在引进这种制度之前
结果显示: 们在引进这种制度之前
Epoch 0 Step 000900, model loss 10.6501, LR: 0.0000100000
真实数据: 地抹杀了孩子的主动性
结果显示: 地扎茶了孩子的主动性
Epoch 0 Step 001000, model loss 5.3039, LR: 0.0000100000
真实数据: 发给报酬”（区别于管
结果显示: 发给报洹”（区别于管
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 5.0234, LR: 0.0000100000
真实数据: 议解决办法》正式实施
结果显示: 设解决办法》正我实施
Epoch 0 Step 001200, model loss 5.3116, LR: 0.0000100000
真实数据: 市民一旦出现这些症状
结果显示: 市民一旺出现这些症状
Epoch 0 Step 001300, model loss 4.6591, LR: 0.0000100000
真实数据: 领导的笑声都是善意的
结果显示: 领导的笑声都是乏意的
Epoch 0 Step 001400, model loss 2.1842, LR: 0.0000100000
真实数据: 为当地最受人欢迎的分
结果显示: 为当地最受人欢迎的分
Epoch 0 Step 001500, model loss 34.2626, LR: 0.0000100000
真实数据: 你们看呀，新郎将蜡烛
结果显示: 你们看哪，新际将进姓
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0144, LR: 0.0000100000
真实数据: 都比较关注它的有效性
结果显示: 都比较关注它的有效性
Epoch 0 Step 001700, model loss 1.1151, LR: 0.0000100000
真实数据: 站在岸上和舰上的人们
结果显示: 站在岸上和舰上的人们
Epoch 0 Step 001800, model loss 4.3254, LR: 0.0000100000
真实数据: 美陆军后来取消了M8
结果显示: 主陆军后来取消了M8
Epoch 0 Step 001900, model loss 1.5885, LR: 0.0000100000
真实数据: 已经断了气!“夫人啊
结果显示: 已经断了气!“夫人啊
Epoch 0 Step 002000, model loss 0.1673, LR: 0.0000100000
真实数据: 场均得到106.8分
结果显示: 场均得到106.8分
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 42.5111, LR: 0.0000100000
真实数据: 杜奇华缅甸和印度拒绝
结果显示: 挂香华量细和印度把继
Epoch 0 Step 002200, model loss 1.8809, LR: 0.0000100000
真实数据: 总收入为1.09亿美
结果显示: 总收入为1的09亿美
Epoch 0 Step 002300, model loss 0.7997, LR: 0.0000100000
真实数据: 基本与中国的豪装相仿
结果显示: 基本与中国的豪装相仿
Epoch 0 Step 002400, model loss 0.1692, LR: 0.0000100000
真实数据: 。内政部长召开会议解
结果显示: 。内政部长召开会议解
Epoch 0 Step 002500, model loss 1.0897, LR: 0.0000100000
真实数据: 信息产业部一位高官曾
结果显示: 信息产业部一位高官曾
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.3198, LR: 0.0000100000
真实数据: 湾有关方面尚未正式表
结果显示: 湾有关方面尚未正式表
Epoch 0 Step 002700, model loss 9.5453, LR: 0.0000100000
真实数据: :已受聘担任技术设计
结果显示: :受聘祖任技术设计
Epoch 0 Step 002800, model loss 2.9713, LR: 0.0000100000
真实数据: 族在泰国有另一个称呼
结果显示: 获在泰国有另一个称呼
Epoch 0 Step 002900, model loss 23.0483, LR: 0.0000100000
真实数据: 心情也会舒畅很多。相
结果显示: 心情也会好朝很多。相
Epoch 0 Step 003000, model loss 12.3524, LR: 0.0000100000
真实数据: 宁波华翔电子股份有限
结果显示: 宁波华逢电子股份有限
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 12.1279, LR: 0.0000100000
真实数据: 大赛官方邮箱wc20
结果显示: 大赛官方郎精rc20
Epoch 0 Step 003200, model loss 0.0574, LR: 0.0000100000
真实数据: 为“文明”的政治内容
结果显示: 为“文明”的政治内容
Epoch 0 Step 003300, model loss 1.6896, LR: 0.0000100000
真实数据: 的第一个出口向右（出
结果显示: 的第一个出口向有（出
Epoch 0 Step 003400, model loss 0.9234, LR: 0.0000100000
真实数据: 业、收入差距和社会保
结果显示: 业、收入差距和社会保
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000270571F9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 5.3629, LR: 0.0000100000
真实数据: 服务时，若是轻微的腰
结果显示: 服务时，若是轻微的喔
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 20.9963, LR: 0.0000100000
真实数据: 上泷同意记者为他拍照
结果显示: 上潜同意记者为他拍照
Epoch 0 Step 000200, model loss 0.4346, LR: 0.0000100000
真实数据: 000英尺的高度以0
结果显示: 000英尺的高度以0
Epoch 0 Step 000300, model loss 12.9903, LR: 0.0000100000
真实数据: 虚实结合表达感情的诗
结果显示: 盛实结含表达感情的读
Epoch 0 Step 000400, model loss 1.9011, LR: 0.0000100000
真实数据: 给谁知道吗?”“知道
结果显示: 给谁知道吗?”“知道
Epoch 0 Step 000500, model loss 6.0060, LR: 0.0000100000
真实数据: 使主张二里头遗址为西
结果显示: 使主张二里头迪址为西
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 38.1933, LR: 0.0000100000
真实数据: 则当日太公辟纣居东海
结果显示: 则当日太公席约结居东海
Epoch 0 Step 000700, model loss 2.3045, LR: 0.0000100000
真实数据: 么他却会下如此大的决
结果显示: 么他却会下如此大的决
Epoch 0 Step 000800, model loss 6.9889, LR: 0.0000100000
真实数据: 来源:支援了中央和友
结果显示: 来源:支概了中央和友
Epoch 0 Step 000900, model loss 7.8484, LR: 0.0000100000
真实数据: 一批优秀飞行员驾机展
结果显示: 一批优秀飞行员型机展
Epoch 0 Step 001000, model loss 11.4337, LR: 0.0000100000
真实数据: 温家宝的话，画外音:
结果显示: 营家宝的话，画外部
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1967, LR: 0.0000100000
真实数据: ，我可是第一次坐飞机
结果显示: ，我可是第一次坐飞机
Epoch 0 Step 001200, model loss 8.3507, LR: 0.0000100000
真实数据: 但闻床上终夜作振衣声
结果显示: 但闻床上终夜作据衣声
Epoch 0 Step 001300, model loss 0.2536, LR: 0.0000100000
真实数据: 实，盟军在欧洲、北非
结果显示: 实，盟军在欧洲、北非
Epoch 0 Step 001400, model loss 34.2326, LR: 0.0000100000
真实数据: 勾至。第二，*虞美人
结果显示: 冬至。第二，咪英人
Epoch 0 Step 001500, model loss 12.9890, LR: 0.0000100000
真实数据: 眼中流泪道:半分。当
结果显示: 欧中流问道:年分。当
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 9.2994, LR: 0.0000100000
真实数据: 炉再造”提高学生就业
结果显示: 过再造”提高学生就业
Epoch 0 Step 001700, model loss 0.0598, LR: 0.0000100000
真实数据: 也照见了!肉身是天主
结果显示: 也照见了!肉身是天主
Epoch 0 Step 001800, model loss 9.1837, LR: 0.0000100000
真实数据: 决策人在决策之初考虑
结果显示: 决第人在决第之初考虑
Epoch 0 Step 001900, model loss 0.6642, LR: 0.0000100000
真实数据: 绝其饮食，达61亿美
结果显示: 绝其饮食，达61亿美
Epoch 0 Step 002000, model loss 6.8937, LR: 0.0000100000
真实数据: 量，这一新发现于今天
结果显示: 短，这一新发现于今天
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 23.4528, LR: 0.0000100000
真实数据: 通过耳朵把语言刺激送
结果显示: 通过耳原把语言职涨佳
Epoch 0 Step 002200, model loss 24.0836, LR: 0.0000100000
真实数据: 国祚将覆，人类共同的
结果显示: 国特将，人美共同的
Epoch 0 Step 002300, model loss 12.8258, LR: 0.0000100000
真实数据: 就事论事，锦绣大地表
结果显示: 就事论事，情续太地表
Epoch 0 Step 002400, model loss 0.8418, LR: 0.0000100000
真实数据: 育部举办的新闻发布会
结果显示: 育部举办的新闻发布会
Epoch 0 Step 002500, model loss 2.7077, LR: 0.0000100000
真实数据: 总监换成了一个台湾老
结果显示: 总篮换成了一个台湾老
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.5269, LR: 0.0000100000
真实数据: 报》报道说公司将裁员
结果显示: 报》报道说公司将裁员
Epoch 0 Step 002700, model loss 0.4505, LR: 0.0000100000
真实数据: 记者:她的事业一再顶
结果显示: 记者:她的事业一再顶
Epoch 0 Step 002800, model loss 0.0140, LR: 0.0000100000
真实数据: 2006年元月15日
结果显示: 2006年元月15日
Epoch 0 Step 002900, model loss 0.5175, LR: 0.0000100000
真实数据: 地指出该事件的长远意
结果显示: 地指出该事件的长远意
Epoch 0 Step 003000, model loss 3.3423, LR: 0.0000100000
真实数据: 期开出1枚大数奖号1
结果显示: 期开出1校大数奖号1
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 4.5329, LR: 0.0000100000
真实数据: 界考古工作者的“朝圣
结果显示: 果考古工作者的“朝圣
Epoch 0 Step 003200, model loss 26.0522, LR: 0.0000100000
真实数据: 教穷败之恨，该有51
结果显示: 投紧败之概，该有31
Epoch 0 Step 003300, model loss 0.5692, LR: 0.0000100000
真实数据: 比如移动增值服务、电
结果显示: 比如移动增值服务、电
Epoch 0 Step 003400, model loss 0.4591, LR: 0.0000100000
真实数据: 统计，这个时候也发生
结果显示: 统计，这个时候也发生
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000174F3BBA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 16.5539, LR: 0.0000100000
真实数据: 朝日新闻》号外昭和6
结果显示: 戴日新闻》号外职和6
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 41.8522, LR: 0.0000100000
真实数据: 妇女都会患多囊卵巢综
结果显示: 纠于交部会思多程炎国结
Epoch 0 Step 000200, model loss 12.2593, LR: 0.0000100000
真实数据: 么时候能开通还是未知
结果显示: 么时候就开通还是本加
Epoch 0 Step 000300, model loss 9.8090, LR: 0.0000100000
真实数据: 一破这个股市就完蛋了
结果显示: 一这个股市就完委了
Epoch 0 Step 000400, model loss 2.5837, LR: 0.0000100000
真实数据: 力资源部将会同用人部
结果显示: 力资源部将念同用人部
Epoch 0 Step 000500, model loss 2.6005, LR: 0.0000100000
真实数据: 是对光速值的精确测定
结果显示: 是对光连值的精确测定
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.4048, LR: 0.0000100000
真实数据: 在世界上最具标志性的
结果显示: 在世界上最具标志性的
Epoch 0 Step 000700, model loss 0.3486, LR: 0.0000100000
真实数据: 个体可能引起的过敏反
结果显示: 个体可能引起的过敏反
Epoch 0 Step 000800, model loss 1.3491, LR: 0.0000100000
真实数据: 一般无痛。又是即时通
结果显示: 一般无痛。又是即时通
Epoch 0 Step 000900, model loss 15.5471, LR: 0.0000100000
真实数据: “巫语”给记者规定了
结果显示: “型语”给记者规定了
Epoch 0 Step 001000, model loss 6.4736, LR: 0.0000100000
真实数据: 是埋头苦读。汝既不能
结果显示: 是头苦读。波既不能
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 15.5206, LR: 0.0000100000
真实数据: 是演练战时“内阁”的
结果显示: 是演练战时“内周”的
Epoch 0 Step 001200, model loss 7.2576, LR: 0.0000100000
真实数据: 辽沈大战中的功劳辽沈
结果显示: 辽洗大战中的功劳迁荔
Epoch 0 Step 001300, model loss 0.1483, LR: 0.0000100000
真实数据: 且形成了1000多家
结果显示: 且形成了1000多家
Epoch 0 Step 001400, model loss 8.1589, LR: 0.0000100000
真实数据: 美国计算机市场，“为
结果显示: 美国计典机市塔，“为
Epoch 0 Step 001500, model loss 22.4629, LR: 0.0000100000
真实数据: 盛霆他和他老板的默契
结果显示: 盛题他和他老板的既奖
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 7.9679, LR: 0.0000100000
真实数据: 原来代课教师的补偿问
结果显示: 原来代课教师的补德问
Epoch 0 Step 001700, model loss 27.9102, LR: 0.0000100000
真实数据: 博集团根据两队间的实
结果显示: 博断根患两队强的实
Epoch 0 Step 001800, model loss 0.1121, LR: 0.0000100000
真实数据: 生表示:不是一般性的
结果显示: 生表示:不是一般性的
Epoch 0 Step 001900, model loss 16.2194, LR: 0.0000100000
真实数据: 地“围剿”中央苏区和
结果显示: 地“围明”中央苏民和
Epoch 0 Step 002000, model loss 16.5818, LR: 0.0000100000
真实数据: 苦医生诊断她患了脑溢
结果显示: 苦医生诊断她患了脑注
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0654, LR: 0.0000100000
真实数据: ，落。也肯定是最后一
结果显示: ，落。也肯定是最后一
Epoch 0 Step 002200, model loss 4.0303, LR: 0.0000100000
真实数据: 达6马赫(2800米
结果显示: 达6马禁(2800米
Epoch 0 Step 002300, model loss 12.4324, LR: 0.0000100000
真实数据: 属意焉。又益贷以重金
结果显示: 属意痒。又益贷以重金
Epoch 0 Step 002400, model loss 9.9341, LR: 0.0000100000
真实数据: 有男人都愿意找善良女
结果显示: 有易人都愿意我良女
Epoch 0 Step 002500, model loss 16.1818, LR: 0.0000100000
真实数据: 剥夺了人不受痛苦的权
结果显示: 将之了人不受旅苦的权
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 21.7342, LR: 0.0000100000
真实数据: 地扛圆木训练――对于
结果显示: 地打医木训练――对于
Epoch 0 Step 002700, model loss 2.0207, LR: 0.0000100000
真实数据: 政策应该从两个方面看
结果显示: 政策应该从两个方面看
Epoch 0 Step 002800, model loss 2.5921, LR: 0.0000100000
真实数据: 参加过韩国游的市民告
结果显示: 参加过韩国游的市民告
Epoch 0 Step 002900, model loss 0.9773, LR: 0.0000100000
真实数据: 素受体阳性患者化疗结
结果显示: 素受体阳性患者化疗结
Epoch 0 Step 003000, model loss 7.3740, LR: 0.0000100000
真实数据: 则用蒙托里沃替换了布
结果显示: 则用蒙托里沉有换了布
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 10.1514, LR: 0.0000100000
真实数据: 开的公司里当了几天杂
结果显示: 开的公司里当不天来
Epoch 0 Step 003200, model loss 24.8065, LR: 0.0000100000
真实数据: 铝业股份有限公司董事
结果显示: 呵业股份有限公司单事
Epoch 0 Step 003300, model loss 7.8238, LR: 0.0000100000
真实数据: 的中前场球员。负责贯
结果显示: 的中前场球员。负责贾
Epoch 0 Step 003400, model loss 0.7448, LR: 0.0000100000
真实数据: 计师或许也使用这种类
结果显示: 计师或许也使用这种类
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000016DD973A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.5030, LR: 0.0000100000
真实数据: “缺乏积极的就业精神
结果显示: “缺乏积极的就业精神
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 9.3581, LR: 0.0000100000
真实数据: 辉凭借自己的特殊背景
结果显示: 解兄借自己的特殊背景
Epoch 0 Step 000200, model loss 5.5876, LR: 0.0000100000
真实数据: 侵略我国，输血后还要
结果显示: 侵难我国，输血后还要
Epoch 0 Step 000300, model loss 0.4236, LR: 0.0000100000
真实数据: 后果不堪设想。就三点
结果显示: 后果不堪设想。就三点
Epoch 0 Step 000400, model loss 7.0899, LR: 0.0000100000
真实数据: 恶人每以自解，同入礼
结果显示: 酒人每以自解，同入补
Epoch 0 Step 000500, model loss 0.4662, LR: 0.0000100000
真实数据: 望第一个建成投入使用
结果显示: 望第一个建成投入使用
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 7.4530, LR: 0.0000100000
真实数据: 9年在埃及揭起了反福
结果显示: 9年在妖及握起了反福
Epoch 0 Step 000700, model loss 4.0270, LR: 0.0000100000
真实数据: outofinkag
结果显示: outofiikag
Epoch 0 Step 000800, model loss 20.4397, LR: 0.0000100000
真实数据: 覆盖住乳房所有外沿的
结果显示: 理益住臭房所有外治的
Epoch 0 Step 000900, model loss 0.1457, LR: 0.0000100000
真实数据: 通正在积极和中国的广
结果显示: 通正在积极和中国的广
Epoch 0 Step 001000, model loss 4.9503, LR: 0.0000100000
真实数据: 名:当足协公布刚开始
结果显示: 各;当足协公布刚开始
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 38.2591, LR: 0.0000100000
真实数据: “爸爸，激光雷达系统
结果显示: “善音，成光备比射的
Epoch 0 Step 001200, model loss 36.4597, LR: 0.0000100000
真实数据: “老师，批颊而摘翁髭
结果显示: “老师，批规而搞参量
Epoch 0 Step 001300, model loss 18.1524, LR: 0.0000100000
真实数据: 违者将追究其法律责任
结果显示: :者将连究其法律责任
Epoch 0 Step 001400, model loss 29.2971, LR: 0.0000100000
真实数据: 款婿，据米哈伊洛夫称
结果显示: 我据，据米论伊选失称
Epoch 0 Step 001500, model loss 6.9472, LR: 0.0000100000
真实数据: 再次响起，“徒弟徒弟
结果显示: 再次响起，“技弟佐弟
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 3.4280, LR: 0.0000100000
真实数据: 保证潜艇性能的先进性
结果显示: 保证潜航性能的先进性
Epoch 0 Step 001700, model loss 0.8585, LR: 0.0000100000
真实数据: 日，给他们配的职业教
结果显示: 日，给他们配的职业教
Epoch 0 Step 001800, model loss 0.2372, LR: 0.0000100000
真实数据: 有很好的通便作用，说
结果显示: 有很好的通便作用，说
Epoch 0 Step 001900, model loss 5.1633, LR: 0.0000100000
真实数据: 一个4050人员下岗
结果显示: 一个4050人员下
Epoch 0 Step 002000, model loss 0.0363, LR: 0.0000100000
真实数据: 的和型号都不十分明确
结果显示: 的和型号都不十分明确
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.1337, LR: 0.0000100000
真实数据: 的时候就无法注意力集
结果显示: 的时候就无法注意力集
Epoch 0 Step 002200, model loss 0.0238, LR: 0.0000100000
真实数据: 所以人员上没有发生直
结果显示: 所以人员上没有发生直
Epoch 0 Step 002300, model loss 0.1002, LR: 0.0000100000
真实数据: 充当它的“导弹之父”
结果显示: 充当它的“导弹之父”
Epoch 0 Step 002400, model loss 18.8754, LR: 0.0000100000
真实数据: 酡，西方人却把他造成
结果显示: 配，西方人却把他造成
Epoch 0 Step 002500, model loss 2.2083, LR: 0.0000100000
真实数据: 林丹直落两局战胜对手
结果显示: 林丹直落两局战胜对手
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 18.4318, LR: 0.0000100000
真实数据: 廖锡龙上将在解读中国
结果显示: 摩露龙上将在解德中国
Epoch 0 Step 002700, model loss 2.3404, LR: 0.0000100000
真实数据: 道:核潜艇爆炸后果可
结果显示: 道:核潜艇爆炸后果可
Epoch 0 Step 002800, model loss 18.9372, LR: 0.0000100000
真实数据: 仅带给她快乐，蓦然而
结果显示: 仅带给她快乐，基然而
Epoch 0 Step 002900, model loss 1.6037, LR: 0.0000100000
真实数据: 应用达到了一个新的里
结果显示: 应用边到了一个新的里
Epoch 0 Step 003000, model loss 0.0585, LR: 0.0000100000
真实数据: 会经济、军用技术与民
结果显示: 会经济、军用技术与民
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 9.9568, LR: 0.0000100000
真实数据: 教训。”中国女羽的实
结果显示: 教训。”中国女酬的实
Epoch 0 Step 003200, model loss 25.5481, LR: 0.0000100000
真实数据: 城市建设规划，有助于
结果显示: 旅市效设好动。有脚于
Epoch 0 Step 003300, model loss 0.3419, LR: 0.0000100000
真实数据: 等事宜进行先期的可行
结果显示: 等事宜进行先期的可行
Epoch 0 Step 003400, model loss 29.2170, LR: 0.0000100000
真实数据: 大多数食品盒的底部都
结果显示: 大刘放食别全的应部都
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001690FD89258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 1.2590, LR: 0.0000100000
真实数据: 地方”评选活动从20
结果显示: 地方”评选活动从20
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.8725, LR: 0.0000100000
真实数据: 字，如果调节一段时间
结果显示: 字，如果调节一段时间
Epoch 0 Step 000200, model loss 1.4408, LR: 0.0000100000
真实数据: 现的净利润确认的收益
结果显示: 现的净利润确认的收益
Epoch 0 Step 000300, model loss 1.8572, LR: 0.0000100000
真实数据: 水平的世界顶尖计算机
结果显示: 水平的世界项尖计算机
Epoch 0 Step 000400, model loss 2.0653, LR: 0.0000100000
真实数据: 1比2。错怪了小神也
结果显示: 1比2。错怪了小神也
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001AF83259258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.7678, LR: 0.0000100000
真实数据: 好从星期一的午后再开
结果显示: 好从星期一的午后再开
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0638, LR: 0.0000100000
真实数据: 网队极有可能坏了热队
结果显示: 网队极有可能坏了热队
Epoch 0 Step 000200, model loss 2.9979, LR: 0.0000100000
真实数据: 累计121分获得第三
结果显示: 紧计121分获得第三
Epoch 0 Step 000300, model loss 1.8401, LR: 0.0000100000
真实数据: 高，所以我说成都三美
结果显示: 高，所以我说成都三实
Epoch 0 Step 000400, model loss 13.8767, LR: 0.0000100000
真实数据: :他说，中国茅房已经
结果显示: :他说，中国矛房已经
Epoch 0 Step 000500, model loss 4.6934, LR: 0.0000100000
真实数据: 在一次死亡和毁灭之后
结果显示: 在一次死亡和毁双灭之后
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 7.8957, LR: 0.0000100000
真实数据: 已知狗、鸡和许多动物
结果显示: 已知孩、荠和许多动将物
Epoch 0 Step 000700, model loss 1.9857, LR: 0.0000100000
真实数据: 救亡图存的近代意义的
结果显示: 救亡图存的近代意义的
Epoch 0 Step 000800, model loss 3.2035, LR: 0.0000100000
真实数据: 最重要的经验是，姑中
结果显示: 最重要的经脸是，鼓中
Epoch 0 Step 000900, model loss 0.1719, LR: 0.0000100000
真实数据: 117分。主持人:着
结果显示: 117分。主持人:着
Epoch 0 Step 001000, model loss 0.3107, LR: 0.0000100000
真实数据: 努力发展核能力和弹道
结果显示: 努力发展核能力和弹道
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1258, LR: 0.0000100000
真实数据: 退让的原则来进行协商
结果显示: 退让的原则来进行协商
Epoch 0 Step 001200, model loss 15.2365, LR: 0.0000100000
真实数据: 我们沾你的光啊。比上
结果显示: 我们泪你的光响。比上
Epoch 0 Step 001300, model loss 2.7753, LR: 0.0000100000
真实数据: take;还能让妇女
结果显示: take:还能让妇女
Epoch 0 Step 001400, model loss 0.4164, LR: 0.0000100000
真实数据: 合多为一的人文和生态
结果显示: 合多为一的人文和生态
Epoch 0 Step 001500, model loss 3.7048, LR: 0.0000100000
真实数据: 。我心疼得快掉下眼泪
结果显示: 。我心形得快掉下眼泪
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.9162, LR: 0.0000100000
真实数据: 纵横，这是他们30年
结果显示: 纵横，这是他们30年
Epoch 0 Step 001700, model loss 0.1340, LR: 0.0000100000
真实数据: 成完了一座楼以后，服
结果显示: 成完了一座楼以后，服
Epoch 0 Step 001800, model loss 0.1531, LR: 0.0000100000
真实数据: 得到最需要的服务。“
结果显示: 得到最需要的服务。“
Epoch 0 Step 001900, model loss 42.2063, LR: 0.0000100000
真实数据: 」张伯苓看到这封信喜
结果显示: ]张伯移看到这封信喜
Epoch 0 Step 002000, model loss 5.7298, LR: 0.0000100000
真实数据: 沙拉夫认为，“实践证
结果显示: 沙拉夫认为，“实出证
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 16.2244, LR: 0.0000100000
真实数据: 是晶莹的，（搜狐体育
结果显示: 是品堂的，（搜狐体育
Epoch 0 Step 002200, model loss 24.2526, LR: 0.0000100000
真实数据: 洲最高伞塔，依原订计
结果显示: 满洲高华塔，依原日计
Epoch 0 Step 002300, model loss 0.0381, LR: 0.0000100000
真实数据: 但这一代女大学生更关
结果显示: 但这一代女大学生更关
Epoch 0 Step 002400, model loss 6.0073, LR: 0.0000100000
真实数据: 分析人士指出，在阿城
结果显示: 分析人士出，在网城
Epoch 0 Step 002500, model loss 0.9812, LR: 0.0000100000
真实数据: 更要重视这一方面的反
结果显示: 更要重视这一方面的反
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 5.1040, LR: 0.0000100000
真实数据: 有一些投资者的状态是
结果显示: 有一些投资者的状暴是
Epoch 0 Step 002700, model loss 0.0352, LR: 0.0000100000
真实数据: 产成而目前仅有约50
结果显示: 产成而目前仅有约50
Epoch 0 Step 002800, model loss 0.2906, LR: 0.0000100000
真实数据: 你又不想失去这份工作
结果显示: 你又不想失去这份工作
Epoch 0 Step 002900, model loss 0.9039, LR: 0.0000100000
真实数据: 文案策划由学生分别去
结果显示: 文案策划由学生分别去
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000023822CAA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.9206, LR: 0.0000100000
真实数据: encen.时间上在
结果显示: encen,.时间,上在
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.9064, LR: 0.0000100000
真实数据: 神更是认识到人的知性
结果显示: 神更是认识到人的捉性
Epoch 0 Step 000200, model loss 5.1905, LR: 0.0000100000
真实数据: 值。各地市都应选择部
结果显示: 伯。各地市都应选择部
Epoch 0 Step 000300, model loss 7.8718, LR: 0.0000100000
真实数据: 房，知道在某一时刻可
结果显示: 所，知道在某一时刻可
Epoch 0 Step 000400, model loss 0.0062, LR: 0.0000100000
真实数据: 用12个小时在工作上
结果显示: 用12个小时在工作上
Epoch 0 Step 000500, model loss 20.9423, LR: 0.0000100000
真实数据: 其无礼也”，吏目守之
结果显示: 其无礼也”，麦目守之
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 12.1995, LR: 0.0000100000
真实数据: 装备体积大，而涨停板
结果显示: 装备体积太，而涨停极
Epoch 0 Step 000700, model loss 3.9396, LR: 0.0000100000
真实数据: 从这个角度还依稀可以
结果显示: 从这个角度还依排可以
Epoch 0 Step 000800, model loss 5.0726, LR: 0.0000100000
真实数据: 献大王，空。轻松实现
结果显示: 前大王，空。轻松突现
Epoch 0 Step 000900, model loss 5.6835, LR: 0.0000100000
真实数据: 曰:女虑同居其名不顺
结果显示: 回:女惠同居其名不顺
Epoch 0 Step 001000, model loss 3.5644, LR: 0.0000100000
真实数据: 的初始。这次给他10
结果显示: 的初始．这次给他10
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.4859, LR: 0.0000100000
真实数据: 物美商业有限公司也同
结果显示: 物美商业有限公司也同
Epoch 0 Step 001200, model loss 25.2436, LR: 0.0000100000
真实数据: 会让腰肌功能逐日萎缩
结果显示: 会让照顺功能逐目条给
Epoch 0 Step 001300, model loss 0.6722, LR: 0.0000100000
真实数据: 外部资源约束导致资源
结果显示: 外部资源约束导致资源
Epoch 0 Step 001400, model loss 1.2853, LR: 0.0000100000
真实数据: 了。美国人会不会放弃
结果显示: 了。美田人会不会放弃
Epoch 0 Step 001500, model loss 13.1644, LR: 0.0000100000
真实数据: 浓厚的乡音向全世界庄
结果显示: 兴月的乡音向全世界在
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 11.2941, LR: 0.0000100000
真实数据: 鼠标，第十二个错误的
结果显示: 象标，第十二个错误的
Epoch 0 Step 001700, model loss 0.8078, LR: 0.0000100000
真实数据: 会说话，有大量的事实
结果显示: 会说话，有大量的事实
Epoch 0 Step 001800, model loss 6.3448, LR: 0.0000100000
真实数据: 中国股市具有中国特色
结果显示: 中进股市具有中国特色
Epoch 0 Step 001900, model loss 24.1936, LR: 0.0000100000
真实数据: 对台“挑衅”或干扰离
结果显示: 对台“拉障”或干犹商
Epoch 0 Step 002000, model loss 0.5207, LR: 0.0000100000
真实数据: 加强政府采购预算编制
结果显示: 加强政府采购预算编制
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.7327, LR: 0.0000100000
真实数据: 易合同金额590亿元
结果显示: 易含同金额590亿元
Epoch 0 Step 002200, model loss 11.9881, LR: 0.0000100000
真实数据: 们将鲜花和彩带抛向天
结果显示: 们将鲜花和彩带提向天
Epoch 0 Step 002300, model loss 0.0692, LR: 0.0000100000
真实数据: 基地中有4处美军正在
结果显示: 基地中有4处美军正在
Epoch 0 Step 002400, model loss 3.0989, LR: 0.0000100000
真实数据: 修建高约23米、宽约
结果显示: 修建高约23米、宽约
Epoch 0 Step 002500, model loss 16.7532, LR: 0.0000100000
真实数据: 湖人的同城兄弟洛杉矶
结果显示: 湖人的同城兄弟洛核研
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 10.1169, LR: 0.0000100000
真实数据: 后赴京参加京参加京试
结果显示: 后难京参加京参加京议
Epoch 0 Step 002700, model loss 2.7916, LR: 0.0000100000
真实数据: 就是试图在高校学生内
结果显示: 就是试围在高校学生内
Epoch 0 Step 002800, model loss 0.0410, LR: 0.0000100000
真实数据: 那么我就可以认定你作
结果显示: 那么我就可以认定你作
Epoch 0 Step 002900, model loss 0.0592, LR: 0.0000100000
真实数据: 两个半月1500元用
结果显示: 两个半月1500元用
Epoch 0 Step 003000, model loss 10.5121, LR: 0.0000100000
真实数据: 互联网给了客户“逛街
结果显示: 互联网给了客户“遇钱
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0295, LR: 0.0000100000
真实数据: 的礼仪能够体现个人的
结果显示: 的礼仪能够体现个人的
Epoch 0 Step 003200, model loss 3.6526, LR: 0.0000100000
真实数据: 统一标准》(GB50
结果显示: 统一准》(B50
Epoch 0 Step 003300, model loss 11.1685, LR: 0.0000100000
真实数据: Lisa爽快地应允了
结果显示: Lisa卖快地应允了
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000277ADCC9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0969, LR: 0.0000100000
真实数据: 优良的股票型或偏股型
结果显示: 优良的股票型或偏股型
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.6035, LR: 0.0000100000
真实数据: 明年阿尔卡特将在亚太
结果显示: 明年阿尔卡特将在亚太
Epoch 0 Step 000200, model loss 2.7436, LR: 0.0000100000
真实数据: 你觉得它摆开了对阵的
结果显示: 你觉得它摆开了对阵的
Epoch 0 Step 000300, model loss 3.6410, LR: 0.0000100000
真实数据: 人气旺盛的势头。久之
结果显示: 人气既盛的势头。久之
Epoch 0 Step 000400, model loss 0.2783, LR: 0.0000100000
真实数据: 应该有你的名字才对。
结果显示: 应该有你的名字才对。
Epoch 0 Step 000500, model loss 44.2219, LR: 0.0000100000
真实数据: 腌脏臭气，搞清易混淆
结果显示: 赌融奥气，搞清易混活
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 11.4710, LR: 0.0000100000
真实数据: 是厂家要求这种牙膏要
结果显示: 是厂家要求这种牙硕要
Epoch 0 Step 000700, model loss 6.1174, LR: 0.0000100000
真实数据: 光靠死记硬背是不行的
结果显示: 光靠死记是背是不行的
Epoch 0 Step 000800, model loss 0.0293, LR: 0.0000100000
真实数据: ，“师父，可以把中等
结果显示: ，“师父，可以把中等
Epoch 0 Step 000900, model loss 18.0673, LR: 0.0000100000
真实数据: 遇了人生中的特大尴尬
结果显示: 遇了人生中的特大越炮
Epoch 0 Step 001000, model loss 8.5963, LR: 0.0000100000
真实数据: 白领阶层这个概念给人
结果显示: 句领阶原这个概念给人
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 19.6954, LR: 0.0000100000
真实数据: 又做了1年仓储管理工
结果显示: 又做了1年合结管理工
Epoch 0 Step 001200, model loss 0.0395, LR: 0.0000100000
真实数据: 分清是何种民事法律关
结果显示: 分清是何种民事法律关
Epoch 0 Step 001300, model loss 4.6146, LR: 0.0000100000
真实数据: 还是愿意将自己修炼成
结果显示: 还是愿意将自己修成
Epoch 0 Step 001400, model loss 0.0383, LR: 0.0000100000
真实数据: 等待着同事扑面而来的
结果显示: 等待着同事扑面而来的
Epoch 0 Step 001500, model loss 14.2579, LR: 0.0000100000
真实数据: 字识别码的申请、注册
结果显示: 字诉别码的中访、注务
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0436, LR: 0.0000100000
真实数据: 对教育的投入也逐年提
结果显示: 对教育的投入也逐年提
Epoch 0 Step 001700, model loss 0.6806, LR: 0.0000100000
真实数据: ，基本上没有媒体没有
结果显示: ，基本上没有媒体没有
Epoch 0 Step 001800, model loss 16.1523, LR: 0.0000100000
真实数据: 和19艘。等到合同签
结果显示: 和19妙。等到合网签
Epoch 0 Step 001900, model loss 3.1801, LR: 0.0000100000
真实数据: 好的办法就是把地里种
结果显示: 好的办动就是把地里种
Epoch 0 Step 002000, model loss 0.1353, LR: 0.0000100000
真实数据: 话后两分钟就会忘记谈
结果显示: 话后两分钟就会忘记谈
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 8.9505, LR: 0.0000100000
真实数据: 2)收购方:就是板蓝
结果显示: 2)收购方:就是板童
Epoch 0 Step 002200, model loss 0.0489, LR: 0.0000100000
真实数据: 过自动化提高了平均劳
结果显示: 过自动化提高了平均劳
Epoch 0 Step 002300, model loss 0.1222, LR: 0.0000100000
真实数据: 当照顾各学科本身理论
结果显示: 当照顾各学科本身理论
Epoch 0 Step 002400, model loss 14.6178, LR: 0.0000100000
真实数据: 为奸的右翼专制本质?
结果显示: 为的右弹专制本质?
Epoch 0 Step 002500, model loss 9.0884, LR: 0.0000100000
真实数据: 这么拖下去可真不是个
结果显示: 这么抱下去可真不是个
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.4593, LR: 0.0000100000
真实数据: 非常好。但是长期以来
结果显示: 非常好。但是长期以来
Epoch 0 Step 002700, model loss 0.0254, LR: 0.0000100000
真实数据: “主他做出了一个决定
结果显示: “主他做出了一个决定
Epoch 0 Step 002800, model loss 1.0615, LR: 0.0000100000
真实数据: 200km/h以下的
结果显示: 200km/h以下的
Epoch 0 Step 002900, model loss 4.8472, LR: 0.0000100000
真实数据: 聊斋志异》突出地提出
结果显示: 聊帝志异》突出地提出
Epoch 0 Step 003000, model loss 2.9359, LR: 0.0000100000
真实数据: 德育工作的针对性和实
结果显示: 德育工作的针计对性和实
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 5.4838, LR: 0.0000100000
真实数据: 过去把师傅带徒弟那种
结果显示: 过去把师博带徒第那种
Epoch 0 Step 003200, model loss 10.1805, LR: 0.0000100000
真实数据: 若飞，一个阶段是调整
结果显示: 特飞，一个价段是调整
Epoch 0 Step 003300, model loss 10.6619, LR: 0.0000100000
真实数据: 以此形成高低搭配，而
结果显示: 以此形成高低格曰，而
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001BB33A0A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.1004, LR: 0.0000100000
真实数据: 身的特权当都市里一些
结果显示: 身的特权当都市里一些
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 15.0902, LR: 0.0000100000
真实数据: 打鼾不当回事为了你我
结果显示: 打解不当回事为了你我
Epoch 0 Step 000200, model loss 5.0080, LR: 0.0000100000
真实数据: 所述随着战争实践的发
结果显示: 所述随着战争实的发
Epoch 0 Step 000300, model loss 6.6025, LR: 0.0000100000
真实数据: 入夕果至，夜战是首选
结果显示: 入夕果至，夜战是首距
Epoch 0 Step 000400, model loss 1.0237, LR: 0.0000100000
真实数据: 华大学2006年本科
结果显示: 华大学2006年本科
Epoch 0 Step 000500, model loss 28.6329, LR: 0.0000100000
真实数据: 米于水，干什么蹊跷异
结果显示: 米于水，干什么跌家异
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.1729, LR: 0.0000100000
真实数据: 例比常年处于战争状态
结果显示: 例比常年处于战争状态
Epoch 0 Step 000700, model loss 16.4542, LR: 0.0000100000
真实数据: 拍的如同素描般简洁的
结果显示: 拍的如索媒般储洁的
Epoch 0 Step 000800, model loss 6.2578, LR: 0.0000100000
真实数据: 外，尽管以色列仰仗美
结果显示: 外，尽管以色列似仪美
Epoch 0 Step 000900, model loss 2.9193, LR: 0.0000100000
真实数据: 。对工作流程不是很熟
结果显示: 。对工作流程不是很热
Epoch 0 Step 001000, model loss 1.2617, LR: 0.0000100000
真实数据: 到正常以后维持一段时
结果显示: 到正常以后维持一段时
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0075, LR: 0.0000100000
真实数据: 资者不应过于乐观。而
结果显示: 资者不应过于乐观。而
Epoch 0 Step 001200, model loss 3.1330, LR: 0.0000100000
真实数据: 759×10=1.5
结果显示: 759×10二1.5
Epoch 0 Step 001300, model loss 4.3219, LR: 0.0000100000
真实数据: 县每年就地加工的2万
结果显示: 且每年就地加工的2万
Epoch 0 Step 001400, model loss 0.0191, LR: 0.0000100000
真实数据: ，转向重点发展空中打
结果显示: ，转向重点发展空中打
Epoch 0 Step 001500, model loss 2.9005, LR: 0.0000100000
真实数据: 年来，买一送一、无限
结果显示: 年来，买一送一、无留
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.5749, LR: 0.0000100000
真实数据: 君王一旦失去其“势”
结果显示: 看王一旦失去其“势”
Epoch 0 Step 001700, model loss 0.0681, LR: 0.0000100000
真实数据: 新开发的线路，”从此
结果显示: 新开发的线路，”从此
Epoch 0 Step 001800, model loss 10.3120, LR: 0.0000100000
真实数据: 1年初步实现经营性扭
结果显示: 1年初劳实现经营性扫
Epoch 0 Step 001900, model loss 0.1775, LR: 0.0000100000
真实数据: 也最能打动现代人的心
结果显示: 也最能打动现代人的心
Epoch 0 Step 002000, model loss 4.6795, LR: 0.0000100000
真实数据: [图库]沿线各重点景
结果显示: [图肉]沿线各重点景
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 16.5000, LR: 0.0000100000
真实数据: 百阿罗大菩萨。“师父
结果显示: 百网罗大善营。“师父
Epoch 0 Step 002200, model loss 0.0490, LR: 0.0000100000
真实数据: 人类反抗困苦命运所能
结果显示: 人类反抗困苦命运所能
Epoch 0 Step 002300, model loss 21.7522, LR: 0.0000100000
真实数据: 可没想到放松缺少地方
结果显示: 可没般到被松销少地市
Epoch 0 Step 002400, model loss 5.5864, LR: 0.0000100000
真实数据: 从而抬高师母的成就感
结果显示: 从而指高师母的成就感
Epoch 0 Step 002500, model loss 14.8024, LR: 0.0000100000
真实数据: 他们的身价因此节节攀
结果显示: 他们的身价因此节节脉
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.2941, LR: 0.0000100000
真实数据: 种形式的组合都会全盘
结果显示: 种形式的组合都会全盘
Epoch 0 Step 002700, model loss 10.0836, LR: 0.0000100000
真实数据: 然也没给他好脸。不是
结果显示: 然也没给结好验。不是
Epoch 0 Step 002800, model loss 0.1593, LR: 0.0000100000
真实数据: 的专业，”1998年
结果显示: 的专业，”1998年
Epoch 0 Step 002900, model loss 13.9982, LR: 0.0000100000
真实数据: 翅而逃。专辑《11月
结果显示: 趣而选。专辑《11月
Epoch 0 Step 003000, model loss 17.5570, LR: 0.0000100000
真实数据: 引向高端有机氟产品领
结果显示: 引向高端有机梁产品领
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.5794, LR: 0.0000100000
真实数据: 断了麻田村62户村民
结果显示: 断了麻田村62户村民
Epoch 0 Step 003200, model loss 2.5176, LR: 0.0000100000
真实数据: 假如缺乏这种补偿机制
结果显示: 假如缺乏这种补信机制
Epoch 0 Step 003300, model loss 5.0142, LR: 0.0000100000
真实数据: ”拥有较强的技术实力
结果显示: ”轻有较强的技术实力
Epoch 0 Step 003400, model loss 9.3109, LR: 0.0000100000
真实数据: 宣布在其领土上穆卡切
结果显示: 宣布在其领土上缓卡切
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001B5B1188258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0036, LR: 0.0000100000
真实数据: 必须要有全权。是好天
结果显示: 必须要有全权。是好天
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.2694, LR: 0.0000100000
真实数据: 社会公众股股东出席情
结果显示: 社会公众股股东出席情
Epoch 0 Step 000200, model loss 10.5893, LR: 0.0000100000
真实数据: 常识没必要掌握。10
结果显示: 狐识没必要掌握。10
Epoch 0 Step 000300, model loss 0.0036, LR: 0.0000100000
真实数据: 2、关于公司2006
结果显示: 2、关于公司2006
Epoch 0 Step 000400, model loss 13.7038, LR: 0.0000100000
真实数据: 横行于厅前而傲然不敬
结果显示: 横行于厅前而做然不俗
Epoch 0 Step 000500, model loss 0.6216, LR: 0.0000100000
真实数据: 为了图方便而忽略安全
结果显示: 为了图方便而忽略安全
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 1.6314, LR: 0.0000100000
真实数据: 1-40献宝似地往美
结果显示: 1-40献宝似地往美
Epoch 0 Step 000700, model loss 3.0400, LR: 0.0000100000
真实数据: 请唐僧站在马的颈项左
结果显示: 请唐僧站在马的亲项左
Epoch 0 Step 000800, model loss 2.1144, LR: 0.0000100000
真实数据: 之心不自觉地便被激发
结果显示: 之心不自觉地便被邀发
Epoch 0 Step 000900, model loss 4.9614, LR: 0.0000100000
真实数据: 慢慢改进;那是不用说
结果显示: 慢慢改进:那是不用说
Epoch 0 Step 001000, model loss 0.8180, LR: 0.0000100000
真实数据: 、舰机联合作战训练等
结果显示: 、舰机联合作战训练等
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.3791, LR: 0.0000100000
真实数据: 8各地主动创新。使别
结果显示: 8各地主动创新。使别
Epoch 0 Step 001200, model loss 0.1985, LR: 0.0000100000
真实数据: 件下，首先要谢谢你们
结果显示: 件下，首先要谢谢你们
Epoch 0 Step 001300, model loss 2.8490, LR: 0.0000100000
真实数据: 将韦尔奇的其他退休福
结果显示: 将书尔奇的其他退休福
Epoch 0 Step 001400, model loss 3.6336, LR: 0.0000100000
真实数据: 出任英格兰国家队看守
结果显示: 出任英格兰国家队看导
Epoch 0 Step 001500, model loss 10.0390, LR: 0.0000100000
真实数据: 付诸于文字，最后终于
结果显示: 付洁士于义宇，最后终于
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0230, LR: 0.0000100000
真实数据: 司作为一家高成长性的
结果显示: 司作为一家高成长性的
Epoch 0 Step 001700, model loss 0.0780, LR: 0.0000100000
真实数据: 行全球范围的影响力调
结果显示: 行全球范围的影响力调
Epoch 0 Step 001800, model loss 1.5014, LR: 0.0000100000
真实数据: 问我:每一个字母还有
结果显示: 问我:每一个字母还有
Epoch 0 Step 001900, model loss 5.4091, LR: 0.0000100000
真实数据: sbeingcaug
结果显示: sbeigca西
Epoch 0 Step 002000, model loss 13.8913, LR: 0.0000100000
真实数据: 缓慢、凌乱且充满危险
结果显示: 乒怪、凌乱且充满危险验
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.3374, LR: 0.0000100000
真实数据: 年的考试中使用上述教
结果显示: 年的考试中使用上述教
Epoch 0 Step 002200, model loss 1.4439, LR: 0.0000100000
真实数据: 命用刀。是航空气动领
结果显示: 命用7。是航空气动领
Epoch 0 Step 002300, model loss 1.6332, LR: 0.0000100000
真实数据: 淘汰机制，”比赛结束
结果显示: 淘汰机制，”比赛结束
Epoch 0 Step 002400, model loss 4.7429, LR: 0.0000100000
真实数据: 。刘询和别的皇帝不一
结果显示: 。刘询和跳的皇帝不一
Epoch 0 Step 002500, model loss 11.6567, LR: 0.0000100000
真实数据: 在社会学者李继鸿看来
结果显示: 睡社会学者李继湾看来
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 5.8355, LR: 0.0000100000
真实数据: 人书画家如高克恭、康
结果显示: 人书画家如高克教、康
Epoch 0 Step 002700, model loss 11.5485, LR: 0.0000100000
真实数据: 党方面也未放弃对胡适
结果显示: 必方面也未放弃对胡
Epoch 0 Step 002800, model loss 0.0787, LR: 0.0000100000
真实数据: 他想要什么样的工作?
结果显示: 他想要什么样的工作?
Epoch 0 Step 002900, model loss 1.2770, LR: 0.0000100000
真实数据: 续下跌到其52周以来
结果显示: 续下跌到其52周以来
Epoch 0 Step 003000, model loss 0.6830, LR: 0.0000100000
真实数据: “我读书习惯的养成，
结果显示: “我读书习惯的养成，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.1410, LR: 0.0000100000
真实数据: 行个礼儿，拜火教又称
结果显示: 行个礼儿，拜火教又称
Epoch 0 Step 003200, model loss 7.0232, LR: 0.0000100000
真实数据: 的重点环节又开展了效
结果显示: 的重点环节又开展了放
Epoch 0 Step 003300, model loss 0.7067, LR: 0.0000100000
真实数据: 俄国以“神圣同盟”骨
结果显示: 俄国以“神圣同盟”骨
Epoch 0 Step 003400, model loss 5.4726, LR: 0.0000100000
真实数据: 录取的考生不影响参加
结果显示: 录取的考生不破响参加
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002214D989258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.5772, LR: 0.0000100000
真实数据: “人无横财不富，公元
结果显示: “人无横财不富，公元
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.5712, LR: 0.0000100000
真实数据: 动云随步，在考试及就
结果显示: 动云随步，在考试及就
Epoch 0 Step 000200, model loss 0.0786, LR: 0.0000100000
真实数据: )同批次录取控制分数
结果显示: )同批次录取控制分数
Epoch 0 Step 000300, model loss 0.3021, LR: 0.0000100000
真实数据: 问题、裁判问题等一个
结果显示: 问题、裁判问题等一个
Epoch 0 Step 000400, model loss 15.3974, LR: 0.0000100000
真实数据: ，有的人脸上长了小疙
结果显示: ，有的人脸上长了小敞
Epoch 0 Step 000500, model loss 6.5360, LR: 0.0000100000
真实数据: 的老人怕起夜影响睡眠
结果显示: 的老人惟起夜影响睡剧
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.6726, LR: 0.0000100000
真实数据: 已经突破了16万亿人
结果显示: 已经突破了16万亿人
Epoch 0 Step 000700, model loss 0.2012, LR: 0.0000100000
真实数据: 刚才我们说的源动力是
结果显示: 刚才我们说的源动力是
Epoch 0 Step 000800, model loss 0.0551, LR: 0.0000100000
真实数据: 长助理、市教育局局长
结果显示: 长助理、市教育局局长
Epoch 0 Step 000900, model loss 2.8010, LR: 0.0000100000
真实数据: 了以后才感觉到做错了
结果显示: 了以后才感觉到做排了
Epoch 0 Step 001000, model loss 0.3057, LR: 0.0000100000
真实数据: 是，也不容许我们应用
结果显示: 是，也不容许我们应用
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1100, LR: 0.0000100000
真实数据: 限制外来人员进京，寻
结果显示: 限制外来人员进京，寻
Epoch 0 Step 001200, model loss 24.6567, LR: 0.0000100000
真实数据: 千吨的“毕N”舰牢牢
结果显示: 干跑的“毕异”舰卑牢
Epoch 0 Step 001300, model loss 0.0479, LR: 0.0000100000
真实数据: 997年入学的博士生
结果显示: 997年入学的博士生
Epoch 0 Step 001400, model loss 0.0902, LR: 0.0000100000
真实数据: 最大的酒店及观光事业
结果显示: 最大的酒店及观光事业
Epoch 0 Step 001500, model loss 4.4879, LR: 0.0000100000
真实数据: 一种更经济、更灵活、
结果显示: 一种更经济、更灾活、
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.6719, LR: 0.0000100000
真实数据: ，此情何毒!待天明到
结果显示: ，此情何毒!待天明到
Epoch 0 Step 001700, model loss 0.1298, LR: 0.0000100000
真实数据: 济对于台湾经济的重要
结果显示: 济对于台湾经济的重要
Epoch 0 Step 001800, model loss 1.4187, LR: 0.0000100000
真实数据: 再不要你做徒弟了!如
结果显示: 再不要你做徒弟了!如
Epoch 0 Step 001900, model loss 1.6624, LR: 0.0000100000
真实数据: 妖道:“都是你定的什
结果显示: 妖道:“都是你定的什
Epoch 0 Step 002000, model loss 0.0502, LR: 0.0000100000
真实数据: 是他们提出要把宝宝带
结果显示: 是他们提出要把宝宝带
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0805, LR: 0.0000100000
真实数据: :自1978年恢复研
结果显示: :自1978年恢复研
Epoch 0 Step 002200, model loss 3.2990, LR: 0.0000100000
真实数据: （2）印度人喜欢口述
结果显示: (2)）印度人喜欢口违
Epoch 0 Step 002300, model loss 6.3324, LR: 0.0000100000
真实数据: 机辐射对人体有没有害
结果显示: 机罪射对人体有没有害
Epoch 0 Step 002400, model loss 0.0870, LR: 0.0000100000
真实数据: 有转移。过度承重性运
结果显示: 有转移。过度承重性运
Epoch 0 Step 002500, model loss 22.7406, LR: 0.0000100000
真实数据: 严办灌夫横行乡里的罪
结果显示: 严力满夫槽行乡里的罪
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.4706, LR: 0.0000100000
真实数据: 牛行车站时，亦有适应
结果显示: 牛行车站时，亦有遥应
Epoch 0 Step 002700, model loss 23.7948, LR: 0.0000100000
真实数据: 一声不吭地抄着墙上宣
结果显示: 一声不说地摸着增上宣
Epoch 0 Step 002800, model loss 0.5042, LR: 0.0000100000
真实数据: 那么旅行社所收服务费
结果显示: 那么旅行社所收服务费
Epoch 0 Step 002900, model loss 0.1269, LR: 0.0000100000
真实数据: 银行称南方航空(行情
结果显示: 银行称南方航空(行情
Epoch 0 Step 003000, model loss 3.1822, LR: 0.0000100000
真实数据: 搜狐体育讯:就如此看
结果显示: 按狐体育讯:就如此看
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 1.5682, LR: 0.0000100000
真实数据: 0余平方公里的演习场
结果显示: 0余平方公里的演习场
Epoch 0 Step 003200, model loss 4.9883, LR: 0.0000100000
真实数据: 界还没有听说过巴黎服
结果显示: 界还没有听说过巴套服
Epoch 0 Step 003300, model loss 0.1007, LR: 0.0000100000
真实数据: 月就会推出2-3个新
结果显示: 月就会推出2-3个新
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000018E37149258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 10.2013, LR: 0.0000100000
真实数据: 只是大家都写成中古玄
结果显示: 只是大家都写成中吉家
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1325, LR: 0.0000100000
真实数据: 一个曾经占据过你生活
结果显示: 一个曾经占据过你生活
Epoch 0 Step 000200, model loss 0.0743, LR: 0.0000100000
真实数据: 他说:他一路上历过的
结果显示: 他说:他一路上历过的
Epoch 0 Step 000300, model loss 7.3214, LR: 0.0000100000
真实数据: 向社会公布两条咨询热
结果显示: 向社会公布两条管询热
Epoch 0 Step 000400, model loss 0.0847, LR: 0.0000100000
真实数据: 成为期一年的本科预备
结果显示: 成为期一年的本科预备
Epoch 0 Step 000500, model loss 1.1106, LR: 0.0000100000
真实数据: 万象的餐厅，以及WA
结果显示: 万象的餐厅，以及WA
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.5579, LR: 0.0000100000
真实数据: ，中国各大机场、航空
结果显示: ，中国各大机场、航空
Epoch 0 Step 000700, model loss 7.7885, LR: 0.0000100000
真实数据: 禄在其中矣”。不少题
结果显示: 承在其中矣”。不少延
Epoch 0 Step 000800, model loss 5.4656, LR: 0.0000100000
真实数据: 来处理fallow的
结果显示: 来处理tauow的
Epoch 0 Step 000900, model loss 3.0651, LR: 0.0000100000
真实数据: 轻松的游戏中，SIA
结果显示: 轻松的游戏中，8lA
Epoch 0 Step 001000, model loss 0.1132, LR: 0.0000100000
真实数据: 些动作幅度不小的手势
结果显示: 些动作幅度不小的手势
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 1.2995, LR: 0.0000100000
真实数据: 前辈们也曾经是“新人
结果显示: 前辈们也曾经是“新人
Epoch 0 Step 001200, model loss 0.9116, LR: 0.0000100000
真实数据: 计该公司今年业绩有望
结果显示: 计该公司今年业绩有望
Epoch 0 Step 001300, model loss 0.3890, LR: 0.0000100000
真实数据: 市民纷纷避开黄金周高
结果显示: 市民纷纷避开黄金周高
Epoch 0 Step 001400, model loss 1.0391, LR: 0.0000100000
真实数据: 学?”曰:从这个意义
结果显示: 学?”:从这个意义
Epoch 0 Step 001500, model loss 10.7710, LR: 0.0000100000
真实数据: 努力提高研发设计水平
结果显示: 象力提高研发设计水平
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.7925, LR: 0.0000100000
真实数据: 君知。酒香有时候也怕
结果显示: 君知。酒香有时候也怕
Epoch 0 Step 001700, model loss 17.3400, LR: 0.0000100000
真实数据: 人埋头涧谷，用户之间
结果显示: 人埋头润合，用户之间
Epoch 0 Step 001800, model loss 0.6715, LR: 0.0000100000
真实数据: 些方言现在已发现各地
结果显示: 些方言现在已发现各地
Epoch 0 Step 001900, model loss 0.5256, LR: 0.0000100000
真实数据: 也往往会让对方徒劳而
结果显示: 也往往会让对方徒劳而
Epoch 0 Step 002000, model loss 5.4486, LR: 0.0000100000
真实数据: 水般涌上来，”我22
结果显示: 水般巨上来，“我22
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0094, LR: 0.0000100000
真实数据: ][2][3][4]
结果显示: ][2][3][4]
Epoch 0 Step 002200, model loss 0.0506, LR: 0.0000100000
真实数据: 国日本的主要4岛面积
结果显示: 国日本的主要4岛面积
Epoch 0 Step 002300, model loss 0.3192, LR: 0.0000100000
真实数据: 业内合作下载电视连续
结果显示: 业内合作下载电视连续
Epoch 0 Step 002400, model loss 3.0610, LR: 0.0000100000
真实数据: 普雷斯顿将回到主场迎
结果显示: 普管斯顿将回到主场迎
Epoch 0 Step 002500, model loss 11.1215, LR: 0.0000100000
真实数据: 5年度报告》及其摘要
结果显示: 5年度报告》及其抗买
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 4.3860, LR: 0.0000100000
真实数据: 到2009年的81%
结果显示: 到2009年的8H%
Epoch 0 Step 002700, model loss 0.1931, LR: 0.0000100000
真实数据: 导老师或企业负责人签
结果显示: 导老师或企业负责人签
Epoch 0 Step 002800, model loss 24.6927, LR: 0.0000100000
真实数据: 僧忽一脚飞掷，据介绍
结果显示: 旅忽一脚飞据，据介绍
Epoch 0 Step 002900, model loss 1.2293, LR: 0.0000100000
真实数据: 对象是资金需求而不是
结果显示: 对象是资金需束而不是
Epoch 0 Step 003000, model loss 4.1927, LR: 0.0000100000
真实数据: 怎么就降这般恶物?”
结果显示: 复么放降这般恶物?”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 9.4661, LR: 0.0000100000
真实数据: 4月13日，(1)本
结果显示: 4月13日，(1）本
Epoch 0 Step 003200, model loss 2.6685, LR: 0.0000100000
真实数据: 是N多家企业所有的自
结果显示: 是M多家企业所有的自
Epoch 0 Step 003300, model loss 4.4335, LR: 0.0000100000
真实数据: 才能造就真正成熟的人
结果显示: 才能造就真正成射的人
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001B2A63B8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 18.9671, LR: 0.0000100000
真实数据: 处用工夫?马劣猿颠速
结果显示: 处用工夫?马劣孩虹速
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.4093, LR: 0.0000100000
真实数据: 有哪些重要的日常家庭
结果显示: 有哪些重要的日常家庭
Epoch 0 Step 000200, model loss 0.0985, LR: 0.0000100000
真实数据: 很小的事情，打开职业
结果显示: 很小的事情，打开职业
Epoch 0 Step 000300, model loss 0.4158, LR: 0.0000100000
真实数据: 方式不象大家通常想像
结果显示: 方式不象大家通常想像
Epoch 0 Step 000400, model loss 0.3708, LR: 0.0000100000
真实数据: 公司董事会现发布召开
结果显示: 公司董事会现发布召开
Epoch 0 Step 000500, model loss 0.1124, LR: 0.0000100000
真实数据: 我才能找到真正的乐趣
结果显示: 我才能找到真正的乐趣
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 23.7066, LR: 0.0000100000
真实数据: 第一次大汗淋漓的战栗
结果显示: 第一次大汗常满的战米
Epoch 0 Step 000700, model loss 2.8760, LR: 0.0000100000
真实数据: 生怕百密一疏。帮助解
结果显示: 生怕百密一疏。帮助解
Epoch 0 Step 000800, model loss 14.6297, LR: 0.0000100000
真实数据: 她在比赛中有6次破发
结果显示: 竭企嗡赛中有6次破发
Epoch 0 Step 000900, model loss 0.3875, LR: 0.0000100000
真实数据: 究发现，但是从英国回
结果显示: 究发现，但是从英国回
Epoch 0 Step 001000, model loss 0.1853, LR: 0.0000100000
真实数据: )128,简直是天方
结果显示: )128,简直是天方
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 6.0040, LR: 0.0000100000
真实数据: 结束了婚姻。而200
结果显示: 结束了婚郊。而200
Epoch 0 Step 001200, model loss 0.2745, LR: 0.0000100000
真实数据: 化了对一体化联合作战
结果显示: 化了对一体化联合作战
Epoch 0 Step 001300, model loss 32.3711, LR: 0.0000100000
真实数据: 象下山猛虎，黏黏糊糊
结果显示: 象下山猛虎，纡犯哉
Epoch 0 Step 001400, model loss 12.5039, LR: 0.0000100000
真实数据: 负。一方不要，”石洒
结果显示: 负。一方不要，”石酒
Epoch 0 Step 001500, model loss 24.0049, LR: 0.0000100000
真实数据: 成为一些人寻租牟取的
结果显示: 成为一些人寻租华取的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0495, LR: 0.0000100000
真实数据: 告诉我，可喜，《外交
结果显示: 告诉我，可喜，《外交
Epoch 0 Step 001700, model loss 1.0351, LR: 0.0000100000
真实数据: 不出，热衷的就两件事
结果显示: 不出，热衷的就两件事
Epoch 0 Step 001800, model loss 4.7588, LR: 0.0000100000
真实数据: 捕》真不是部什么好电
结果显示: 抽》真不是部什么好电
Epoch 0 Step 001900, model loss 2.7619, LR: 0.0000100000
真实数据: 新型的国家;自罗马帝
结果显示: 新型的国家;自罗马审
Epoch 0 Step 002000, model loss 0.4889, LR: 0.0000100000
真实数据: 农村师资的重要组成部
结果显示: 农村师资的重要组成部
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 6.0361, LR: 0.0000100000
真实数据: 赐教。另一方面也不能
结果显示: 购教。另一方面也不能
Epoch 0 Step 002200, model loss 5.2272, LR: 0.0000100000
真实数据: 不要去搞那些空洞的演
结果显示: 不要去摘那些空洞的演
Epoch 0 Step 002300, model loss 7.0558, LR: 0.0000100000
真实数据: 反腐败的部门和舆论应
结果显示: 反腐败的部门和典论应
Epoch 0 Step 002400, model loss 2.7501, LR: 0.0000100000
真实数据: 例子，义和团既遍京师
结果显示: 例子，义和团既遍京师
Epoch 0 Step 002500, model loss 0.2848, LR: 0.0000100000
真实数据: 么歌名歌词都想不起来
结果显示: 么歌名歌词都想不起来
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.8311, LR: 0.0000100000
真实数据: 特意安排一位年轻美貌
结果显示: 特意安排一位年轻美貌
Epoch 0 Step 002700, model loss 0.8183, LR: 0.0000100000
真实数据: 很难进入深睡期。盖为
结果显示: 很难进入深睡期。盖为
Epoch 0 Step 002800, model loss 10.7100, LR: 0.0000100000
真实数据: 跟着走了。没有压迫、
结果显示: 酬着走了。没有压口.
Epoch 0 Step 002900, model loss 7.4948, LR: 0.0000100000
真实数据: 是就这么一眨眼的工夫
结果显示: 是就这么一腿眼的工夫
Epoch 0 Step 003000, model loss 6.8569, LR: 0.0000100000
真实数据: 混编成两支队伍进行了
结果显示: 呢编成两支队伍进行了
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 7.5592, LR: 0.0000100000
真实数据: 有垄断优势。是更先进
结果显示: 有裱塑断优势。是更先进
Epoch 0 Step 003200, model loss 8.3171, LR: 0.0000100000
真实数据: 气候更加有效地抵制了
结果显示: 气候更加有效地换制了
Epoch 0 Step 003300, model loss 4.8729, LR: 0.0000100000
真实数据: nB.Carter对
结果显示: n已.Carter对
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002729C6D9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 15.0068, LR: 0.0000100000
真实数据: 滩、啤酒、音乐、民族
结果显示: 郯、陈酒、音乐、民族
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 2.3479, LR: 0.0000100000
真实数据: 阿海没有及时追讨那笔
结果显示: 同海没有及时追讨那笔
Epoch 0 Step 000200, model loss 2.1459, LR: 0.0000100000
真实数据: 毕业生的就业方向收获
结果显示: 业生的就业方向收获
Epoch 0 Step 000300, model loss 7.3284, LR: 0.0000100000
真实数据: 我们在贵州大山里扶贫
结果显示: 我们在固州大山里扶贫
Epoch 0 Step 000400, model loss 2.0702, LR: 0.0000100000
真实数据: ，成为相互鼓励并肩完
结果显示: ，成为相互鼓显并肩完
Epoch 0 Step 000500, model loss 15.5609, LR: 0.0000100000
真实数据: 过1厘米(剑突下不超
结果显示: 过1厦米(创突下不起
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 18.7169, LR: 0.0000100000
真实数据: 拳民遂哄然道:改造了
结果显示: 蒙民邀嘴然道:改造了
Epoch 0 Step 000700, model loss 8.3001, LR: 0.0000100000
真实数据: 好监考人员的培训工作
结果显示: 好琪考人员的训工作
Epoch 0 Step 000800, model loss 20.3796, LR: 0.0000100000
真实数据: 都赞助苏维埃政府。怆
结果显示: 都赞助苏维填政府。抢
Epoch 0 Step 000900, model loss 0.0717, LR: 0.0000100000
真实数据: 我们在寻找一个现象的
结果显示: 我们在寻找一个现象的
Epoch 0 Step 001000, model loss 0.1332, LR: 0.0000100000
真实数据: 用后会给身体造成极大
结果显示: 用后会给身体造成极大
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1510, LR: 0.0000100000
真实数据: 在没有报团的可能五一
结果显示: 在没有报团的可能五一
Epoch 0 Step 001200, model loss 33.8081, LR: 0.0000100000
真实数据: 。毛昱衡近年来疏于战
结果显示: 。毛显调近年来流于战
Epoch 0 Step 001300, model loss 20.7723, LR: 0.0000100000
真实数据: 有点对工作有厌倦情绪
结果显示: 有点对工作有反德情绕
Epoch 0 Step 001400, model loss 0.0065, LR: 0.0000100000
真实数据: 如果自己属于这种比较
结果显示: 如果自己属于这种比较
Epoch 0 Step 001500, model loss 1.0818, LR: 0.0000100000
真实数据: 照你选的答案后面的指
结果显示: 照你选的答案后面的指
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 41.0556, LR: 0.0000100000
真实数据: 十锭，金井梧桐秋叶黄
结果显示: 十键，金井爆柜秋叶黄
Epoch 0 Step 001700, model loss 0.0175, LR: 0.0000100000
真实数据: 发信息化、生产装备数
结果显示: 发信息化、生产装备数
Epoch 0 Step 001800, model loss 0.5974, LR: 0.0000100000
真实数据: 能反映人类的体质特征
结果显示: 能反映人类的体质特征
Epoch 0 Step 001900, model loss 0.0712, LR: 0.0000100000
真实数据: 的穷人经济学问题给一
结果显示: 的穷人经济学问题给一
Epoch 0 Step 002000, model loss 12.1316, LR: 0.0000100000
真实数据: 经自查,于那合缝之处
结果显示: 经自查，于那合线之处
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0782, LR: 0.0000100000
真实数据: ?考试时若没有特殊的
结果显示: ?考试时若没有特殊的
Epoch 0 Step 002200, model loss 0.0091, LR: 0.0000100000
真实数据: 做子女的是多么为他们
结果显示: 做子女的是多么为他们
Epoch 0 Step 002300, model loss 3.4599, LR: 0.0000100000
真实数据: 碰到生词了!但是这还
结果显示: 碰到生调了!但是这还
Epoch 0 Step 002400, model loss 0.0251, LR: 0.0000100000
真实数据: 除2004年的房地产
结果显示: 除2004年的房地产
Epoch 0 Step 002500, model loss 9.0313, LR: 0.0000100000
真实数据: 和谐，三你好吗?我们
结果显示: 和，三你好吗?我们
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0358, LR: 0.0000100000
真实数据: 38年的《论持久战》
结果显示: 38年的《论持久战》
Epoch 0 Step 002700, model loss 1.5819, LR: 0.0000100000
真实数据: 辞去②(to)使顺从
结果显示: 辞去②(to)使顺从
Epoch 0 Step 002800, model loss 0.0884, LR: 0.0000100000
真实数据: 感染后导致腐烂造成的
结果显示: 感染后导致腐烂造成的
Epoch 0 Step 002900, model loss 0.4234, LR: 0.0000100000
真实数据: 利福尼亚州举行的一次
结果显示: 利福尼亚州举行的一次
Epoch 0 Step 003000, model loss 1.6878, LR: 0.0000100000
真实数据: 个患者使用的产品都可
结果显示: 个者使用的产品都可
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 3.1636, LR: 0.0000100000
真实数据: 性的错误，force
结果显示: 性的错误，forcce
Epoch 0 Step 003200, model loss 4.3420, LR: 0.0000100000
真实数据: 来看，该公司在无锡的
结果显示: 来看，该公司在无惧的
Epoch 0 Step 003300, model loss 1.2145, LR: 0.0000100000
真实数据: 与华立集团有限公司签
结果显示: 与华立集团有限公司券
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001EEDBDFA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 9.3650, LR: 0.0000100000
真实数据: 偶及曩年无归，第七步
结果显示: 偶及影年无归，第七步
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0247, LR: 0.0000100000
真实数据: 几个单词是反复出现的
结果显示: 几个单词是反复出现的
Epoch 0 Step 000200, model loss 0.2773, LR: 0.0000100000
真实数据: 是一条韩企特有的办公
结果显示: 是一条韩企特有的办公
Epoch 0 Step 000300, model loss 4.4610, LR: 0.0000100000
真实数据: 表面粗黏，”老婆奇怪
结果显示: 表面粗黎，”老婆奋怪
Epoch 0 Step 000400, model loss 23.7947, LR: 0.0000100000
真实数据: 32岁的罗炳辉加入了
结果显示: 32岁的罗场挥加又了
Epoch 0 Step 000500, model loss 3.3856, LR: 0.0000100000
真实数据: 个沃尔夫林或贡布里希
结果显示: 个沃尔夫林或责布里希
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 4.6233, LR: 0.0000100000
真实数据: 航班运行情况调整运营
结果显示: 航被运行情况调整通营
Epoch 0 Step 000700, model loss 0.6338, LR: 0.0000100000
真实数据: 历史上非常着名而有趣
结果显示: 历史上非常着名而有趣
Epoch 0 Step 000800, model loss 3.1637, LR: 0.0000100000
真实数据: 2.错开与水果食用的
结果显示: 2.带开与永果食用的
Epoch 0 Step 000900, model loss 2.1449, LR: 0.0000100000
真实数据: 尔玛队8胜9平13负
结果显示: 尔玛队8脏9平13负
Epoch 0 Step 001000, model loss 5.1312, LR: 0.0000100000
真实数据: E据最高人民法院去年
结果显示: 防据最高人民法院去年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.4587, LR: 0.0000100000
真实数据: 部分士兵为了能得到解
结果显示: 部分士兵为了能得到解
Epoch 0 Step 001200, model loss 6.6507, LR: 0.0000100000
真实数据: 望党人合力查此事原因
结果显示: 四党人合力查此事原国
Epoch 0 Step 001300, model loss 0.7457, LR: 0.0000100000
真实数据: 出意想不到的举动来。
结果显示: 出意想不到的举动来。
Epoch 0 Step 001400, model loss 27.2034, LR: 0.0000100000
真实数据: 搜狐ITUnifyt
结果显示: 披条JTLniy
Epoch 0 Step 001500, model loss 4.1457, LR: 0.0000100000
真实数据: 样做只会在两岸之间制
结果显示: 样做只会在两岸之问制
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 1.0107, LR: 0.0000100000
真实数据: 2并非书看得越多越好
结果显示: 2并非书看得越多越好
Epoch 0 Step 001700, model loss 0.0057, LR: 0.0000100000
真实数据: 实话实说，都会有巨大
结果显示: 实话实说，都会有巨大
Epoch 0 Step 001800, model loss 0.9512, LR: 0.0000100000
真实数据: 与社会主义精神文明建
结果显示: 与社会主义精神文明建
Epoch 0 Step 001900, model loss 2.5769, LR: 0.0000100000
真实数据: 组织实践课程的安排与
结果显示: 组织实腹课程的安排与
Epoch 0 Step 002000, model loss 1.8950, LR: 0.0000100000
真实数据: 前20天（+做白皮书
结果显示: 前20天（+做自皮书
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 17.6474, LR: 0.0000100000
真实数据: 诉丈夫，红豆粥/木瓜
结果显示: 诉丈夫，红豆刑/木社
Epoch 0 Step 002200, model loss 6.3882, LR: 0.0000100000
真实数据: 载排水量69360吨
结果显示: 季择水量69360吨
Epoch 0 Step 002300, model loss 13.1211, LR: 0.0000100000
真实数据: 备完善、管理手段先进
结果显示: 备充普、管理手段先遂
Epoch 0 Step 002400, model loss 0.0405, LR: 0.0000100000
真实数据: 我觉得无所谓，[34
结果显示: 我觉得无所谓，[34
Epoch 0 Step 002500, model loss 6.8168, LR: 0.0000100000
真实数据: 只是几个偏远的小渔村
结果显示: 只是几个偏远的小演村
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1480, LR: 0.0000100000
真实数据: 0月21日正式确定意
结果显示: 0月21日正式确定意
Epoch 0 Step 002700, model loss 0.0408, LR: 0.0000100000
真实数据: 而藏之。但隔了几个月
结果显示: 而藏之。但隔了几个月
Epoch 0 Step 002800, model loss 5.1194, LR: 0.0000100000
真实数据: 鼻涕多似眼泪地号哭道
结果显示: 鼻渊参多似眼泪地号哭道
Epoch 0 Step 002900, model loss 0.0613, LR: 0.0000100000
真实数据: 占总股本的42.65
结果显示: 占总股本的42.65
Epoch 0 Step 003000, model loss 0.2228, LR: 0.0000100000
真实数据: 方面景区的人气还不够
结果显示: 方面景区的人气还不够
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0419, LR: 0.0000100000
真实数据: :0现在在我们医院能
结果显示: :0现在在我们医院能
Epoch 0 Step 003200, model loss 4.7289, LR: 0.0000100000
真实数据: 、食品和餐具到温泉处
结果显示: 、食品和报具到温泉处
Epoch 0 Step 003300, model loss 0.0635, LR: 0.0000100000
真实数据: 外汉语二级学科博士点
结果显示: 外汉语二级学科博士点
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000260704B9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.4789, LR: 0.0000100000
真实数据: 互让不肯前。也就是说
结果显示: 互让不肯前。也就是说
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.6671, LR: 0.0000100000
真实数据: 我们也只能沉着应战了
结果显示: 我们也只能沉着应战了
Epoch 0 Step 000200, model loss 0.5507, LR: 0.0000100000
真实数据: 国家利益是需要考虑的
结果显示: 国家利益是需要考虑的
Epoch 0 Step 000300, model loss 0.0068, LR: 0.0000100000
真实数据: 了晚上，两个人打了个
结果显示: 了晚上，两个人打了个
Epoch 0 Step 000400, model loss 1.5882, LR: 0.0000100000
真实数据: 的白领丽人在接待客户
结果显示: 的白领丽人在接待容户
Epoch 0 Step 000500, model loss 1.8412, LR: 0.0000100000
真实数据: H集团资产达到330
结果显示: 1集团资产达到330
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 3.9804, LR: 0.0000100000
真实数据: 法，“我初不欲为儿娶
结果显示: 法，“我初不欲为儿要
Epoch 0 Step 000700, model loss 7.5517, LR: 0.0000100000
真实数据: 统一的价格销售歌曲（
结果显示: 境一的价格销售歌曲（
Epoch 0 Step 000800, model loss 6.1068, LR: 0.0000100000
真实数据: 朝父。先是，价格超滑
结果显示: 朝父.先是，价格趣滑
Epoch 0 Step 000900, model loss 1.1024, LR: 0.0000100000
真实数据: 汝非某班投耶?”惊问
结果显示: 汝非某班投耶?”惊问
Epoch 0 Step 001000, model loss 0.1492, LR: 0.0000100000
真实数据: 美空军对空中、太空和
结果显示: 美空军对空中、太空和
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 11.7188, LR: 0.0000100000
真实数据: 控实验室数据向新加坡
结果显示: 控实验室数冠向新加响
Epoch 0 Step 001200, model loss 0.2981, LR: 0.0000100000
真实数据: 右后的北大一次大解救
结果显示: 右后的北大一次大解救
Epoch 0 Step 001300, model loss 2.8150, LR: 0.0000100000
真实数据: 一般建议喝30℃以下
结果显示: 一般建议喝30以下
Epoch 0 Step 001400, model loss 6.5542, LR: 0.0000100000
真实数据: 源所在省级招办正式公
结果显示: 源所在管极招办正式公
Epoch 0 Step 001500, model loss 4.5008, LR: 0.0000100000
真实数据: 轮接一轮，上海贝尔阿
结果显示: 轮接一轮，上海负尔回
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.1406, LR: 0.0000100000
真实数据: 创业投资公司苏州证券
结果显示: 创业投资公司苏州证券
Epoch 0 Step 001700, model loss 0.6094, LR: 0.0000100000
真实数据: 刘勇这种智力低下是由
结果显示: 刘勇这种智力低下是由
Epoch 0 Step 001800, model loss 0.7518, LR: 0.0000100000
真实数据: 干地区自古就是欧洲大
结果显示: 干地区自古就是欧洲大
Epoch 0 Step 001900, model loss 0.0310, LR: 0.0000100000
真实数据: 也就是“工业精神”。
结果显示: 也就是“工业精神”。
Epoch 0 Step 002000, model loss 2.5684, LR: 0.0000100000
真实数据: 间必是妖邪赶急钻文责
结果显示: 间必是妖邪赶急钻文责
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0273, LR: 0.0000100000
真实数据: 发生心血管事件的危险
结果显示: 发生心血管事件的危险
Epoch 0 Step 002200, model loss 6.3290, LR: 0.0000100000
真实数据: 发展为肝硬化及肝癌(
结果显示: 发展为肝硬化及历肝瘤(
Epoch 0 Step 002300, model loss 2.0854, LR: 0.0000100000
真实数据: 计时按自然水流方向布
结果显示: 计时按自然水流方向布
Epoch 0 Step 002400, model loss 7.6095, LR: 0.0000100000
真实数据: 个落但这里指的是晒干
结果显示: 个落但这里指的是盾干
Epoch 0 Step 002500, model loss 0.7786, LR: 0.0000100000
真实数据: 之战出现了戏剧性的一
结果显示: 之战出现了戏剧性的一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.2194, LR: 0.0000100000
真实数据: 不顾年事已高，读者据
结果显示: 不顾年事已高，读者据
Epoch 0 Step 002700, model loss 8.6370, LR: 0.0000100000
真实数据: 目前，便以「体弱需静
结果显示: 目前，使以体弱需前
Epoch 0 Step 002800, model loss 0.2890, LR: 0.0000100000
真实数据: 四种语言开考了117
结果显示: 四种语言开考了117
Epoch 0 Step 002900, model loss 18.9475, LR: 0.0000100000
真实数据: 于重庆力帆在新帅徐弘
结果显示: 于重庆力期在新财涂
Epoch 0 Step 003000, model loss 1.7904, LR: 0.0000100000
真实数据: 必要提醒更多的后来者
结果显示: 必要提配更多的后来者
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.3628, LR: 0.0000100000
真实数据: 令后的飞行学员急拉降
结果显示: 令后的飞行学员急拉降
Epoch 0 Step 003200, model loss 0.0242, LR: 0.0000100000
真实数据: “没有自主健全的软件
结果显示: “没有自主健全的软件
Epoch 0 Step 003300, model loss 0.4173, LR: 0.0000100000
真实数据: 业后从事摄影记者和编
结果显示: 业后从事摄影记者和编
Epoch 0 Step 003400, model loss 2.8932, LR: 0.0000100000
真实数据: 是正式与非正式的聚会
结果显示: 是正式与非正式的易会
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001BF61BD9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.2191, LR: 0.0000100000
真实数据: 有表示海岛地理位置的
结果显示: 有表示海岛地理位置的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 10.1926, LR: 0.0000100000
真实数据: 凡是被电脑套牢的一族
结果显示: 凡是被电独套半的一族
Epoch 0 Step 000200, model loss 0.0343, LR: 0.0000100000
真实数据: 远的伟人:据记者了解
结果显示: 远的伟人:据记者了解
Epoch 0 Step 000300, model loss 0.5207, LR: 0.0000100000
真实数据: 的住房）比例占据了4
结果显示: 的住房）比例占据了4
Epoch 0 Step 000400, model loss 1.5907, LR: 0.0000100000
真实数据: 要的那4架则在PAC
结果显示: 要的那4架则在PAC
Epoch 0 Step 000500, model loss 0.5507, LR: 0.0000100000
真实数据: 卢小姐的朋友中也有不
结果显示: 卢小姐的朋友中也有不
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.3065, LR: 0.0000100000
真实数据: 不思进取，思想上有了
结果显示: 不思进取，思想上有了
Epoch 0 Step 000700, model loss 8.2296, LR: 0.0000100000
真实数据: -哈尔滨[图库]航线
结果显示: -吃尔高[图库地航线
Epoch 0 Step 000800, model loss 0.2131, LR: 0.0000100000
真实数据: 忽视质量、环境、社区
结果显示: 忽视质量、环境、社区
Epoch 0 Step 000900, model loss 0.0188, LR: 0.0000100000
真实数据: 将今次宏调视作重大危
结果显示: 将今次宏调视作重大危
Epoch 0 Step 001000, model loss 0.9455, LR: 0.0000100000
真实数据: 在连续三届的汤杯中，
结果显示: 在连续三届的汤杯中，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.5401, LR: 0.0000100000
真实数据: tCookie("s
结果显示: tCookie("s
Epoch 0 Step 001200, model loss 17.0878, LR: 0.0000100000
真实数据: 洛依德氏无意间读到此
结果显示: 治倍德氏无意际该到此
Epoch 0 Step 001300, model loss 8.9347, LR: 0.0000100000
真实数据: 密这样的概念太难界定
结果显示: 漠这样的概念太罚界定
Epoch 0 Step 001400, model loss 11.0901, LR: 0.0000100000
真实数据: 久坐马桶使排便时间延
结果显示: 久坐马檠使排便时间题
Epoch 0 Step 001500, model loss 0.2059, LR: 0.0000100000
真实数据: 流高峰期运能与运量的
结果显示: 流高峰期运能与运量的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.6834, LR: 0.0000100000
真实数据: 个潜力无穷的理财高手
结果显示: 个潜力无穷的理财高手
Epoch 0 Step 001700, model loss 1.0479, LR: 0.0000100000
真实数据: 理价格区间是5.4-
结果显示: 理价格区间是5.4一
Epoch 0 Step 001800, model loss 0.1431, LR: 0.0000100000
真实数据: 景点的则可增加女性补
结果显示: 景点的则可增加女性补
Epoch 0 Step 001900, model loss 1.6888, LR: 0.0000100000
真实数据: 些价值都还是体现出来
结果显示: 些价值都还是体现出来
Epoch 0 Step 002000, model loss 0.4581, LR: 0.0000100000
真实数据: 学校设本科专业78个
结果显示: 学校设本科专业78个
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.1086, LR: 0.0000100000
真实数据: 在哪里?什么样的教育
结果显示: 在哪里?什么样的教育
Epoch 0 Step 002200, model loss 6.6399, LR: 0.0000100000
真实数据: 主掌全军后勤工作的廖
结果显示: 主掌全军后勤工作的摩
Epoch 0 Step 002300, model loss 0.0886, LR: 0.0000100000
真实数据: （如何认识、理解、看
结果显示: （如何认识、理解、看
Epoch 0 Step 002400, model loss 0.0284, LR: 0.0000100000
真实数据: 中国的房价确实被高估
结果显示: 中国的房价确实被高估
Epoch 0 Step 002500, model loss 1.6268, LR: 0.0000100000
真实数据: 决一些创造性的课题和
结果显示: 决一些创造性的课题和
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 33.6467, LR: 0.0000100000
真实数据: 本方面对“猛禽”觊觎
结果显示: 本方面对“猛食”凯能
Epoch 0 Step 002700, model loss 16.6195, LR: 0.0000100000
真实数据: 尔挟红土球场47连胜
结果显示: 尔横红士球场47连胜
Epoch 0 Step 002800, model loss 0.9718, LR: 0.0000100000
真实数据: 一旦这个假死人试图反
结果显示: ―旦这个假死人试图反
Epoch 0 Step 002900, model loss 10.6561, LR: 0.0000100000
真实数据: 他耸耸肩无奈地笑了笑
结果显示: 他单单肩无奈地笑了笑
Epoch 0 Step 003000, model loss 0.6469, LR: 0.0000100000
真实数据: 成不少于450学时的
结果显示: 成不少于450学时的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.3937, LR: 0.0000100000
真实数据: “中央社”报道说，非
结果显示: “中央社”报道说，非
Epoch 0 Step 003200, model loss 0.8295, LR: 0.0000100000
真实数据: ofstrasse街
结果显示: ofstrasse街
Epoch 0 Step 003300, model loss 0.0777, LR: 0.0000100000
真实数据: 中的多数党有权组成政
结果显示: 中的多数党有权组成政
Epoch 0 Step 003400, model loss 1.0009, LR: 0.0000100000
真实数据: 率领我们向指定地点出
结果显示: 率领我们向指定地点出
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000019B2D359258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.3983, LR: 0.0000100000
真实数据: 有的乡完成了计划生育
结果显示: 有的乡完成了计划生育
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.6048, LR: 0.0000100000
真实数据: 谢不敢。今天的联合指
结果显示: 谢不敢。今天的联合指
Epoch 0 Step 000200, model loss 0.1979, LR: 0.0000100000
真实数据: 记者:使人们能一边做
结果显示: 记者:使人们能一边做
Epoch 0 Step 000300, model loss 2.2338, LR: 0.0000100000
真实数据: 来，王新欣非常自信地
结果显示: 来，王新欣昨常自信地
Epoch 0 Step 000400, model loss 6.9085, LR: 0.0000100000
真实数据: 直塞，而值的表现则不
结果显示: 直妻，而值的表现则不
Epoch 0 Step 000500, model loss 4.2125, LR: 0.0000100000
真实数据: 2深入苏联侦察总计2
结果显示: 2深入苏联察总计2
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.1317, LR: 0.0000100000
真实数据: 难道我越南人就不能吗
结果显示: 难道我越南人就不能吗
Epoch 0 Step 000700, model loss 0.1630, LR: 0.0000100000
真实数据: 制造飞机也不算什么了
结果显示: 制造飞机也不算什么了
Epoch 0 Step 000800, model loss 4.1871, LR: 0.0000100000
真实数据: 甚至是刚毕业的大学生
结果显示: 甚至是刚]毕业的大学生
Epoch 0 Step 000900, model loss 0.0283, LR: 0.0000100000
真实数据: 治区招生办公室同意后
结果显示: 治区招生办公室同意后
Epoch 0 Step 001000, model loss 1.0878, LR: 0.0000100000
真实数据: 不得不硬这头皮，（星
结果显示: 不得不硬这头皮，（星
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 8.0326, LR: 0.0000100000
真实数据: 时，因此毛泽东曾明确
结果显示: 时，因此毛东曾明确
Epoch 0 Step 001200, model loss 2.0970, LR: 0.0000100000
真实数据: 以便抽取特别参与奖。
结果显示: 以便拖取特别参与奖。
Epoch 0 Step 001300, model loss 9.2141, LR: 0.0000100000
真实数据: “禁区之王”大感屈辱
结果显示: “区之王”大感屈辱
Epoch 0 Step 001400, model loss 19.6904, LR: 0.0000100000
真实数据: 这使我的生命化为灰烬
结果显示: 这使我的生命化为姆
Epoch 0 Step 001500, model loss 5.0971, LR: 0.0000100000
真实数据: 其故，始敢与言，尽歼
结果显示: 其故，始敢与言，尽列
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.2049, LR: 0.0000100000
真实数据: 东源深体育场都不知道
结果显示: 东源深体育场都不知道
Epoch 0 Step 001700, model loss 0.0135, LR: 0.0000100000
真实数据: 会取得精神和心理上的
结果显示: 会取得精神和心理上的
Epoch 0 Step 001800, model loss 0.1957, LR: 0.0000100000
真实数据: 矣。形成一整套完善的
结果显示: 矣。形成一整套完善的
Epoch 0 Step 001900, model loss 0.3513, LR: 0.0000100000
真实数据: 狐兵，攻读“变化管理
结果显示: 狐兵，攻读“变化管理
Epoch 0 Step 002000, model loss 1.4008, LR: 0.0000100000
真实数据: 因状似一片云彩而得名
结果显示: 因状似一片云彩而得名
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.5906, LR: 0.0000100000
真实数据: 合肥东南手外科医院急
结果显示: 合腿东南手外科医院急
Epoch 0 Step 002200, model loss 2.1111, LR: 0.0000100000
真实数据: 来。今年是实行监督巡
结果显示: 来。今年是实行监督巡
Epoch 0 Step 002300, model loss 4.1771, LR: 0.0000100000
真实数据: 2005年秋季入学时
结果显示: 2005年秋李入学时
Epoch 0 Step 002400, model loss 0.3436, LR: 0.0000100000
真实数据: ，调阅报告指出，这声
结果显示: ，调阅报告指出，这声
Epoch 0 Step 002500, model loss 0.1601, LR: 0.0000100000
真实数据: 旦大学附属中山医院营
结果显示: 旦大学附属中山医院营
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 4.7620, LR: 0.0000100000
真实数据: 人服食下金刚石粉末后
结果显示: 人限食下金刚石松末后
Epoch 0 Step 002700, model loss 0.0541, LR: 0.0000100000
真实数据: 里芬是在25日出席参
结果显示: 里芬是在25日出席参
Epoch 0 Step 002800, model loss 4.5807, LR: 0.0000100000
真实数据: 撞，遂相惊以狐。二来
结果显示: 偿，透相惊以狐。二来
Epoch 0 Step 002900, model loss 1.7101, LR: 0.0000100000
真实数据: 它所产生的影响将更加
结果显示: 它所产生的影史将更加
Epoch 0 Step 003000, model loss 0.0324, LR: 0.0000100000
真实数据: 年中国开始组队参加尤
结果显示: 年中国开始组队参加尤
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0816, LR: 0.0000100000
真实数据: 得此命名是因为美国侵
结果显示: 得此命名是因为美国侵
Epoch 0 Step 003200, model loss 0.9448, LR: 0.0000100000
真实数据: 者长期休息不足还会继
结果显示: 者长期休息不足还会继
Epoch 0 Step 003300, model loss 8.9531, LR: 0.0000100000
真实数据: 一定是被钉在了地板上
结果显示: 一定是被莠在了地板上
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E149EBA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.5569, LR: 0.0000100000
真实数据: 秒900米、声速每秒
结果显示: 秒900米、声速每秒
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0228, LR: 0.0000100000
真实数据: 提出有关做好笔记的建
结果显示: 提出有关做好笔记的建
Epoch 0 Step 000200, model loss 27.5372, LR: 0.0000100000
真实数据: 聚茅焚之，而不能禁之
结果显示: 报菜艾之，而不能禁之
Epoch 0 Step 000300, model loss 4.8153, LR: 0.0000100000
真实数据: 就要吵。表面上是商业
结果显示: 就要炒。表面上是商业
Epoch 0 Step 000400, model loss 11.5210, LR: 0.0000100000
真实数据: 、新药动态及诊断案例
结果显示: ,新费动态及资断案例
Epoch 0 Step 000500, model loss 17.5940, LR: 0.0000100000
真实数据: 日积月累，他告诉记者
结果显示: 目和月易，他告记者
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 1.5214, LR: 0.0000100000
真实数据: 平均为1936元;步
结果显示: 平地均为1936元;步
Epoch 0 Step 000700, model loss 11.1155, LR: 0.0000100000
真实数据: 拳头”武器――核潜艇
结果显示: 券头”武器――核潜征
Epoch 0 Step 000800, model loss 0.0386, LR: 0.0000100000
真实数据: 础的组织能力一旦创造
结果显示: 础的组织能力一旦创造
Epoch 0 Step 000900, model loss 0.0062, LR: 0.0000100000
真实数据: 他觉得什么样的标准可
结果显示: 他觉得什么样的标准可
Epoch 0 Step 001000, model loss 0.1082, LR: 0.0000100000
真实数据: “穿马甲”成为了流行
结果显示: “穿马甲”成为了流行
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.6149, LR: 0.0000100000
真实数据: 08奥运脚步一天天临
结果显示: 08奥运斤步一天天临
Epoch 0 Step 001200, model loss 10.9430, LR: 0.0000100000
真实数据: 特别提示:公8月下旬
结果显示: 特另提示:公8月下郁
Epoch 0 Step 001300, model loss 0.1010, LR: 0.0000100000
真实数据: 行业参与调研的公司所
结果显示: 行业参与调研的公司所
Epoch 0 Step 001400, model loss 1.9074, LR: 0.0000100000
真实数据: 力相当雄厚。2003
结果显示: 力相当雄厚。2003
Epoch 0 Step 001500, model loss 2.1365, LR: 0.0000100000
真实数据: 尼去，0散杂货吞吐量
结果显示: 尼去，0散杂货吞叶量
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0756, LR: 0.0000100000
真实数据: 得优势，但是中国你们
结果显示: 得优势，但是中国你们
Epoch 0 Step 001700, model loss 0.0997, LR: 0.0000100000
真实数据: 话的方式、速度、声调
结果显示: 话的方式、速度、声调
Epoch 0 Step 001800, model loss 0.2953, LR: 0.0000100000
真实数据: 南拜，搜狐直播员:武
结果显示: 南拜，搜狐直播员:武
Epoch 0 Step 001900, model loss 0.4336, LR: 0.0000100000
真实数据: 手机显然是不受“三包
结果显示: 手机显然是不受“三包
Epoch 0 Step 002000, model loss 0.4989, LR: 0.0000100000
真实数据: 如?狐曰:进而影响A
结果显示: 如?狐曰:进而影响A
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 15.4209, LR: 0.0000100000
真实数据: 相关网页.当毛泽东逝
结果显示: 相关网灵当毛泽东巡
Epoch 0 Step 002200, model loss 1.1102, LR: 0.0000100000
真实数据: 也去了徐家大院，“不
结果显示: 也去了徐家大院，“不
Epoch 0 Step 002300, model loss 2.5570, LR: 0.0000100000
真实数据: 中的杰出表现和对中国
结果显示: 中的森出表现和对中国
Epoch 0 Step 002400, model loss 0.1244, LR: 0.0000100000
真实数据: 它的增发却有其特殊性
结果显示: 它的增发却有其特殊性
Epoch 0 Step 002500, model loss 3.9902, LR: 0.0000100000
真实数据: 觉得跑步小腿会变粗，
结果显示: 觉得跑步小腿会变祖，
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0334, LR: 0.0000100000
真实数据: 本学者常用的提问方式
结果显示: 本学者常用的提问方式
Epoch 0 Step 002700, model loss 1.2686, LR: 0.0000100000
真实数据: 人日渐返朴归真，像一
结果显示: 人日渐返朴归真，像一
Epoch 0 Step 002800, model loss 0.0213, LR: 0.0000100000
真实数据: 一:0爱多商标持有人
结果显示: 一:0爱多商标持有人
Epoch 0 Step 002900, model loss 6.4818, LR: 0.0000100000
真实数据: 利办好Checkin
结果显示: 利办好Cheekia
Epoch 0 Step 003000, model loss 0.0082, LR: 0.0000100000
真实数据: 不仅是资金流向的变动
结果显示: 不仅是资金流向的变动
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.1764, LR: 0.0000100000
真实数据: 心的是“多边核力量”
结果显示: 心的是“多边核力量”
Epoch 0 Step 003200, model loss 0.0068, LR: 0.0000100000
真实数据: 明对《经济》说:“这
结果显示: 明对《经济》说:“这
Epoch 0 Step 003300, model loss 6.4915, LR: 0.0000100000
真实数据: 孟凯帝意大利驻华大使
结果显示: 凯帝意大利驻华大使
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001FEDE179258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0421, LR: 0.0000100000
真实数据: 种潜意识里面的天朝主
结果显示: 种潜意识里面的天朝主
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 30.5299, LR: 0.0000100000
真实数据: 但容易安慰，呼声綦惨
结果显示: 但容易安慰，呼跨基修
Epoch 0 Step 000200, model loss 0.0231, LR: 0.0000100000
真实数据: 在朝鲜战争中功绩极大
结果显示: 在朝鲜战争中功绩极大
Epoch 0 Step 000300, model loss 2.2181, LR: 0.0000100000
真实数据: 中奖率高达98%以上
结果显示: 中雾率高达98%以上
Epoch 0 Step 000400, model loss 0.0953, LR: 0.0000100000
真实数据: 复制、转发以及用于业
结果显示: 复制、转发以及用于业
Epoch 0 Step 000500, model loss 15.5577, LR: 0.0000100000
真实数据: 整措施。闽人有纳妾者
结果显示: 整推施。呜人有纳妾者
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.2754, LR: 0.0000100000
真实数据: 老母即世，不断受到市
结果显示: 老母即世，不断受到市
Epoch 0 Step 000700, model loss 10.9969, LR: 0.0000100000
真实数据: 的时候。不利于耳朵的
结果显示: 的时候。不利于耳见的
Epoch 0 Step 000800, model loss 0.1779, LR: 0.0000100000
真实数据: 去年也与法国进行超音
结果显示: 去年也与法国进行超音
Epoch 0 Step 000900, model loss 11.4087, LR: 0.0000100000
真实数据: 变化可以用来勘探矿床
结果显示: 变化可以用来甚探矿床
Epoch 0 Step 001000, model loss 0.0898, LR: 0.0000100000
真实数据: 将加速制药行业内的兼
结果显示: 将加速制药行业内的兼
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 10.4434, LR: 0.0000100000
真实数据: 来居然真的分泌出了乳
结果显示: 来居然算的分汉出了乳
Epoch 0 Step 001200, model loss 0.2814, LR: 0.0000100000
真实数据: :不作乱离人。他们的
结果显示: :不作乱离人。他们的
Epoch 0 Step 001300, model loss 0.0599, LR: 0.0000100000
真实数据: 龙号”的改装成本太高
结果显示: 龙号”的改装成本太高
Epoch 0 Step 001400, model loss 0.4297, LR: 0.0000100000
真实数据: 品只有背投和等离子电
结果显示: 品只有背投和等离子电
Epoch 0 Step 001500, model loss 7.5070, LR: 0.0000100000
真实数据: 向警方供述，这和到央
结果显示: 向警方例述，这和到央
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 8.6542, LR: 0.0000100000
真实数据: 牛仔裤由实用变成时装
结果显示: 牛得神由实用变成时装
Epoch 0 Step 001700, model loss 0.0040, LR: 0.0000100000
真实数据: 反，其第一季度的收入
结果显示: 反，其第一季度的收入
Epoch 0 Step 001800, model loss 8.1692, LR: 0.0000100000
真实数据: 上升浪清晰有力，兄善
结果显示: 上升浪清断有力，兄善
Epoch 0 Step 001900, model loss 4.7261, LR: 0.0000100000
真实数据: 有数个豪华VIP包房
结果显示: 有数个豪华VTP包房
Epoch 0 Step 002000, model loss 4.1057, LR: 0.0000100000
真实数据: 广场(Nurnber
结果显示: 广场(INurnber
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0754, LR: 0.0000100000
真实数据: 放误导性信号如果成功
结果显示: 放误导性信号如果成功
Epoch 0 Step 002200, model loss 8.0849, LR: 0.0000100000
真实数据: 验物美价廉的购物乐趣
结果显示: 验物美价魔的购物乐趣
Epoch 0 Step 002300, model loss 2.3497, LR: 0.0000100000
真实数据: 聪明、舒适、酷”正是
结果显示: 职明、舒适、酷”正是
Epoch 0 Step 002400, model loss 0.0125, LR: 0.0000100000
真实数据: 文载法国《电影手册》
结果显示: 文载法国《电影手册》
Epoch 0 Step 002500, model loss 3.7260, LR: 0.0000100000
真实数据: 民网4月4日电据台湾
结果显示: 民网4月4日电据台管
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1425, LR: 0.0000100000
真实数据: 00毫克调整到200
结果显示: 00毫克调整到200
Epoch 0 Step 002700, model loss 0.4198, LR: 0.0000100000
真实数据: 委托人持股数量:一个
结果显示: 委托人持股数量:一个
Epoch 0 Step 002800, model loss 0.0776, LR: 0.0000100000
真实数据: 3、情绪定律追物给主
结果显示: 3、情绪定律追物给主
Epoch 0 Step 002900, model loss 0.1268, LR: 0.0000100000
真实数据: 贵族更高贵，第三者出
结果显示: 贵族更高贵，第三者出
Epoch 0 Step 003000, model loss 16.0792, LR: 0.0000100000
真实数据: 成为后赵村令人羡慕的
结果显示: 成为后赵村令人美项的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 13.5589, LR: 0.0000100000
真实数据: 可笑!”子女见翁躁急
结果显示: 可笑!”子女见翁睡领
Epoch 0 Step 003200, model loss 0.0275, LR: 0.0000100000
真实数据: 向广大游客做好出境前
结果显示: 向广大游客做好出境前
Epoch 0 Step 003300, model loss 0.2465, LR: 0.0000100000
真实数据: 其实各有各的益处。暴
结果显示: 其实各有各的益处。暴
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001D1A2728258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0775, LR: 0.0000100000
真实数据: 6我们尽量要用通俗易
结果显示: 6我们尽量要用通俗易
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.2060, LR: 0.0000100000
真实数据: 的“模块营”一次以“
结果显示: 的“模块营”一次以“
Epoch 0 Step 000200, model loss 24.2013, LR: 0.0000100000
真实数据: 那跛子曲三仍是烫上酒
结果显示: 那跟子曲三仍是资上酒
Epoch 0 Step 000300, model loss 1.1426, LR: 0.0000100000
真实数据: 59分就是第一名。竞
结果显示: 59分就是第一名。竟
Epoch 0 Step 000400, model loss 3.5978, LR: 0.0000100000
真实数据: 和传统的硬盘缓冲区有
结果显示: 和传统的硬盘缓冲区有
Epoch 0 Step 000500, model loss 16.0099, LR: 0.0000100000
真实数据: 蜜描述:她一口咬定没
结果显示: 虽描述:她一口咬定没
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0383, LR: 0.0000100000
真实数据: 在一番白热化的争夺之
结果显示: 在一番白热化的争夺之
Epoch 0 Step 000700, model loss 15.6655, LR: 0.0000100000
真实数据: 防止紫外线伤害的特种
结果显示: 防止繁外线伤赛的特种
Epoch 0 Step 000800, model loss 0.5804, LR: 0.0000100000
真实数据: "而猪八戒则是保唐僧
结果显示: "而猪八戒则是保唐僧
Epoch 0 Step 000900, model loss 1.0129, LR: 0.0000100000
真实数据: 对于职场新人来说，因
结果显示: 对于职场新人来说，因
Epoch 0 Step 001000, model loss 17.1924, LR: 0.0000100000
真实数据: 尚义迟尚斌尽显大哥风
结果显示: 陈义迟尚量尽显大纪
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.1144, LR: 0.0000100000
真实数据: 专家说，和同事关系也
结果显示: 专家说，和同事美系也
Epoch 0 Step 001200, model loss 0.1407, LR: 0.0000100000
真实数据: 但计算并不复杂，“大
结果显示: 但计算并不复杂，“大
Epoch 0 Step 001300, model loss 0.0235, LR: 0.0000100000
真实数据: 与字义相反地，比邻有
结果显示: 与字义相反地，比邻有
Epoch 0 Step 001400, model loss 0.1301, LR: 0.0000100000
真实数据: 希拉克略夺得帝位的同
结果显示: 希拉克略夺得帝位的同
Epoch 0 Step 001500, model loss 0.0892, LR: 0.0000100000
真实数据: 以期夺取盟军空军基地
结果显示: 以期夺取盟军空军基地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 7.2228, LR: 0.0000100000
真实数据: 想要，柴云振和当地乡
结果显示: 想要，禁云振和当地乡
Epoch 0 Step 001700, model loss 0.0913, LR: 0.0000100000
真实数据: 迎而问之。视客流情况
结果显示: 迎而问之。视客流情况
Epoch 0 Step 001800, model loss 0.0229, LR: 0.0000100000
真实数据: 尔辛基地区建造650
结果显示: 尔辛基地区建造650
Epoch 0 Step 001900, model loss 10.3667, LR: 0.0000100000
真实数据: 乌斯测定的原子量进行
结果显示: 鸟斯测定的原子进行
Epoch 0 Step 002000, model loss 38.2092, LR: 0.0000100000
真实数据: 了袈裟，从世界范围来
结果显示: 了装装，从世界范围来
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 19.2219, LR: 0.0000100000
真实数据: 可惜这两年白领缩水啦
结果显示: 可悟这两年白领缩水嘴
Epoch 0 Step 002200, model loss 0.3708, LR: 0.0000100000
真实数据: 火不旺，一张是秋天的
结果显示: 火不旺，一张是秋天的
Epoch 0 Step 002300, model loss 0.0103, LR: 0.0000100000
真实数据: 今已有2000多年的
结果显示: 今已有2000多年的
Epoch 0 Step 002400, model loss 0.0131, LR: 0.0000100000
真实数据: 工股份有限公司财务科
结果显示: 工股份有限公司财务科
Epoch 0 Step 002500, model loss 1.7704, LR: 0.0000100000
真实数据: ，从更深层次上也反映
结果显示: ，从更深层次上也反映
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 1.4920, LR: 0.0000100000
真实数据: 晚，也是俄在中亚地区
结果显示: 晚，也是俄在中亚地区
Epoch 0 Step 002700, model loss 0.4302, LR: 0.0000100000
真实数据: 裁军总数达到近200
结果显示: 裁军总数达到近200
Epoch 0 Step 002800, model loss 0.4324, LR: 0.0000100000
真实数据: 007centRig
结果显示: 007centRig
Epoch 0 Step 002900, model loss 0.7886, LR: 0.0000100000
真实数据: 烦叙，在提取10%法
结果显示: 烦叙，在提取10%法
Epoch 0 Step 003000, model loss 3.5432, LR: 0.0000100000
真实数据: 后果也可能很不一样）
结果显示: 后米也可能很不一样）
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.2205, LR: 0.0000100000
真实数据: 永远离开了他为之奋斗
结果显示: 永远离开了他为之奋斗
Epoch 0 Step 003200, model loss 0.0300, LR: 0.0000100000
真实数据: 作为中法文化年的核心
结果显示: 作为中法文化年的核心
Epoch 0 Step 003300, model loss 0.1148, LR: 0.0000100000
真实数据: 府再继续任由问题发展
结果显示: 府再继续任由问题发展
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021ACCC89258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.4582, LR: 0.0000100000
真实数据: 又问我Busines
结果显示: 又问我Busines
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.8963, LR: 0.0000100000
真实数据: 为了推动今后的业务增
结果显示: 为了推动今后的业务增
Epoch 0 Step 000200, model loss 0.0106, LR: 0.0000100000
真实数据: 过观察识别单词在任何
结果显示: 过观察识别单词在任何
Epoch 0 Step 000300, model loss 0.0092, LR: 0.0000100000
真实数据: 要企业给他们一次机会
结果显示: 要企业给他们一次机会
Epoch 0 Step 000400, model loss 3.6902, LR: 0.0000100000
真实数据: 例超过了公司先前的预
结果显示: 例起过了公司先前的预
Epoch 0 Step 000500, model loss 0.0314, LR: 0.0000100000
真实数据: 和新生事物有着天生的
结果显示: 和新生事物有着天生的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0874, LR: 0.0000100000
真实数据: 学者联合会要求学校在
结果显示: 学者联合会要求学校在
Epoch 0 Step 000700, model loss 0.3046, LR: 0.0000100000
真实数据: 护士不足问题较为突出
结果显示: 护士不足问题较为突出
Epoch 0 Step 000800, model loss 9.8724, LR: 0.0000100000
真实数据: 漏三下，才交睫，不知
结果显示: 派三下，才交联，不知
Epoch 0 Step 000900, model loss 0.7526, LR: 0.0000100000
真实数据: 又经营起了一家广告公
结果显示: 又经营起了一家广告公
Epoch 0 Step 001000, model loss 23.7358, LR: 0.0000100000
真实数据: 搓洗，张先生也感到了
结果显示: 撑洪，张先生也感到了
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1268, LR: 0.0000100000
真实数据: C中心的主持人大声喊
结果显示: C中心的主持人大声喊
Epoch 0 Step 001200, model loss 0.0483, LR: 0.0000100000
真实数据: 等。水是同里人的天堂
结果显示: 等。水是同里人的天堂
Epoch 0 Step 001300, model loss 25.6187, LR: 0.0000100000
真实数据: 打退堂鼓。陈俐同认为
结果显示: 打退空灼。陈倒同认为
Epoch 0 Step 001400, model loss 17.0171, LR: 0.0000100000
真实数据: 乖离苦长，论述题（1
结果显示: 乘离苦长，论述题（1
Epoch 0 Step 001500, model loss 0.2693, LR: 0.0000100000
真实数据: 大家都喜欢吉利的数字
结果显示: 大家都喜欢吉利的数字
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.5346, LR: 0.0000100000
真实数据: 但光从口头上认罪不行
结果显示: 但光从口头上认罪不行
Epoch 0 Step 001700, model loss 0.0845, LR: 0.0000100000
真实数据: 也是不善于表达情感的
结果显示: 也是不善于表达情感的
Epoch 0 Step 001800, model loss 1.9053, LR: 0.0000100000
真实数据: 诵、将校园换成了大成
结果显示: 诵、将校园换成了大成
Epoch 0 Step 001900, model loss 0.1852, LR: 0.0000100000
真实数据: 活期转存“通知存款”
结果显示: 活期转存“通知存款”
Epoch 0 Step 002000, model loss 2.5701, LR: 0.0000100000
真实数据: 力要远远好于听力能力
结果显示: 力要边远好于听力能力
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.1468, LR: 0.0000100000
真实数据: 你们却在这个地盘上班
结果显示: 你们却在这个地盘上班
Epoch 0 Step 002200, model loss 0.0912, LR: 0.0000100000
真实数据: 加上一个中国人的名字
结果显示: 加上一个中国人的名字
Epoch 0 Step 002300, model loss 3.1843, LR: 0.0000100000
真实数据: 服酸奶是牛奶经过发酵
结果显示: 服酸奶是牛奶经过发咣
Epoch 0 Step 002400, model loss 9.6183, LR: 0.0000100000
真实数据: ng）先生表示:近日
结果显示: na）先生表示:近日
Epoch 0 Step 002500, model loss 0.0440, LR: 0.0000100000
真实数据: 展对于这些有可能生育
结果显示: 展对于这些有可能生育
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.7836, LR: 0.0000100000
真实数据: 计划也在有条不紊的进
结果显示: 计划也在有条不素的进
Epoch 0 Step 002700, model loss 0.1468, LR: 0.0000100000
真实数据: 究所的发展空间会更大
结果显示: 究所的发展空间会更大
Epoch 0 Step 002800, model loss 1.9606, LR: 0.0000100000
真实数据: 华胜天成(行情,道士
结果显示: 华胜天成(行情,，道士
Epoch 0 Step 002900, model loss 8.0230, LR: 0.0000100000
真实数据: 姆大陆”可能连接着某
结果显示: 母大陆”可能连接着某
Epoch 0 Step 003000, model loss 2.1133, LR: 0.0000100000
真实数据: 竟是怎么想的?"此外
结果显示: 党是怎么想的?"此外
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 2.6421, LR: 0.0000100000
真实数据: 而且忘记的都是对于你
结果显示: 面且忌记的都是对于你
Epoch 0 Step 003200, model loss 1.6061, LR: 0.0000100000
真实数据: 早来到黑风山上。6苏
结果显示: 早来到黑风山上。6旅
Epoch 0 Step 003300, model loss 1.2040, LR: 0.0000100000
真实数据: 很用心地给我写了每字
结果显示: 很用心地给我写了每字
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000019D63FFA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0471, LR: 0.0000100000
真实数据: 合治疗可以减少复发和
结果显示: 合治疗可以减少复发和
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0118, LR: 0.0000100000
真实数据: 只有小小的修改。一方
结果显示: 只有小小的修改。一方
Epoch 0 Step 000200, model loss 0.4908, LR: 0.0000100000
真实数据: 认日军没有转向攻击江
结果显示: 认日军没有转向攻击江
Epoch 0 Step 000300, model loss 0.1155, LR: 0.0000100000
真实数据: X线检查发现是“气胸
结果显示: X线检查发现是“气胸
Epoch 0 Step 000400, model loss 0.0032, LR: 0.0000100000
真实数据: 而且性病在没有治愈之
结果显示: 而且性病在没有治愈之
Epoch 0 Step 000500, model loss 0.0345, LR: 0.0000100000
真实数据: 了外国公司，现在看起
结果显示: 了外国公司，现在看起
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 2.1291, LR: 0.0000100000
真实数据: 阳则在三分线上大显神
结果显示: 阳则在三分线上大显神
Epoch 0 Step 000700, model loss 0.9347, LR: 0.0000100000
真实数据: 因为戴尔，美丽更富有
结果显示: 因为戴尔，美丽更富有
Epoch 0 Step 000800, model loss 0.0804, LR: 0.0000100000
真实数据: 每年数千万的住院病人
结果显示: 每年数千万的住院病人
Epoch 0 Step 000900, model loss 16.3500, LR: 0.0000100000
真实数据: 两臂直束胯间，张在侧
结果显示: 两臂直束聘间，张在侧
Epoch 0 Step 001000, model loss 4.2916, LR: 0.0000100000
真实数据: 他凭该权力向客户索取
结果显示: 他凭该投力向客户索取
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.2012, LR: 0.0000100000
真实数据: 02年度达460亿美
结果显示: 02年度达460亿美
Epoch 0 Step 001200, model loss 0.0517, LR: 0.0000100000
真实数据: 在位年代的研究确定了
结果显示: 在位年代的研究确定了
Epoch 0 Step 001300, model loss 1.8760, LR: 0.0000100000
真实数据: townSouthA
结果显示: townsouthA
Epoch 0 Step 001400, model loss 6.1441, LR: 0.0000100000
真实数据: 从冲浪板摔下来的经历
结果显示: 从冲浪板捧下来的经历
Epoch 0 Step 001500, model loss 2.5567, LR: 0.0000100000
真实数据: 并为实施调整预留用地
结果显示: 关为实施调整预留用地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 1.8728, LR: 0.0000100000
真实数据: 目前逐渐恢复至正常水
结果显示: 目前逐渐恢复至正常水
Epoch 0 Step 001700, model loss 0.2385, LR: 0.0000100000
真实数据: 是完美动人的故事都值
结果显示: 是完美动人的故事都值
Epoch 0 Step 001800, model loss 10.0998, LR: 0.0000100000
真实数据: 故又有去氧麻黄碱之称
结果显示: 款又有去氧麻黄破之称
Epoch 0 Step 001900, model loss 0.8959, LR: 0.0000100000
真实数据: 不能完全符合大规模的
结果显示: 不能完个符合大规模的
Epoch 0 Step 002000, model loss 0.2027, LR: 0.0000100000
真实数据: 等有着极端的欲望的人
结果显示: 等有着极端的欲望的人
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0724, LR: 0.0000100000
真实数据: 量约为6.6亿立方米
结果显示: 量约为6.6亿立方米
Epoch 0 Step 002200, model loss 15.3704, LR: 0.0000100000
真实数据: 物，卢武铉甚至说过“
结果显示: 物，卢武德甚至说过“
Epoch 0 Step 002300, model loss 5.7826, LR: 0.0000100000
真实数据: 副反应小，曹仁的三千
结果显示: 副反虚小，尝仁的三千
Epoch 0 Step 002400, model loss 0.1502, LR: 0.0000100000
真实数据: 军演中展示了几种导弹
结果显示: 军演中展示了几种导弹
Epoch 0 Step 002500, model loss 4.6641, LR: 0.0000100000
真实数据: 六代传人张本兴老人领
结果显示: 大代传人张本数老人领
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 1.4965, LR: 0.0000100000
真实数据: :我就是要对这些通用
结果显示: :我就是要对这些逼用
Epoch 0 Step 002700, model loss 0.0172, LR: 0.0000100000
真实数据: 了公交车。妻问之亦不
结果显示: 了公交车。妻问之亦不
Epoch 0 Step 002800, model loss 0.0760, LR: 0.0000100000
真实数据: 另外一位资深的分析师
结果显示: 另外一位资深的分析师
Epoch 0 Step 002900, model loss 0.3123, LR: 0.0000100000
真实数据: 电脑上输入你的医疗保
结果显示: 电脑上输入你的医疗保
Epoch 0 Step 003000, model loss 0.0693, LR: 0.0000100000
真实数据: 现在我们必须离开，其
结果显示: 现在我们必须离开，其
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.4069, LR: 0.0000100000
真实数据: “医药航空母舰”的都
结果显示: “医药航空母舰”的都
Epoch 0 Step 003200, model loss 1.4424, LR: 0.0000100000
真实数据: 业宣讲会已经排到11
结果显示: 业宣讲会已经摔到11
Epoch 0 Step 003300, model loss 0.3005, LR: 0.0000100000
真实数据: 久而久之，幸月色昏黄
结果显示: 久而久之，幸月色昏黄
Epoch 0 Step 003400, model loss 0.4239, LR: 0.0000100000
真实数据: 务兵和士官也可参加应
结果显示: 务兵和士官也可参加应
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000022B4BCAA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 10.2773, LR: 0.0000100000
真实数据: 出的浓烟，异而反窥之
结果显示: 出的浓烟，异而反章之
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0227, LR: 0.0000100000
真实数据: 用。只是意味着获得了
结果显示: 用。只是意味着获得了
Epoch 0 Step 000200, model loss 11.6439, LR: 0.0000100000
真实数据: 犹如天际抖落而下的一
结果显示: 犹如天际择落而下的一
Epoch 0 Step 000300, model loss 0.4727, LR: 0.0000100000
真实数据: ，我们为学校提供能源
结果显示: ，我们为学校提供能源
Epoch 0 Step 000400, model loss 0.0044, LR: 0.0000100000
真实数据: 头发状态。我们大家都
结果显示: 头发状态。我们大家都
Epoch 0 Step 000500, model loss 0.9713, LR: 0.0000100000
真实数据: 能够深入讨论，然后有
结果显示: 能够深入讨论，然后有
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 14.4612, LR: 0.0000100000
真实数据: 了本相，数日未殓，另
结果显示: 了本相，数日未韵，另
Epoch 0 Step 000700, model loss 0.0871, LR: 0.0000100000
真实数据: 想看看有没有合适的职
结果显示: 想看看有没有合适的职
Epoch 0 Step 000800, model loss 6.1152, LR: 0.0000100000
真实数据: “且休报怨，研究发现
结果显示: “且体报怨，研究发现
Epoch 0 Step 000900, model loss 0.0216, LR: 0.0000100000
真实数据: 目标市场薪资水平的基
结果显示: 目标市场薪资水平的基
Epoch 0 Step 001000, model loss 0.1152, LR: 0.0000100000
真实数据: 责军售的米哈伊尔・德
结果显示: 责军售的米哈伊尔・德
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 8.6236, LR: 0.0000100000
真实数据: 塔的加入给投资者赋予
结果显示: 塔的加入给投资者贼予
Epoch 0 Step 001200, model loss 0.4765, LR: 0.0000100000
真实数据: 由此，向新的山头冲去
结果显示: 由此，向新的山头冲去
Epoch 0 Step 001300, model loss 0.0906, LR: 0.0000100000
真实数据: 归。由于封的人数太多
结果显示: 归。由于封的人数太多
Epoch 0 Step 001400, model loss 0.0641, LR: 0.0000100000
真实数据: 者见智。周成王元年在
结果显示: 者见智。周成王元年在
Epoch 0 Step 001500, model loss 0.5283, LR: 0.0000100000
真实数据: th='+width
结果显示: th='+width
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.4279, LR: 0.0000100000
真实数据: 专业录取男女比例不限
结果显示: 专业录取男女比例不限
Epoch 0 Step 001700, model loss 8.6158, LR: 0.0000100000
真实数据: 该项目的实施将初步摸
结果显示: 该项目的实施将初步摆
Epoch 0 Step 001800, model loss 0.1301, LR: 0.0000100000
真实数据: 可归的人用各种眼神看
结果显示: 可归的人用各种眼神看
Epoch 0 Step 001900, model loss 0.4273, LR: 0.0000100000
真实数据: 、新华社记者陈辉报道
结果显示: 、新华社记者陈辉报道
Epoch 0 Step 002000, model loss 0.0661, LR: 0.0000100000
真实数据: 且也，但由于是家里的
结果显示: 且也，但由于是家里的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 7.9155, LR: 0.0000100000
真实数据: 长期打击旅游市场的“
结果显示: 长期打击旅游市场的”
Epoch 0 Step 002200, model loss 1.6828, LR: 0.0000100000
真实数据: 律、行政法规规定的其
结果显示: 律、行政法规规定的其
Epoch 0 Step 002300, model loss 0.0805, LR: 0.0000100000
真实数据: 专业工作年限证明和居
结果显示: 专业工作年限证明和居
Epoch 0 Step 002400, model loss 0.2904, LR: 0.0000100000
真实数据: 大的政治、经济财政、
结果显示: 大的政治、经济财政、
Epoch 0 Step 002500, model loss 5.4975, LR: 0.0000100000
真实数据: 则为加强旗装封闭形式
结果显示: 则为加强旗装封研形式
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 10.9195, LR: 0.0000100000
真实数据: 然表现出色，我们想第
结果显示: 然表观出色，我们新第
Epoch 0 Step 002700, model loss 0.2649, LR: 0.0000100000
真实数据: 就会赶快用“葡萄减肥
结果显示: 就会赶快用“葡萄减肥
Epoch 0 Step 002800, model loss 0.8537, LR: 0.0000100000
真实数据: 第一是找不到这样的遗
结果显示: 第一是找不到这样的遗
Epoch 0 Step 002900, model loss 0.0599, LR: 0.0000100000
真实数据: 寻找的是什么样的机会
结果显示: 寻找的是什么样的机会
Epoch 0 Step 003000, model loss 0.1091, LR: 0.0000100000
真实数据: 宴时，更正:两处壁画
结果显示: 宴时，更正:两处壁画
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.1981, LR: 0.0000100000
真实数据: 格意义上不是一部个人
结果显示: 格意义上不是一部个人
Epoch 0 Step 003200, model loss 0.3410, LR: 0.0000100000
真实数据: 而不是克服。若奉老母
结果显示: 而不是克服。若奉老母
Epoch 0 Step 003300, model loss 2.4190, LR: 0.0000100000
真实数据: 力。完成都国腾通信1
结果显示: 力。完成都国胞通信1
Epoch 0 Step 003400, model loss 0.4154, LR: 0.0000100000
真实数据: ，也许会考你见过的案
结果显示: ，也许会考你见过的案
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002791587A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 6.9356, LR: 0.0000100000
真实数据: 睡眠、饮食清淡的同时
结果显示: 困眼、饮食清淡的同时
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1442, LR: 0.0000100000
真实数据: 明显的莫过于突出民族
结果显示: 明显的莫过于突出民族
Epoch 0 Step 000200, model loss 0.0454, LR: 0.0000100000
真实数据: “手是可以留给先生牵
结果显示: “手是可以留给先生牵
Epoch 0 Step 000300, model loss 8.8327, LR: 0.0000100000
真实数据: 上高耸的舰桥上林立的
结果显示: 上高趋的桥上林立的
Epoch 0 Step 000400, model loss 12.8089, LR: 0.0000100000
真实数据: 别人从背后将衣服撕去
结果显示: 别人从背后将衣服惕去
Epoch 0 Step 000500, model loss 0.2230, LR: 0.0000100000
真实数据: 从香港创新科技署了解
结果显示: 从香港创新科技署了解
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0117, LR: 0.0000100000
真实数据: 出任何办法。大多数参
结果显示: 出任何办法。大多数参
Epoch 0 Step 000700, model loss 2.9769, LR: 0.0000100000
真实数据: 偿还的债务负担和社会
结果显示: 偿还的镇务负担和社会
Epoch 0 Step 000800, model loss 8.8271, LR: 0.0000100000
真实数据: 不含防腐剂，人才国际
结果显示: 不含防庭袖，人方国际
Epoch 0 Step 000900, model loss 2.4259, LR: 0.0000100000
真实数据: 国统一使用新的企业所
结果显示: 国统一侠使用新的企业所
Epoch 0 Step 001000, model loss 0.6962, LR: 0.0000100000
真实数据: 空军司令部司令”由“
结果显示: 空军司令部司令”由“
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0646, LR: 0.0000100000
真实数据: 有光合作用的绿色组织
结果显示: 有光合作用的绿色组织
Epoch 0 Step 001200, model loss 6.9050, LR: 0.0000100000
真实数据: 乙肝带毒母亲所生子女
结果显示: c肝带毒母亲所生子女
Epoch 0 Step 001300, model loss 0.0092, LR: 0.0000100000
真实数据: ，几名曾在西门子公司
结果显示: ，几名曾在西门子公司
Epoch 0 Step 001400, model loss 0.4772, LR: 0.0000100000
真实数据: 当然不愿与胜利方接触
结果显示: 当然不愿与胜利方接触
Epoch 0 Step 001500, model loss 0.0675, LR: 0.0000100000
真实数据: 1的“好”属于词义扩
结果显示: 1的“好”属于词义扩
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 14.9742, LR: 0.0000100000
真实数据: 葛红林市长在见面会现
结果显示: 感红林市长在见面会现
Epoch 0 Step 001700, model loss 0.0208, LR: 0.0000100000
真实数据: 特别是假名牌，微软争
结果显示: 特别是假名牌，微软争
Epoch 0 Step 001800, model loss 0.1096, LR: 0.0000100000
真实数据: 一、重要提示答疑专家
结果显示: 一、重要提示答疑专家
Epoch 0 Step 001900, model loss 4.7628, LR: 0.0000100000
真实数据: 然后是兴趣，我收购的
结果显示: 然后是岗趣，我收则的
Epoch 0 Step 002000, model loss 4.9075, LR: 0.0000100000
真实数据: 背。“太阳的节奏可不
结果显示: 背。“太阳的节赛可不
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 3.6383, LR: 0.0000100000
真实数据: 是实德趁势追赶泰山的
结果显示: 是实德趋势追赶泰山的
Epoch 0 Step 002200, model loss 0.1406, LR: 0.0000100000
真实数据: 从而促进美空军购买更
结果显示: 从而促进美空军购买更
Epoch 0 Step 002300, model loss 1.6688, LR: 0.0000100000
真实数据: aVinciCode
结果显示: aVinciCode
Epoch 0 Step 002400, model loss 4.0745, LR: 0.0000100000
真实数据: 众不同的东西以一种“
结果显示: 众不阿的东西以D种“
Epoch 0 Step 002500, model loss 0.0036, LR: 0.0000100000
真实数据: 。就连英足总内部也出
结果显示: 。就连英足总内部也出
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.5755, LR: 0.0000100000
真实数据: 在所有颜料中白颜料用
结果显示: 在所有颜料中白颜料用
Epoch 0 Step 002700, model loss 1.9010, LR: 0.0000100000
真实数据: 紧急电话:据了解，呼
结果显示: 紧急电话:据了解，呼
Epoch 0 Step 002800, model loss 0.5107, LR: 0.0000100000
真实数据: 语法也掌握得非常精准
结果显示: 语法也掌握得非常精准
Epoch 0 Step 002900, model loss 0.1826, LR: 0.0000100000
真实数据: 看看能不能帮助王小波
结果显示: 看看能不能帮助王小波
Epoch 0 Step 003000, model loss 1.8985, LR: 0.0000100000
真实数据: 菲律宾约有8200万
结果显示: 非律宾约有8200万
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 5.6348, LR: 0.0000100000
真实数据: 在面对美军抓捕行动时
结果显示: 在面对美军抵拒行动时
Epoch 0 Step 003200, model loss 0.0024, LR: 0.0000100000
真实数据: 历。1/5的美国网民
结果显示: 历。1/5的美国网民
Epoch 0 Step 003300, model loss 0.0151, LR: 0.0000100000
真实数据: 会主动地学习新的知识
结果显示: 会主动地学习新的知识
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001CB196F9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 8.5600, LR: 0.0000100000
真实数据: 怪猫”上蹿下跳发出巨
结果显示: 怪猫”上赚下跳发出巨
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0194, LR: 0.0000100000
真实数据: 太子道:600600
结果显示: 太子道:600600
Epoch 0 Step 000200, model loss 3.8968, LR: 0.0000100000
真实数据: “哥呵，才至半山，在
结果显示: “哥绳，才至半山，在
Epoch 0 Step 000300, model loss 17.7955, LR: 0.0000100000
真实数据: 设帐，正是这卑琐处境
结果显示: 设惟，正是这年球处境
Epoch 0 Step 000400, model loss 0.0739, LR: 0.0000100000
真实数据: 说，有些管理措施也不
结果显示: 说，有些管理措施也不
Epoch 0 Step 000500, model loss 0.0322, LR: 0.0000100000
真实数据: 为社会创造了约400
结果显示: 为社会创造了约400
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0416, LR: 0.0000100000
真实数据: 个月，不至于死不休也
结果显示: 个月，不至于死不休也
Epoch 0 Step 000700, model loss 2.0576, LR: 0.0000100000
真实数据: 慢性乙肝防治指南》全
结果显示: 慢性乙肝防治指南》全
Epoch 0 Step 000800, model loss 1.0659, LR: 0.0000100000
真实数据: 本到中国来，烟波荡荡
结果显示: 本到中国来，烟波荡荡
Epoch 0 Step 000900, model loss 1.0833, LR: 0.0000100000
真实数据: 对策:钟山区（六盘水
结果显示: 对策:钟山区（六盘水
Epoch 0 Step 001000, model loss 8.2086, LR: 0.0000100000
真实数据: 白鸽，公曰:窃逃于此
结果显示: 白嘘，公曰:窃逃于此
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.5534, LR: 0.0000100000
真实数据: 在喝前和喝后进行测试
结果显示: 在喝前和喝后进行测试
Epoch 0 Step 001200, model loss 1.6992, LR: 0.0000100000
真实数据: 一般不把食物剩在碗中
结果显示: 一般不把食物剩在碗中
Epoch 0 Step 001300, model loss 44.7710, LR: 0.0000100000
真实数据: ，女性先奚落、嘲讽男
结果显示: ，女性先落、敏调男
Epoch 0 Step 001400, model loss 0.8330, LR: 0.0000100000
真实数据: 意。毁约不仅使大学生
结果显示: 意。毁约不仅使大学生
Epoch 0 Step 001500, model loss 0.0254, LR: 0.0000100000
真实数据: 是我可以帮助队友进球
结果显示: 是我可以帮助队友进球
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.3301, LR: 0.0000100000
真实数据: 但只闻中国军队奋起抗
结果显示: 但只间中国军队奋起抗
Epoch 0 Step 001700, model loss 1.9921, LR: 0.0000100000
真实数据: 这次选举中，营养价值
结果显示: 这次选举中，营养价值
Epoch 0 Step 001800, model loss 14.2751, LR: 0.0000100000
真实数据: 体公开的我军军事演习
结果显示: 告公件的我军军事决习
Epoch 0 Step 001900, model loss 3.1809, LR: 0.0000100000
真实数据: 停留在上个世纪改革开
结果显示: 停留在上个世纪改菲开
Epoch 0 Step 002000, model loss 1.2556, LR: 0.0000100000
真实数据: 不浅也。”赞美具有一
结果显示: 不浅也。”赞美具有一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.1983, LR: 0.0000100000
真实数据: 费占到销售额的11%
结果显示: 费占到销售额的11%
Epoch 0 Step 002200, model loss 0.6580, LR: 0.0000100000
真实数据: 格布再次发威，为北方
结果显示: 格布再次发威，为北方
Epoch 0 Step 002300, model loss 0.0170, LR: 0.0000100000
真实数据: 展台也一样挤满了应聘
结果显示: 展台也一样挤满了应聘
Epoch 0 Step 002400, model loss 15.3589, LR: 0.0000100000
真实数据: 较积极的喀麦隆前锋贝
结果显示: 较积极的略麦隆前锋贝
Epoch 0 Step 002500, model loss 6.3560, LR: 0.0000100000
真实数据: 降低肥胖的发生率;考
结果显示: 降低肥胖的发生率;专
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 5.5565, LR: 0.0000100000
真实数据: 科学家威尔逊发明威尔
结果显示: 科学家威尔困发明威尔
Epoch 0 Step 002700, model loss 0.2014, LR: 0.0000100000
真实数据: K线形态也形成箱形整
结果显示: K线形态也形成箱形整
Epoch 0 Step 002800, model loss 15.9183, LR: 0.0000100000
真实数据: 东南沿海又有倭寇之乱
结果显示: 东南沿海又有管恋之乱
Epoch 0 Step 002900, model loss 0.2086, LR: 0.0000100000
真实数据: :社会利润率是会平均
结果显示: :社会利润率是会平均
Epoch 0 Step 003000, model loss 1.8509, LR: 0.0000100000
真实数据: 设立了合规部门。米内
结果显示: 设立了合规部门。崇内
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.3318, LR: 0.0000100000
真实数据: 华留学生所学的专业正
结果显示: 华留学生所学的专业正
Epoch 0 Step 003200, model loss 0.1147, LR: 0.0000100000
真实数据: 反复无常就是“现实生
结果显示: 反复无常就是“现实生
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000208F0C1A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 10.7621, LR: 0.0000100000
真实数据: 、嚼碎或研成粉末服用
结果显示: 、嘴碎或研成粉束服用
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0428, LR: 0.0000100000
真实数据: tegrievanc
结果显示: tegrievanc
Epoch 0 Step 000200, model loss 5.5086, LR: 0.0000100000
真实数据: ”众臣道:本月中下旬
结果显示: ”众臣道:本月中下
Epoch 0 Step 000300, model loss 0.0069, LR: 0.0000100000
真实数据: 生们对每个求职机会都
结果显示: 生们对每个求职机会都
Epoch 0 Step 000400, model loss 18.8171, LR: 0.0000100000
真实数据: ，终于第一次看清楚了
结果显示: ，经于落一次需致了
Epoch 0 Step 000500, model loss 5.6193, LR: 0.0000100000
真实数据: 教职工都在“‘迎接奥
结果显示: 教职工都在“迎接奥
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 9.5393, LR: 0.0000100000
真实数据: 在面试之前，脚上流血
结果显示: 在面试之前，脚上流
Epoch 0 Step 000700, model loss 0.4873, LR: 0.0000100000
真实数据: ，除了对高级管理人才
结果显示: ，除了对高级管理人才
Epoch 0 Step 000800, model loss 0.4611, LR: 0.0000100000
真实数据: 值球员”（MVP）的
结果显示: 值球员”（MVP）的
Epoch 0 Step 000900, model loss 2.4992, LR: 0.0000100000
真实数据: 的抢救工作的确取得了
结果显示: 的搭救工作的确取得了
Epoch 0 Step 001000, model loss 9.7783, LR: 0.0000100000
真实数据: 疲惫时用。对价股份上
结果显示: 疲急时用。对价股份上
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.4492, LR: 0.0000100000
真实数据: 熟眠。以何为罚?”僧
结果显示: 熟眼。以何为罚?”僧
Epoch 0 Step 001200, model loss 12.1403, LR: 0.0000100000
真实数据: 即遽止。一则化些茶饭
结果显示: 即速止。一则化些茶饭
Epoch 0 Step 001300, model loss 4.4745, LR: 0.0000100000
真实数据: 是雪上加霜，但当时工
结果显示: 是雪上加君，但当时工
Epoch 0 Step 001400, model loss 17.7740, LR: 0.0000100000
真实数据: 、旋风咖啡杯委以重任
结果显示: 、遵风咖虽杯妻以重伪
Epoch 0 Step 001500, model loss 1.7492, LR: 0.0000100000
真实数据: 使某些产品类别单一的
结果显示: 使某些产品类别单一的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0576, LR: 0.0000100000
真实数据: 4、一定要做一个经济
结果显示: 4、一定要做一个经济
Epoch 0 Step 001700, model loss 5.6615, LR: 0.0000100000
真实数据: 先生浏览网页时突然发
结果显示: 先生炒览网页时突然发
Epoch 0 Step 001800, model loss 0.0407, LR: 0.0000100000
真实数据: 玩笑说，其他医院的检
结果显示: 玩笑说，其他医院的检
Epoch 0 Step 001900, model loss 0.4256, LR: 0.0000100000
真实数据: 现在看好像男女基本上
结果显示: 现在看好像男女基本上
Epoch 0 Step 002000, model loss 7.5583, LR: 0.0000100000
真实数据: 事诉讼法学》王国枢主
结果显示: 事诉绘法学》王国柜主
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0100, LR: 0.0000100000
真实数据: 以后就没人给我活干了
结果显示: 以后就没人给我活干了
Epoch 0 Step 002200, model loss 0.1726, LR: 0.0000100000
真实数据: 佛教与道教都有所发展
结果显示: 佛教与道教都有所发展
Epoch 0 Step 002300, model loss 0.5350, LR: 0.0000100000
真实数据: 杀死了布里，9.满月
结果显示: 杀死了布里，9.满月
Epoch 0 Step 002400, model loss 2.8607, LR: 0.0000100000
真实数据: 长，请问下一步如何治
结果显示: 长，请问下一步如何谊
Epoch 0 Step 002500, model loss 1.6369, LR: 0.0000100000
真实数据: ，CategoryD
结果显示: ，CategoryD
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.1261, LR: 0.0000100000
真实数据: 一篇不少于800字的
结果显示: 一篇不少于800字的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002A6B48FA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0033, LR: 0.0000100000
真实数据: 这次并购花的代价有点
结果显示: 这次并购花的代价有点
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0259, LR: 0.0000100000
真实数据: 北部、东部的水面尤甚
结果显示: 北部、东部的水面尤甚
Epoch 0 Step 000200, model loss 2.0331, LR: 0.0000100000
真实数据: 也就失去一道免疫防病
结果显示: 也就失去一道党疫防病
Epoch 0 Step 000300, model loss 6.1419, LR: 0.0000100000
真实数据: 寇的观念，这也没有什
结果显示: 宽的观令，这也没有什
Epoch 0 Step 000400, model loss 0.0029, LR: 0.0000100000
真实数据: 没从刚刚的事情里回过
结果显示: 没从刚刚的事情里回过
Epoch 0 Step 000500, model loss 23.5452, LR: 0.0000100000
真实数据: 僻型“我只管踢好每一
结果显示: 件型“我只管耶好每一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.8012, LR: 0.0000100000
真实数据: 十娘。“上边的感觉真
结果显示: 十娘。“上边的感觉真
Epoch 0 Step 000700, model loss 0.0175, LR: 0.0000100000
真实数据: 学科门类社会不断进步
结果显示: 学科门类社会不断进步
Epoch 0 Step 000800, model loss 0.7428, LR: 0.0000100000
真实数据: 三年后的你，十分欢喜
结果显示: 三年后的你，十分欢喜
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000145D5A6C258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0262, LR: 0.0000100000
真实数据: 中国球员要留洋似乎困
结果显示: 中国球员要留洋似乎困
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1088, LR: 0.0000100000
真实数据: 从“心”做起，概括起
结果显示: 从“心”做起，概括起
Epoch 0 Step 000200, model loss 0.0183, LR: 0.0000100000
真实数据: ，也成为合并过程中的
结果显示: ，也成为合并过程中的
Epoch 0 Step 000300, model loss 0.2643, LR: 0.0000100000
真实数据: 代也等于是一个国家历
结果显示: 代也等于是一个国家历
Epoch 0 Step 000400, model loss 0.1917, LR: 0.0000100000
真实数据: 用也不大;刀锋)飞行
结果显示: 用也不大;刀锋)飞行
Epoch 0 Step 000500, model loss 0.1316, LR: 0.0000100000
真实数据: 在下午放学但此时绝大
结果显示: 在下午放学但此时绝大
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0613, LR: 0.0000100000
真实数据: 新京报》4月16日报
结果显示: 新京报》4月16日报
Epoch 0 Step 000700, model loss 0.1474, LR: 0.0000100000
真实数据: 两家基地航空公司（南
结果显示: 两家基地航空公司（南
Epoch 0 Step 000800, model loss 2.0506, LR: 0.0000100000
真实数据: 日本军演半步不离佛地
结果显示: 日本军满半步不离佛地
Epoch 0 Step 000900, model loss 23.5946, LR: 0.0000100000
真实数据: 原糖链末端为N-乙酰
结果显示: 原糖椭秉端为N-Z酬
Epoch 0 Step 001000, model loss 0.5629, LR: 0.0000100000
真实数据: ，犹豫不决、仓促上阵
结果显示: ，犹豫不决、仓促上阵
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 14.2725, LR: 0.0000100000
真实数据: 跟老板编了个见记者的
结果显示: 最老长编了个现记者的
Epoch 0 Step 001200, model loss 2.1149, LR: 0.0000100000
真实数据: 家的生活都是一地鸡毛
结果显示: 家的生活都是一地鸡韦
Epoch 0 Step 001300, model loss 31.2736, LR: 0.0000100000
真实数据: 四溢、湿地遍布、禽鸟
结果显示: 四道、温地响布、高乌
Epoch 0 Step 001400, model loss 2.0107, LR: 0.0000100000
真实数据: 对于久经考场的同学们
结果显示: 对于欠经考场的同学们
Epoch 0 Step 001500, model loss 1.2800, LR: 0.0000100000
真实数据: 种我们迄今尚不知道的
结果显示: 种我们逸今尚不知道的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0028, LR: 0.0000100000
真实数据: 通高校的在校生人数是
结果显示: 通高校的在校生人数是
Epoch 0 Step 001700, model loss 16.4770, LR: 0.0000100000
真实数据: VD格式孰胜孰败的过
结果显示: VD格式获胜教败的过
Epoch 0 Step 001800, model loss 0.1773, LR: 0.0000100000
真实数据: 使将出来，同时准备面
结果显示: 使将出来，同时准备面
Epoch 0 Step 001900, model loss 1.3368, LR: 0.0000100000
真实数据: ，导师说，现在大盘涨
结果显示: ，导师说，现在大盘涨
Epoch 0 Step 002000, model loss 6.6912, LR: 0.0000100000
真实数据: 里才安心。泼灭了妖火
结果显示: 里才安心。波灭了妖大
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.3646, LR: 0.0000100000
真实数据: 种方法既练听力，李致
结果显示: 种方法既练听力，李致
Epoch 0 Step 002200, model loss 1.0691, LR: 0.0000100000
真实数据: 乐评级以及摩根士丹利
结果显示: 乐评级以及摩根士丹利
Epoch 0 Step 002300, model loss 0.0725, LR: 0.0000100000
真实数据: 免采取可能导致局势进
结果显示: 免采取可能导致局势进
Epoch 0 Step 002400, model loss 0.0391, LR: 0.0000100000
真实数据: 食物中毒和食源性疾病
结果显示: 食物中毒和食源性疾病
Epoch 0 Step 002500, model loss 0.0092, LR: 0.0000100000
真实数据: 宝贵的财富。并且节日
结果显示: 宝贵的财富。并且节日
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.8224, LR: 0.0000100000
真实数据: 在激光打印机市场表现
结果显示: 在藏光打印机市场表现
Epoch 0 Step 002700, model loss 1.1216, LR: 0.0000100000
真实数据: G五粮液(00085
结果显示: G五粮液(00085
Epoch 0 Step 002800, model loss 7.7715, LR: 0.0000100000
真实数据: 其中，第十四届美猴王
结果显示: 其中，第十四届美独王
Epoch 0 Step 002900, model loss 0.0060, LR: 0.0000100000
真实数据: 用该工具为美国的广告
结果显示: 用该工具为美国的广告
Epoch 0 Step 003000, model loss 4.3062, LR: 0.0000100000
真实数据: 005年6月22日―
结果显示: 005年6月22日一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0070, LR: 0.0000100000
真实数据: 中的数据进行动态的统
结果显示: 中的数据进行动态的统
Epoch 0 Step 003200, model loss 0.1753, LR: 0.0000100000
真实数据: 房地产企业的高层管理
结果显示: 房地产企业的高层管理
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000015FE1D9A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 9.1015, LR: 0.0000100000
真实数据: 8等到别人跟你搭讪就
结果显示: 8等到别人跟你搭慎就
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1256, LR: 0.0000100000
真实数据: 、管理混乱、保险不健
结果显示: 、管理混乱、保险不健
Epoch 0 Step 000200, model loss 0.0221, LR: 0.0000100000
真实数据: 时取出，希望由此阻止
结果显示: 时取出，希望由此阻止
Epoch 0 Step 000300, model loss 0.0118, LR: 0.0000100000
真实数据: 然后向老城的北边。2
结果显示: 然后向老城的北边。2
Epoch 0 Step 000400, model loss 5.8883, LR: 0.0000100000
真实数据: 比如背包缝线不牢、小
结果显示: 比如背包绳线不牢、小
Epoch 0 Step 000500, model loss 5.2064, LR: 0.0000100000
真实数据: 得不可能每个人都是好
结果显示: 得不可能考章个人都是好
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0395, LR: 0.0000100000
真实数据: 士伦护理液会造成使用
结果显示: 士伦护理液会造成使用
Epoch 0 Step 000700, model loss 0.6151, LR: 0.0000100000
真实数据: 突然雷达观测报告:颇
结果显示: 突然雷达观测报告:颇
Epoch 0 Step 000800, model loss 0.0302, LR: 0.0000100000
真实数据: 织后卫到中锋的任何位
结果显示: 织后卫到中锋的任何位
Epoch 0 Step 000900, model loss 5.1964, LR: 0.0000100000
真实数据: 经以开口‘阿拉’为荣
结果显示: 经以开口‘阿拉”为菜
Epoch 0 Step 001000, model loss 1.2926, LR: 0.0000100000
真实数据: 道:是不易得附件炎的
结果显示: 道:是不易得附件炎的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.3255, LR: 0.0000100000
真实数据: 004年底，岸口无渔
结果显示: 004年底，岸口无渔
Epoch 0 Step 001200, model loss 0.0071, LR: 0.0000100000
真实数据: 一部分是作为职业经理
结果显示: 一部分是作为职业经理
Epoch 0 Step 001300, model loss 11.2753, LR: 0.0000100000
真实数据: 同妪启户出粟，在网络
结果显示: 同锻启户出果，在网络
Epoch 0 Step 001400, model loss 0.2504, LR: 0.0000100000
真实数据: 指标双双跃居全国医药
结果显示: 指标双双跃居全国医药
Epoch 0 Step 001500, model loss 0.0157, LR: 0.0000100000
真实数据: 读。女人的特别就在于
结果显示: 读。女人的特别就在于
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.8308, LR: 0.0000100000
真实数据: 上海分公司那边出了乱
结果显示: 上海分公司那边出了乱
Epoch 0 Step 001700, model loss 0.0160, LR: 0.0000100000
真实数据: 来，过去多认为一、二
结果显示: 来，过去多认为一、二
Epoch 0 Step 001800, model loss 1.4839, LR: 0.0000100000
真实数据: A22和F-35的服
结果显示: A22和F-35的服
Epoch 0 Step 001900, model loss 7.9223, LR: 0.0000100000
真实数据: 缮的重点是重绘建筑彩
结果显示: 倍的重点是重绘建筑彩
Epoch 0 Step 002000, model loss 0.8462, LR: 0.0000100000
真实数据: 最多可进行1―2小时
结果显示: 最多可进行1-2小时
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.2384, LR: 0.0000100000
真实数据: 人应有的自知自觉。最
结果显示: 人应有的自知自觉。最
Epoch 0 Step 002200, model loss 0.0379, LR: 0.0000100000
真实数据: 走，搜狐直播员:付海
结果显示: 走，搜狐直播员:付海
Epoch 0 Step 002300, model loss 13.9687, LR: 0.0000100000
真实数据: 务影响，Ⅱ能削弱题干
结果显示: 务影响，川能削弱题干
Epoch 0 Step 002400, model loss 0.0799, LR: 0.0000100000
真实数据: 均为红外近距格斗空空
结果显示: 均为红外近距格斗空空
Epoch 0 Step 002500, model loss 0.1572, LR: 0.0000100000
真实数据: [见面三分情]的中国
结果显示: [见面三分情]的中国
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1291, LR: 0.0000100000
真实数据: 最易癌变的妇科病妻子
结果显示: 最易癌变的妇科病妻子
Epoch 0 Step 002700, model loss 3.5452, LR: 0.0000100000
真实数据: 网消息，●缺乏幽默感
结果显示: 网消息，●缺乏出默感
Epoch 0 Step 002800, model loss 0.5147, LR: 0.0000100000
真实数据: 。岭南山区由于地湿寒
结果显示: 。岭南山区由于地湿寒
Epoch 0 Step 002900, model loss 2.6547, LR: 0.0000100000
真实数据: 向着公司高层地位迈进
结果显示: 向省公司高层地位迈进
Epoch 0 Step 003000, model loss 5.4696, LR: 0.0000100000
真实数据: 人，6.敦促他戒烟少
结果显示: 人，o.再促他戒烟少
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.3563, LR: 0.0000100000
真实数据: 大部分人家中均有亲属
结果显示: 大部分人家中均有亲属
Epoch 0 Step 003200, model loss 12.2511, LR: 0.0000100000
真实数据: 为，母劬不堪;月度例
结果显示: 为，母验不堪;月度例
Epoch 0 Step 003300, model loss 0.6873, LR: 0.0000100000
真实数据: ，直到刘庄即位三年后
结果显示: ，直到刘庄即位三年后
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002DADB8CA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.4997, LR: 0.0000100000
真实数据: 导弹将由印度国防部军
结果显示: 导弹将由印度国防部军
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0104, LR: 0.0000100000
真实数据: 因为人不是静止的动物
结果显示: 因为人不是静止的动物
Epoch 0 Step 000200, model loss 0.0707, LR: 0.0000100000
真实数据: （阿根廷）/洛伦索（
结果显示: （阿根廷）/洛伦索（
Epoch 0 Step 000300, model loss 0.0414, LR: 0.0000100000
真实数据: 这款系统凭借其强大的
结果显示: 这款系统凭借其强大的
Epoch 0 Step 000400, model loss 2.9166, LR: 0.0000100000
真实数据: 人必修课保持思想清净
结果显示: 人必修谋保持思想清净
Epoch 0 Step 000500, model loss 0.0761, LR: 0.0000100000
真实数据: 果自身作战体系尚不完
结果显示: 果自身作战体系尚不完
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0399, LR: 0.0000100000
真实数据: 1366我可以告诉大
结果显示: 1366我可以告诉大
Epoch 0 Step 000700, model loss 0.6787, LR: 0.0000100000
真实数据: 女初长成”，观众将被
结果显示: 女初长成”，观众将被
Epoch 0 Step 000800, model loss 0.4705, LR: 0.0000100000
真实数据: 。“抢项目”现象再度
结果显示: 。“抢项目”现象再度
Epoch 0 Step 000900, model loss 5.0975, LR: 0.0000100000
真实数据: 还可在相关度假村享受
结果显示: 近可在相关度假村享受
Epoch 0 Step 001000, model loss 0.9767, LR: 0.0000100000
真实数据: 这样，孙行者看了一会
结果显示: 这样，孙行者看了一会
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1903, LR: 0.0000100000
真实数据: 个人游我们是有选择性
结果显示: 个人游我们是有选择性
Epoch 0 Step 001200, model loss 2.3426, LR: 0.0000100000
真实数据: 风生，书中所应偿还债
结果显示: 风生，书中所应偿还估
Epoch 0 Step 001300, model loss 0.5875, LR: 0.0000100000
真实数据: 众两院中获得压倒多数
结果显示: 众两院中获得压倒多数
Epoch 0 Step 001400, model loss 0.7253, LR: 0.0000100000
真实数据: 的状态为阿森纳保驾护
结果显示: 的状态为阿森纳保驾护
Epoch 0 Step 001500, model loss 0.0879, LR: 0.0000100000
真实数据: 少则6000元，与此
结果显示: 少则6000元，与此
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.3546, LR: 0.0000100000
真实数据: 到“十一五”末，据一
结果显示: 到“+一五”末，据一
Epoch 0 Step 001700, model loss 0.0245, LR: 0.0000100000
真实数据: 引入内，第一志愿生源
结果显示: 引入内，第一志愿生源
Epoch 0 Step 001800, model loss 0.0010, LR: 0.0000100000
真实数据: 去也。“都是你定的什
结果显示: 去也。“都是你定的什
Epoch 0 Step 001900, model loss 6.6012, LR: 0.0000100000
真实数据: 每天都在我们身边蔓延
结果显示: 每天都在我们身边锤延
Epoch 0 Step 002000, model loss 10.7330, LR: 0.0000100000
真实数据: ，每出一物，淋漓鲜血
结果显示: ，每出一物，浙浪鲜血
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.1601, LR: 0.0000100000
真实数据: 土”云云。便可以额外
结果显示: 土”云云。便可以额外
Epoch 0 Step 002200, model loss 4.9211, LR: 0.0000100000
真实数据: 回去，还好五一终于来
结果显示: 圆去，还好五D终于来
Epoch 0 Step 002300, model loss 14.2957, LR: 0.0000100000
真实数据: 是不是有教唆人犯罪的
结果显示: 是不是有教隆人犯罪的
Epoch 0 Step 002400, model loss 0.7256, LR: 0.0000100000
真实数据: 大家怕冷怕热不换工作
结果显示: 大家怕冷怕热不换工作
Epoch 0 Step 002500, model loss 16.7217, LR: 0.0000100000
真实数据: 钦宗赵桓在上海，但金
结果显示: 软宗赵极在上海，但金
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 17.2287, LR: 0.0000100000
真实数据: 疡、扁桃体炎、咽炎等
结果显示: 驴、痛枕体炎、唯炎等
Epoch 0 Step 002700, model loss 0.4346, LR: 0.0000100000
真实数据: 交易变得更加直观轻松
结果显示: 交易变得更加直观轻松
Epoch 0 Step 002800, model loss 1.1450, LR: 0.0000100000
真实数据: 干香。这类人的野心指
结果显示: 干香，这类人的野心指
Epoch 0 Step 002900, model loss 4.3652, LR: 0.0000100000
真实数据: 非政府组织的合法活动
结果显示: 非政府组织的合法活功
Epoch 0 Step 003000, model loss 0.0032, LR: 0.0000100000
真实数据: 十来名，三个成绩相关
结果显示: 十来名，三个成绩相关
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.2763, LR: 0.0000100000
真实数据: 、我军第一位作战指挥
结果显示: 、我军第一位作战指挥
Epoch 0 Step 003200, model loss 0.0427, LR: 0.0000100000
真实数据: 们有什么好处啊?同学
结果显示: 们有什么好处啊?同学
Epoch 0 Step 003300, model loss 0.0012, LR: 0.0000100000
真实数据: 但是人总要面对现实的
结果显示: 但是人总要面对现实的
Epoch 0 Step 003400, model loss 0.0345, LR: 0.0000100000
真实数据: 份3844.3715
结果显示: 份3844.3715
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000260CEB2C258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 1.0228, LR: 0.0000100000
真实数据: 苏联制“米格29”战
结果显示: 苏联制“米格29”战
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0055, LR: 0.0000100000
真实数据: 从而成为一代武学大师
结果显示: 从而成为一代武学大师
Epoch 0 Step 000200, model loss 0.1608, LR: 0.0000100000
真实数据: 交手段解决伊朗核问题
结果显示: 交手段解决伊朗核问题
Epoch 0 Step 000300, model loss 3.6589, LR: 0.0000100000
真实数据: 忽悠之七――能杀菌的
结果显示: 忽悠之七―能杀菌的
Epoch 0 Step 000400, model loss 0.0055, LR: 0.0000100000
真实数据: 正对人们的价值认同产
结果显示: 正对人们的价值认同产
Epoch 0 Step 000500, model loss 0.0219, LR: 0.0000100000
真实数据: 际上最具有竞争力的产
结果显示: 际上最具有竞争力的产
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 1.0632, LR: 0.0000100000
真实数据: 舍非耶?”邢便请入舍
结果显示: 舍非耶?”邢便请入舍
Epoch 0 Step 000700, model loss 0.5289, LR: 0.0000100000
真实数据: 一下这个梦想的实际意
结果显示: 一下这个梦想的实际意
Epoch 0 Step 000800, model loss 0.0156, LR: 0.0000100000
真实数据: 高性、研究型课程学习
结果显示: 高性、研究型课程学习
Epoch 0 Step 000900, model loss 0.0083, LR: 0.0000100000
真实数据: 或者只是口头部署工作
结果显示: 或者只是口头部署工作
Epoch 0 Step 001000, model loss 0.1348, LR: 0.0000100000
真实数据: 死记硬背史实是远远不
结果显示: 死记硬背史实是远远不
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1641, LR: 0.0000100000
真实数据: 型坦克驾驶模拟系统”
结果显示: 型坦克驾驶模拟系统”
Epoch 0 Step 001200, model loss 0.0015, LR: 0.0000100000
真实数据: 带的班级多次被评为市
结果显示: 带的班级多次被评为市
Epoch 0 Step 001300, model loss 0.0089, LR: 0.0000100000
真实数据: t1977year.
结果显示: t1977year.
Epoch 0 Step 001400, model loss 0.0558, LR: 0.0000100000
真实数据: 制度的创立和消失都不
结果显示: 制度的创立和消失都不
Epoch 0 Step 001500, model loss 0.1094, LR: 0.0000100000
真实数据: 填报平行第一院校志愿
结果显示: 填报平行第一院校志愿
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0808, LR: 0.0000100000
真实数据: 时读过这一报道的英国
结果显示: 时读过这一报道的英国
Epoch 0 Step 001700, model loss 0.0235, LR: 0.0000100000
真实数据: 其家中经济条件困难，
结果显示: 其家中经济条件困难，
Epoch 0 Step 001800, model loss 0.2120, LR: 0.0000100000
真实数据: 在六年后的1976年
结果显示: 在六年后的1976年
Epoch 0 Step 001900, model loss 0.0086, LR: 0.0000100000
真实数据: 52摄氏度!不一会儿
结果显示: 52摄氏度!不一会儿
Epoch 0 Step 002000, model loss 0.0002, LR: 0.0000100000
真实数据: 不是用在这时候的。不
结果显示: 不是用在这时候的。不
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0828, LR: 0.0000100000
真实数据: 这是巴基斯坦继3月2
结果显示: 这是巴基斯坦继3月2
Epoch 0 Step 002200, model loss 3.4779, LR: 0.0000100000
真实数据: 有的甚至落地进行连锁
结果显示: 有的甚至落地进行连缴
Epoch 0 Step 002300, model loss 2.1988, LR: 0.0000100000
真实数据: 一买一卖中净赚一二十
结果显示: 一买一卖中净一二十
Epoch 0 Step 002400, model loss 0.1293, LR: 0.0000100000
真实数据: 预计下轮会维持在10
结果显示: 预计下轮会维持在10
Epoch 0 Step 002500, model loss 0.0508, LR: 0.0000100000
真实数据: 在物质、金钱基础上的
结果显示: 在物质、金钱基础上的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 1.5191, LR: 0.0000100000
真实数据: 00080)金花股份
结果显示: 00080)金花股份
Epoch 0 Step 002700, model loss 2.4282, LR: 0.0000100000
真实数据: 反被聪明误。以“成就
结果显示: 反被聪明误。以“成就
Epoch 0 Step 002800, model loss 11.2226, LR: 0.0000100000
真实数据: 了打嗝外，“让大家相
结果显示: 了打晒外，“让大家相
Epoch 0 Step 002900, model loss 0.1391, LR: 0.0000100000
真实数据: 占有18%的市场份额
结果显示: 占有18%的市场份额
Epoch 0 Step 003000, model loss 0.5072, LR: 0.0000100000
真实数据: 亦不能绝。学校里的跳
结果显示: 亦不能绝。学校里的跳
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 8.6996, LR: 0.0000100000
真实数据: 过来唱了。“他奶奶的
结果显示: 过来明了。“他如知的
Epoch 0 Step 003200, model loss 27.1755, LR: 0.0000100000
真实数据: 女儿随母亲住在舅舅家
结果显示: 女儿随母亲住在网家
Epoch 0 Step 003300, model loss 0.8586, LR: 0.0000100000
真实数据: 2、被担保人财务报表
结果显示: 2、被担保人财务报表
Epoch 0 Step 003400, model loss 0.2846, LR: 0.0000100000
真实数据: 因为行刺的动机相差很
结果显示: 因为行刺的动机相差很
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002374475A258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0488, LR: 0.0000100000
真实数据: 居然跑去度假。闻歌起
结果显示: 居然跑去度假。闻歌起
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0080, LR: 0.0000100000
真实数据: 你拿这个钱去买张纸来
结果显示: 你拿这个钱去买张纸来
Epoch 0 Step 000200, model loss 0.0338, LR: 0.0000100000
真实数据: 大中华区董事总经理一
结果显示: 大中华区董事总经理一
Epoch 0 Step 000300, model loss 0.2993, LR: 0.0000100000
真实数据: 是寺院。实现净利润4
结果显示: 是寺院。实现净利润4
Epoch 0 Step 000400, model loss 18.2792, LR: 0.0000100000
真实数据: 神经中枢，远远不能满
结果显示: 神经中秉、选远不能
Epoch 0 Step 000500, model loss 16.2995, LR: 0.0000100000
真实数据: 其蠹役满堂，方注目间
结果显示: 其疆役满堂，方注目间
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0376, LR: 0.0000100000
真实数据: 视行为……反正不管别
结果显示: 视行为……反正不管别
Epoch 0 Step 000700, model loss 1.0639, LR: 0.0000100000
真实数据: stagainin8
结果显示: stagainin8
Epoch 0 Step 000800, model loss 7.7189, LR: 0.0000100000
真实数据: 有路标，因此说轻松世
结果显示: 有路标，固此说轻松世
Epoch 0 Step 000900, model loss 2.1290, LR: 0.0000100000
真实数据: 汝纵之何在火力上更可
结果显示: 沙纵之何在火力上更可
Epoch 0 Step 001000, model loss 0.1285, LR: 0.0000100000
真实数据: 务部还出台了支持内地
结果显示: 务部还出台了支持内地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 7.3782, LR: 0.0000100000
真实数据: 人一下子全垮了。20
结果显示: 人一下子全适了。20
Epoch 0 Step 001200, model loss 0.0263, LR: 0.0000100000
真实数据: 为保证市场销售的染发
结果显示: 为保证市场销售的染发
Epoch 0 Step 001300, model loss 0.4029, LR: 0.0000100000
真实数据: 村学生的比例为17.
结果显示: 村学生的比例为17.
Epoch 0 Step 001400, model loss 0.8948, LR: 0.0000100000
真实数据: 抗生素若再次大幅降价
结果显示: 抗生素若再次大幅降价
Epoch 0 Step 001500, model loss 9.0092, LR: 0.0000100000
真实数据: 的人们来美容小店安慰
结果显示: 的人们来美容小店安壁
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0103, LR: 0.0000100000
真实数据: 是不能说治疗方法改变
结果显示: 是不能说治疗方法改变
Epoch 0 Step 001700, model loss 0.0828, LR: 0.0000100000
真实数据: 十九条于是，公立学校
结果显示: 十九条于是，公立学校
Epoch 0 Step 001800, model loss 2.1561, LR: 0.0000100000
真实数据: 容易下笔。将痛苦和灾
结果显示: 容易下笔。将痛苦和纹
Epoch 0 Step 001900, model loss 0.0043, LR: 0.0000100000
真实数据: 轻轻地说了一句话。不
结果显示: 轻轻地说了一句话。不
Epoch 0 Step 002000, model loss 5.5783, LR: 0.0000100000
真实数据: 饭的大嫂只收我两块钱
结果显示: 饭的大姻只收我两块钱
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0339, LR: 0.0000100000
真实数据: 同时也需要在每一步中
结果显示: 同时也需要在每一步中
Epoch 0 Step 002200, model loss 0.0319, LR: 0.0000100000
真实数据: 在进行这种业务创新的
结果显示: 在进行这种业务创新的
Epoch 0 Step 002300, model loss 0.3155, LR: 0.0000100000
真实数据: 主席维扎伊・马洛亚（
结果显示: 主席维扎伊・马洛亚（
Epoch 0 Step 002400, model loss 2.6569, LR: 0.0000100000
真实数据: 岁及50岁以上妇女的
结果显示: 岁及50岁以上妇女的
Epoch 0 Step 002500, model loss 0.1316, LR: 0.0000100000
真实数据: 。顺其自然。介绍了俄
结果显示: 。顺其自然。介绍了俄
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.4677, LR: 0.0000100000
真实数据: 中医院男性专科副主任
结果显示: 中医院男性专科副主任
Epoch 0 Step 002700, model loss 0.0152, LR: 0.0000100000
真实数据: 纷开放，说明一定有很
结果显示: 纷开放，说明一定有很
Epoch 0 Step 002800, model loss 0.0009, LR: 0.0000100000
真实数据: 这个地方也是可以说既
结果显示: 这个地方也是可以说既
Epoch 0 Step 002900, model loss 0.0108, LR: 0.0000100000
真实数据: ，享有美好的“未来”
结果显示: ，享有美好的“未来”
Epoch 0 Step 003000, model loss 0.1124, LR: 0.0000100000
真实数据: 过多，就是健择这个药
结果显示: 过多，就是健择这个药
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.5566, LR: 0.0000100000
真实数据: 堡晋级决赛的历程非常
结果显示: 堡晋级决赛的历程非常
Epoch 0 Step 003200, model loss 5.7107, LR: 0.0000100000
真实数据: 计》(经管类)(04
结果显示: 计》(经管类)04
Epoch 0 Step 003300, model loss 1.3456, LR: 0.0000100000
真实数据: 报外是否还可以阅读其
结果显示: 报外是否还可以阅读其
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001AC475D9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 12.2085, LR: 0.0000100000
真实数据: B铅笔将选中的答案涂
结果显示: B楹笔将选中的答案涂
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1438, LR: 0.0000100000
真实数据: 水雷时出现了发射故障
结果显示: 水雷时出现了发射故障
Epoch 0 Step 000200, model loss 0.0139, LR: 0.0000100000
真实数据: ，除没收假冒名牌商品
结果显示: ，除没收假冒名牌商品
Epoch 0 Step 000300, model loss 0.0822, LR: 0.0000100000
真实数据: 以真面目示人那一天起
结果显示: 以真面目示人那一天起
Epoch 0 Step 000400, model loss 0.0570, LR: 0.0000100000
真实数据: 取得了积极成效，然而
结果显示: 取得了积极成效，然而
Epoch 0 Step 000500, model loss 0.2348, LR: 0.0000100000
真实数据: 师分析说，动辄包机包
结果显示: 师分析说，动辄包机包
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0770, LR: 0.0000100000
真实数据: 机制并未使员工的满意
结果显示: 机制并未使员工的满意
Epoch 0 Step 000700, model loss 10.6277, LR: 0.0000100000
真实数据: 日俘管理处命令一部分
结果显示: 日仔管理处命令一部分
Epoch 0 Step 000800, model loss 2.0847, LR: 0.0000100000
真实数据: 碳酸，可能是醒后记忆
结果显示: 残酸，可能是醒后记忆
Epoch 0 Step 000900, model loss 0.7773, LR: 0.0000100000
真实数据: 用户可以从服务商那里
结果显示: 用户可以从服务商那里
Epoch 0 Step 001000, model loss 1.1461, LR: 0.0000100000
真实数据: 日一言:经过一番努力
结果显示: 日一言:经过一番努力
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 5.0969, LR: 0.0000100000
真实数据: 把那什么孙行者拿来凑
结果显示: 把那什么孙行者拿来读
Epoch 0 Step 001200, model loss 0.0473, LR: 0.0000100000
真实数据: 威胁全球金融稳定的程
结果显示: 威胁全球金融稳定的程
Epoch 0 Step 001300, model loss 6.4531, LR: 0.0000100000
真实数据: 适嗅之，海上对空防御
结果显示: 适痧之，海上对空防御
Epoch 0 Step 001400, model loss 0.0044, LR: 0.0000100000
真实数据: 也给我们医药行业带来
结果显示: 也给我们医药行业带来
Epoch 0 Step 001500, model loss 0.2243, LR: 0.0000100000
真实数据: 厌的女人吗?难道那样
结果显示: 厌的女人吗?难道那样
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 22.8631, LR: 0.0000100000
真实数据: ”刘翔在大阪卫冕后曾
结果显示: ”刘赠在大奖卫亚后营
Epoch 0 Step 001700, model loss 0.0031, LR: 0.0000100000
真实数据: 方基于关心，随后空投
结果显示: 方基于关心，随后空投
Epoch 0 Step 001800, model loss 1.9839, LR: 0.0000100000
真实数据: 他们。8布伦达・巴恩
结果显示: 他们。8布伦达・巴思
Epoch 0 Step 001900, model loss 0.2941, LR: 0.0000100000
真实数据: 固，教育学（0401
结果显示: 固，教育学（0401
Epoch 0 Step 002000, model loss 0.0358, LR: 0.0000100000
真实数据: 05/1020:00
结果显示: 05/1020:00
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.1620, LR: 0.0000100000
真实数据: 的公安人员声称要抓他
结果显示: 的公安人员声称要打他
Epoch 0 Step 002200, model loss 1.4049, LR: 0.0000100000
真实数据: 存在的漏洞的恶意软件
结果显示: 存在的漏洞的恶意软件
Epoch 0 Step 002300, model loss 6.5713, LR: 0.0000100000
真实数据: 衣人有把臂可申请成为
结果显示: 衣人有把跨可申请成为
Epoch 0 Step 002400, model loss 3.7300, LR: 0.0000100000
真实数据: 店皇家斯威士太阳酒店
结果显示: 店皇家斯威士太阳洒店
Epoch 0 Step 002500, model loss 2.2900, LR: 0.0000100000
真实数据: 们只做澳门博采、娱乐
结果显示: 们只做澳门博采、娱乐
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 12.2211, LR: 0.0000100000
真实数据: 阳港区码头的上海港国
结果显示: 田激时头的上海港国
Epoch 0 Step 002700, model loss 1.4739, LR: 0.0000100000
真实数据: eNet硅谷动力消息
结果显示: eNet硅谷动力消息
Epoch 0 Step 002800, model loss 0.1086, LR: 0.0000100000
真实数据: 要求四本书吃得非常透
结果显示: 要求四本书吃得非常透
Epoch 0 Step 002900, model loss 0.0041, LR: 0.0000100000
真实数据: ，衣服也并不总是自己
结果显示: ，衣服也并不总是自己
Epoch 0 Step 003000, model loss 0.1741, LR: 0.0000100000
真实数据: 因为家长们大多缺乏乐
结果显示: 因为家长们大多缺乏乐
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 1.5613, LR: 0.0000100000
真实数据: 而为两，行者往殿上请
结果显示: 而为两，行者住殿上请
Epoch 0 Step 003200, model loss 0.9474, LR: 0.0000100000
真实数据: 颠，欲使不完全抗体与
结果显示: 颠，欲使不完全抗体与
Epoch 0 Step 003300, model loss 2.9628, LR: 0.0000100000
真实数据: “浩宇”网吧，益贤之
结果显示: “浴宇”网吧，益贤之
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001948C2D9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.5147, LR: 0.0000100000
真实数据: 恐怕与媒体屏蔽掉的世
结果显示: 恐怕与媒体屏蔽掉的世
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 17.2056, LR: 0.0000100000
真实数据: 惠安张坂林老师:因此
结果显示: 惠安张奴林老师:因此
Epoch 0 Step 000200, model loss 6.7807, LR: 0.0000100000
真实数据: 帮助提高华侨大学羽毛
结果显示: 帮助提高华轿大学羽毛
Epoch 0 Step 000300, model loss 1.1719, LR: 0.0000100000
真实数据: 当我们补充上省略的部
结果显示: 当我们补充上省略的部
Epoch 0 Step 000400, model loss 4.5409, LR: 0.0000100000
真实数据: 硕士在淮海路乱穿马路
结果显示: 硕士在谁海路乱穿马路
Epoch 0 Step 000500, model loss 11.6684, LR: 0.0000100000
真实数据: 、Mondo”行国寿
结果显示: 、pdo”行国指
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 7.5816, LR: 0.0000100000
真实数据: 藏于池塘底部，这就意
结果显示: 藏于池格底部，这就意
Epoch 0 Step 000700, model loss 0.0052, LR: 0.0000100000
真实数据: 盆，在本机构、本人所
结果显示: 盆，在本机构、本人所
Epoch 0 Step 000800, model loss 14.0508, LR: 0.0000100000
真实数据: 深深烙印在我的脑海里
结果显示: 深深给印在我的胞海里
Epoch 0 Step 000900, model loss 0.2565, LR: 0.0000100000
真实数据: 生告诉记者，两股做多
结果显示: 生告诉记者，两股做多
Epoch 0 Step 001000, model loss 0.7103, LR: 0.0000100000
真实数据: 种考试本身就是不科学
结果显示: 种考试本身就是不科学
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0153, LR: 0.0000100000
真实数据: 他平生第一次看见长城
结果显示: 他平生第一次看见长城
Epoch 0 Step 001200, model loss 1.2884, LR: 0.0000100000
真实数据: 在澳大利亚进行的女足
结果显示: 在澳大利亚进行的女足
Epoch 0 Step 001300, model loss 7.1901, LR: 0.0000100000
真实数据: 否则，清香味散发殆尽
结果显示: 否则，清香味散发怖尽
Epoch 0 Step 001400, model loss 0.0224, LR: 0.0000100000
真实数据: 搭建出一个文字的客厅
结果显示: 搭建出一个文字的客厅
Epoch 0 Step 001500, model loss 1.8192, LR: 0.0000100000
真实数据: 实香浓爽口，武则天时
结果显示: 实香浓爽口，武则天时
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.8016, LR: 0.0000100000
真实数据: 性的拉升行情则一触即
结果显示: 性的拉升行情则一融即
Epoch 0 Step 001700, model loss 0.2018, LR: 0.0000100000
真实数据: 。并买下各地的10M
结果显示: 。并买下各地的10M
Epoch 0 Step 001800, model loss 11.9787, LR: 0.0000100000
真实数据: 公开的外聘专家遴选机
结果显示: 公开的外聘专家速选机
Epoch 0 Step 001900, model loss 0.0249, LR: 0.0000100000
真实数据: 能再随便批出租车牌照
结果显示: 能再随便批出租车牌照
Epoch 0 Step 002000, model loss 0.0411, LR: 0.0000100000
真实数据: 995年下半年，B)
结果显示: 995年下半年，B)
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0058, LR: 0.0000100000
真实数据: 几个学生都表示没有针
结果显示: 几个学生都表示没有针
Epoch 0 Step 002200, model loss 0.0576, LR: 0.0000100000
真实数据: 如何将旅游和旅行业对
结果显示: 如何将旅游和旅行业对
Epoch 0 Step 002300, model loss 39.3604, LR: 0.0000100000
真实数据: 败了骜不驯馁克斯都・
结果显示: 败了势不薪缓克斯都・
Epoch 0 Step 002400, model loss 0.0662, LR: 0.0000100000
真实数据: 以上一般就选择放疗加
结果显示: 以上一般就选择放疗加
Epoch 0 Step 002500, model loss 1.0547, LR: 0.0000100000
真实数据: 月3日、4日出游较实
结果显示: 月3日、4日出游较实
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1810, LR: 0.0000100000
真实数据: 月15日前停止移动数
结果显示: 月15日前停止移动数
Epoch 0 Step 002700, model loss 0.4317, LR: 0.0000100000
真实数据: 但购买力也呈上升态势
结果显示: 但购买力也呈上升态势
Epoch 0 Step 002800, model loss 1.9903, LR: 0.0000100000
真实数据: butI’mtryi
结果显示: butI'mtryi
Epoch 0 Step 002900, model loss 0.0098, LR: 0.0000100000
真实数据: 单位:来回24个小时
结果显示: 单位:来回24个小时
Epoch 0 Step 003000, model loss 0.0690, LR: 0.0000100000
真实数据: 选择（1）的人，既别
结果显示: 选择（1）的人，既别
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.1556, LR: 0.0000100000
真实数据: 胜业。有73%来自中
结果显示: 胜业。有73%来自中
Epoch 0 Step 003200, model loss 3.2058, LR: 0.0000100000
真实数据: 雨洪水利用以及浅层地
结果显示: 西洪水利用以及浅层地
Epoch 0 Step 003300, model loss 0.1599, LR: 0.0000100000
真实数据: 花鼓戏几十年的潮起潮
结果显示: 花鼓戏几十年的潮起潮
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000019E043B9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 1.0459, LR: 0.0000100000
真实数据: O20215）的主考
结果显示: 020215）的主考
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 5.0150, LR: 0.0000100000
真实数据: 一颗原子弹著称于世）
结果显示: 一秀原子弹著称于世）
Epoch 0 Step 000200, model loss 0.0558, LR: 0.0000100000
真实数据: 大富翁吗190000
结果显示: 大富翁吗190000
Epoch 0 Step 000300, model loss 0.0834, LR: 0.0000100000
真实数据: 于放宽大陆观光客、农
结果显示: 于放宽大陆观光客、农
Epoch 0 Step 000400, model loss 3.6043, LR: 0.0000100000
真实数据: 粘之。我们在之后的预
结果显示: 枯之。我们在之后的预
Epoch 0 Step 000500, model loss 0.1851, LR: 0.0000100000
真实数据: 用一场精彩的、有内容
结果显示: 用一场精彩的、有内容
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0025, LR: 0.0000100000
真实数据: 的名片都没有印自己的
结果显示: 的名片都没有印自己的
Epoch 0 Step 000700, model loss 5.2007, LR: 0.0000100000
真实数据: 本节一开始，房后三日
结果显示: 本节一开始，房后三
Epoch 0 Step 000800, model loss 14.0934, LR: 0.0000100000
真实数据: 播员:王珂主罚任意球
结果显示: 播员:王犴主罚任意球
Epoch 0 Step 000900, model loss 0.1846, LR: 0.0000100000
真实数据: 绿色也会失去，在这里
结果显示: 绿色也会失去，在这里
Epoch 0 Step 001000, model loss 1.3208, LR: 0.0000100000
真实数据: 客观、深度、超前的投
结果显示: 春观、深度、超前的投
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.8521, LR: 0.0000100000
真实数据: 广益的结果比我预先的
结果显示: 广益的结果比我预先的"
Epoch 0 Step 001200, model loss 0.2902, LR: 0.0000100000
真实数据: ”乱言曰:（图片来源
结果显示: ”乱言曰:（图片来源
Epoch 0 Step 001300, model loss 0.8819, LR: 0.0000100000
真实数据: 明白她意思是让我慢慢
结果显示: 明白她意思是让我模慢
Epoch 0 Step 001400, model loss 0.0128, LR: 0.0000100000
真实数据: 电器通过与永乐合并的
结果显示: 电器通过与永乐合并的
Epoch 0 Step 001500, model loss 7.8869, LR: 0.0000100000
真实数据: 最早是“八味地黄丸”
结果显示: 最早是“八味地黄九”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.3041, LR: 0.0000100000
真实数据: 后汉书》说的“党众离
结果显示: 后汉书》说的“党众离
Epoch 0 Step 001700, model loss 8.8328, LR: 0.0000100000
真实数据: 拉玛干沙漠中并不鲜见
结果显示: 拉顶干沙漠中并不鲜见
Epoch 0 Step 001800, model loss 0.0071, LR: 0.0000100000
真实数据: 1937年“七七”事
结果显示: 1937年“七七”事
Epoch 0 Step 001900, model loss 0.1511, LR: 0.0000100000
真实数据: 奇想并发现了万有引力
结果显示: 奇想并发现了万有引力
Epoch 0 Step 002000, model loss 0.1588, LR: 0.0000100000
真实数据: 业上很有成绩，公子市
结果显示: 业上很有成绩，公子市
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0026, LR: 0.0000100000
真实数据: 包括5个小孩，那天中
结果显示: 包括5个小孩，那天中
Epoch 0 Step 002200, model loss 0.0217, LR: 0.0000100000
真实数据: 性应当比女性更加坚强
结果显示: 性应当比女性更加坚强
Epoch 0 Step 002300, model loss 0.0399, LR: 0.0000100000
真实数据: 年北京实行高考自主命
结果显示: 年北京实行高考自主命
Epoch 0 Step 002400, model loss 9.1933, LR: 0.0000100000
真实数据: 学各校区内，捉而曳之
结果显示: 学备校区内，捉而虫之
Epoch 0 Step 002500, model loss 1.6383, LR: 0.0000100000
真实数据: 弟啊!怎生降得妖魔?
结果显示: 弟啊!怎生降得妖魔?
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0163, LR: 0.0000100000
真实数据: 成固定资产投资101
结果显示: 成固定资产投资101
Epoch 0 Step 002700, model loss 0.0927, LR: 0.0000100000
真实数据: 企业之间追求的都是共
结果显示: 企业之间追求的都是共
Epoch 0 Step 002800, model loss 0.8156, LR: 0.0000100000
真实数据: 人们还可以进一步指出
结果显示: 人们还可以进一步指出
Epoch 0 Step 002900, model loss 0.0658, LR: 0.0000100000
真实数据: 说明北京市场并不是铁
结果显示: 说明北京市场并不是铁
Epoch 0 Step 003000, model loss 7.1926, LR: 0.0000100000
真实数据: 心理有病?要把大赛做
结果显示: 心理有病?要把武菜做
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 19.5895, LR: 0.0000100000
真实数据: 能驾驭化学问题的全貌
结果显示: 能驾驼化学问题的全貌
Epoch 0 Step 003200, model loss 0.1096, LR: 0.0000100000
真实数据: tTrainee的项
结果显示: tTrainee的项
Epoch 0 Step 003300, model loss 0.0018, LR: 0.0000100000
真实数据: 是机械对于现代社会还
结果显示: 是机械对于现代社会还
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000026C41719258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.1056, LR: 0.0000100000
真实数据: 长张忠培先生当着李学
结果显示: 长张忠培先生当着李学
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1345, LR: 0.0000100000
真实数据: ，相关科目突出，“既
结果显示: ，相关科目突出，“既
Epoch 0 Step 000200, model loss 0.2382, LR: 0.0000100000
真实数据: 的信念都已经灰飞烟灭
结果显示: 的信念都已经灰飞烟灭
Epoch 0 Step 000300, model loss 19.5356, LR: 0.0000100000
真实数据: 在土铳炮的开道下，可
结果显示: 在士衅炮的开道下，可
Epoch 0 Step 000400, model loss 2.1692, LR: 0.0000100000
真实数据: ，波斯皇帝（公元前5
结果显示: ，波斯垒帝（公元前5
Epoch 0 Step 000500, model loss 0.0030, LR: 0.0000100000
真实数据: 搜狐直播员:本场比赛
结果显示: 搜狐直播员:本场比赛
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 18.9019, LR: 0.0000100000
真实数据: 肆簋》“惟王廿祀”[
结果显示: 窖篇》“惟王甘祀”[
Epoch 0 Step 000700, model loss 0.0118, LR: 0.0000100000
真实数据: 街投资者当然也注意到
结果显示: 街投资者当然也注意到
Epoch 0 Step 000800, model loss 8.7686, LR: 0.0000100000
真实数据: 使者以我诚笃，得到4
结果显示: 使者以我连耸，得到4
Epoch 0 Step 000900, model loss 0.3248, LR: 0.0000100000
真实数据: 我们是谁下台就画谁的
结果显示: 我们是谁下台就画谁的
Epoch 0 Step 001000, model loss 4.6296, LR: 0.0000100000
真实数据: ;为跨辈近亲结婚做解
结果显示: :为跨辈近亲结婚做解
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 14.4903, LR: 0.0000100000
真实数据: 田和北汽福田签署了《
结果显示: 围和北汽福围示著了《
Epoch 0 Step 001200, model loss 4.4304, LR: 0.0000100000
真实数据: 优先的任务是服务化软
结果显示: 优先的任务是服务化较
Epoch 0 Step 001300, model loss 1.4074, LR: 0.0000100000
真实数据: 们将人脱光鞋子露出手
结果显示: 们将人脱光勒子露出手
Epoch 0 Step 001400, model loss 6.5149, LR: 0.0000100000
真实数据: 不考外语的考生不能获
结果显示: 不考外语的考生不能欢
Epoch 0 Step 001500, model loss 4.1808, LR: 0.0000100000
真实数据: 游客都关心的违约金问
结果显示: 游客都关心的连约金问
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0555, LR: 0.0000100000
真实数据: 问:翁南游，另一方面
结果显示: 问:翁南游，另一方面
Epoch 0 Step 001700, model loss 1.1783, LR: 0.0000100000
真实数据: 。4、电话追踪是不信
结果显示: 。4、电话追踪是不信
Epoch 0 Step 001800, model loss 4.6277, LR: 0.0000100000
真实数据: 鞋虽然每年春夏都会出
结果显示: 虽然每年春夏都会出
Epoch 0 Step 001900, model loss 0.3643, LR: 0.0000100000
真实数据: andstrong-
结果显示: andstrong-
Epoch 0 Step 002000, model loss 0.0521, LR: 0.0000100000
真实数据: 是其中一位出色的玩家
结果显示: 是其中一位出色的玩家
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.3510, LR: 0.0000100000
真实数据: 上海申花只是一场预热
结果显示: 上海申花只是一场预热
Epoch 0 Step 002200, model loss 0.0067, LR: 0.0000100000
真实数据: 同时也是复旦大学的培
结果显示: 同时也是复旦大学的培
Epoch 0 Step 002300, model loss 0.2130, LR: 0.0000100000
真实数据: 归，但是，中美航线在
结果显示: 归，但是，中美航线在
Epoch 0 Step 002400, model loss 4.6318, LR: 0.0000100000
真实数据: 0平以上，”方驰华教
结果显示: 0平以上，”方他华教
Epoch 0 Step 002500, model loss 29.5589, LR: 0.0000100000
真实数据: 纳什三分命中后，璀璨
结果显示: 综什三分命中后，魂难
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 9.9077, LR: 0.0000100000
真实数据: 的是求异法。对德国的
结果显示: 的是求科法。对德网的
Epoch 0 Step 002700, model loss 6.0619, LR: 0.0000100000
真实数据: 人同居的事瞒住了配偶
结果显示: 人同居的事鹏住了配偶
Epoch 0 Step 002800, model loss 2.3610, LR: 0.0000100000
真实数据: 在锋线缺人的情况下今
结果显示: 在苹线缺人的情况下今
Epoch 0 Step 002900, model loss 0.1182, LR: 0.0000100000
真实数据: A股股东606,使个
结果显示: A股股东606,使个
Epoch 0 Step 003000, model loss 14.8583, LR: 0.0000100000
真实数据: 不要斤斤计较。忍不住
结果显示: 不要斥斥计较。忍不住
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0432, LR: 0.0000100000
真实数据: 培养具有良好的促进作
结果显示: 培养具有良好的促进作
Epoch 0 Step 003200, model loss 0.0440, LR: 0.0000100000
真实数据: 微软可能是惟一能够提
结果显示: 微软可能是惟一能够提
Epoch 0 Step 003300, model loss 0.9929, LR: 0.0000100000
真实数据: 兴的是头号球星布兰德
结果显示: 兴的是头号球星布兰德
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E8E1889258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.3080, LR: 0.0000100000
真实数据: 些主要科目填得满满的
结果显示: 些主要科目填得满满的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0240, LR: 0.0000100000
真实数据: 但以如此轻松的方式突
结果显示: 但以如此轻松的方式突
Epoch 0 Step 000200, model loss 0.0191, LR: 0.0000100000
真实数据: 车:玩什么我就不多说
结果显示: 车:玩什么我就不多说
Epoch 0 Step 000300, model loss 3.6712, LR: 0.0000100000
真实数据: 家诺基亚网络解决方案
结果显示: 家诺基亚网络解决方察
Epoch 0 Step 000400, model loss 0.0016, LR: 0.0000100000
真实数据: 报报业集团发起全国报
结果显示: 报报业集团发起全国报
Epoch 0 Step 000500, model loss 1.3405, LR: 0.0000100000
真实数据: 些醉意，如今，专家提
结果显示: 些醉意，如今，专家提
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0024, LR: 0.0000100000
真实数据: 两年前忽然调职到一个
结果显示: 两年前忽然调职到一个
Epoch 0 Step 000700, model loss 0.5992, LR: 0.0000100000
真实数据: 又何足怪。”听说还大
结果显示: 又何足怪。”听说还大
Epoch 0 Step 000800, model loss 0.0070, LR: 0.0000100000
真实数据: 分农村线路也将于今年
结果显示: 分农村线路也将于今年
Epoch 0 Step 000900, model loss 0.3579, LR: 0.0000100000
真实数据: 现大家看得见。减21
结果显示: 现大家看得见。减21
Epoch 0 Step 001000, model loss 3.8422, LR: 0.0000100000
真实数据: Gainesvill
结果显示: （ainesyill
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0213, LR: 0.0000100000
真实数据: 了!我这这话决不是拍
结果显示: 了!我这这话决不是拍
Epoch 0 Step 001200, model loss 6.7163, LR: 0.0000100000
真实数据: 捻着露但有浩叹。但早
结果显示: 瘫着瞬但有浩叹。但早
Epoch 0 Step 001300, model loss 0.0597, LR: 0.0000100000
真实数据: 告诉你，生既醒，去年
结果显示: 告诉你，生既醒，去年
Epoch 0 Step 001400, model loss 0.7999, LR: 0.0000100000
真实数据: 案的对价水平相当于流
结果显示: 案的对价水平相当子于流
Epoch 0 Step 001500, model loss 0.0218, LR: 0.0000100000
真实数据: 计到今年年底，其生产
结果显示: 计到今年年底，其生产
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0202, LR: 0.0000100000
真实数据: 在马尔代夫的优惠旅行
结果显示: 在马尔代夫的优惠旅行
Epoch 0 Step 001700, model loss 28.2237, LR: 0.0000100000
真实数据: 徒弟，王二笑嘻嘻地请
结果显示: 徒弟，王二笑响睛地请
Epoch 0 Step 001800, model loss 5.0995, LR: 0.0000100000
真实数据: 行了一场史无前例的大
结果显示: 行了一场定无前例的大
Epoch 0 Step 001900, model loss 2.7162, LR: 0.0000100000
真实数据: 对于对手的这种带有污
结果显示: 对于对手的这种带有河
Epoch 0 Step 002000, model loss 0.0264, LR: 0.0000100000
真实数据: 由于老板涉足房地产业
结果显示: 由于老板涉足房地产业
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.2524, LR: 0.0000100000
真实数据: 学校招聘的“开禁日”
结果显示: 学校招聘的“开禁日”
Epoch 0 Step 002200, model loss 0.1253, LR: 0.0000100000
真实数据: 者又摇手道:因试前履
结果显示: 者又摇手道:因试前履
Epoch 0 Step 002300, model loss 1.0129, LR: 0.0000100000
真实数据: 就没有及时采纳这一建
结果显示: 就没有及时采纳这一建
Epoch 0 Step 002400, model loss 2.1391, LR: 0.0000100000
真实数据: --whatoure
结果显示: 一-whatoure
Epoch 0 Step 002500, model loss 9.3643, LR: 0.0000100000
真实数据: 化和精神的风韵丧失了
结果显示: 化和精神的风药丧先了
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0407, LR: 0.0000100000
真实数据: 顾对象必须参加第一次
结果显示: 顾对象必须参加第一次
Epoch 0 Step 002700, model loss 0.0570, LR: 0.0000100000
真实数据: 7万人在2005年这
结果显示: 7万人在2005年这
Epoch 0 Step 002800, model loss 0.0244, LR: 0.0000100000
真实数据: 子集团是本次股权分置
结果显示: 子集团是本次股权分置
Epoch 0 Step 002900, model loss 0.1626, LR: 0.0000100000
真实数据: 也在反思“美式民主”
结果显示: 也在反思“美式民主”
Epoch 0 Step 003000, model loss 24.3680, LR: 0.0000100000
真实数据: 佛罗伦萨的攻势下苟延
结果显示: 佛罗伦萨的政势下萄延
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.3788, LR: 0.0000100000
真实数据: Cfruitless
结果显示: Cfruitless
Epoch 0 Step 003200, model loss 0.0061, LR: 0.0000100000
真实数据: 刚才环顾四周一看，在
结果显示: 刚才环顾四周一看，在
Epoch 0 Step 003300, model loss 0.0670, LR: 0.0000100000
真实数据: ，不规则动词的变化形
结果显示: ，不规则动词的变化形
Epoch 0 Step 003400, model loss 0.0042, LR: 0.0000100000
真实数据: 其主馆可容纳八万观众
结果显示: 其主馆可容纳八万观众
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021C11238258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 1.9627, LR: 0.0000100000
真实数据: 岳父的话点醒了阿尤夫
结果显示: 父的话点醒了阿尤夫
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0559, LR: 0.0000100000
真实数据: 让路人看了觉得很新鲜
结果显示: 让路人看了觉得很新鲜
Epoch 0 Step 000200, model loss 3.0639, LR: 0.0000100000
真实数据: 可常用和滥用。笑起来
结果显示: 可常用和G用。笑起来
Epoch 0 Step 000300, model loss 0.3824, LR: 0.0000100000
真实数据: 国临床肿瘤学会(AS
结果显示: 国临床肿瘤学会(AS
Epoch 0 Step 000400, model loss 0.0180, LR: 0.0000100000
真实数据: 小罗祖，中国是一个很
结果显示: 小罗祖，中国是一个很
Epoch 0 Step 000500, model loss 0.0207, LR: 0.0000100000
真实数据: 个灵活、复原力强的团
结果显示: 个灵活、复原力强的团
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.1742, LR: 0.0000100000
真实数据: 市的花天酒地跟我无关
结果显示: 市的花天酒地跟我无关
Epoch 0 Step 000700, model loss 0.0592, LR: 0.0000100000
真实数据: 南航空公司提供的材料
结果显示: 南航空公司提供的材料
Epoch 0 Step 000800, model loss 0.1130, LR: 0.0000100000
真实数据: 。还要懂得使用高效、
结果显示: 。还要懂得使用高效、
Epoch 0 Step 000900, model loss 0.0864, LR: 0.0000100000
真实数据: 个任务从前有人执行过
结果显示: 个任务从前有人执行过
Epoch 0 Step 001000, model loss 0.0529, LR: 0.0000100000
真实数据: 以靠近同乡朋友的稳定
结果显示: 以靠近同乡朋友的稳定
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.5726, LR: 0.0000100000
真实数据: Boucher对布朗
结果显示: Boueher对布朗
Epoch 0 Step 001200, model loss 0.0007, LR: 0.0000100000
真实数据: 这不是明天就会发生的
结果显示: 这不是明天就会发生的
Epoch 0 Step 001300, model loss 0.1535, LR: 0.0000100000
真实数据: “文明办网、文明上网
结果显示: “文明办网、文明上网
Epoch 0 Step 001400, model loss 0.0045, LR: 0.0000100000
真实数据: 层门上，他们也没有强
结果显示: 层门上，他们也没有强
Epoch 0 Step 001500, model loss 5.6901, LR: 0.0000100000
真实数据: 完成封井计划。也就是
结果显示: 完成封并计划。也就是
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.1867, LR: 0.0000100000
真实数据: 现在新建的4D的影院
结果显示: 现在新建的4D的影院
Epoch 0 Step 001700, model loss 1.5512, LR: 0.0000100000
真实数据: 我国的香港地区和台湾
结果显示: 我国的香港地区和台湾
Epoch 0 Step 001800, model loss 2.5656, LR: 0.0000100000
真实数据: 一般需要陪走服务的孩
结果显示: 一般需要陷走服务的孩
Epoch 0 Step 001900, model loss 1.7092, LR: 0.0000100000
真实数据: 其间“李白”几度落泪
结果显示: 其间“李白”几度怎泪
Epoch 0 Step 002000, model loss 0.0116, LR: 0.0000100000
真实数据: 大意）随身携带一个网
结果显示: 大意）随身携带一个网
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 12.7144, LR: 0.0000100000
真实数据: 把势强盗。闵大洪说。
结果显示: 把势强盗。阅大洪说。
Epoch 0 Step 002200, model loss 0.0325, LR: 0.0000100000
真实数据: 感叹“讲解、演示很精
结果显示: 感叹“讲解、演示很精
Epoch 0 Step 002300, model loss 0.0155, LR: 0.0000100000
真实数据: 我为妖，在这个事例中
结果显示: 我为妖，在这个事例中
Epoch 0 Step 002400, model loss 10.2560, LR: 0.0000100000
真实数据: 公更是连个影子都瞧不
结果显示: 公更是连个影子都眼不
Epoch 0 Step 002500, model loss 7.5582, LR: 0.0000100000
真实数据: 权的墨合销售对这种模
结果显示: 权的圣合销售对这种模
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 7.4656, LR: 0.0000100000
真实数据: :张学良穿着一件雪白
结果显示: :张学良穿着一件警白二
Epoch 0 Step 002700, model loss 0.0461, LR: 0.0000100000
真实数据: 生提醒，既不合情、合
结果显示: 生提醒，既不合情、合
Epoch 0 Step 002800, model loss 1.2635, LR: 0.0000100000
真实数据: 拦截本已少得可怜的河
结果显示: 挡截本已少得可怜的河
Epoch 0 Step 002900, model loss 34.9247, LR: 0.0000100000
真实数据: 若酤自啖，提供岗位数
结果显示: 若酷自魄，提供岗位数
Epoch 0 Step 003000, model loss 0.8331, LR: 0.0000100000
真实数据: 广东教育学院天津某寺
结果显示: 广东教育学院天津某寺
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.3641, LR: 0.0000100000
真实数据: 但医生都不同意，“慈
结果显示: 但医生都不同意，“慈
Epoch 0 Step 003200, model loss 8.4989, LR: 0.0000100000
真实数据: 斯--白俄罗斯联盟共
结果显示: 期--白轨罗斯联盟共
Epoch 0 Step 003300, model loss 3.9398, LR: 0.0000100000
真实数据: 时间采访北京移动和咨
结果显示: 时间采访北京稿动和咨
Epoch 0 Step 003400, model loss 25.2147, LR: 0.0000100000
真实数据: 沙、高温、干旱、饥饿
结果显示: 沙、高温、干早、饥
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000261E37DA258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 2.2309, LR: 0.0000100000
真实数据: cn作为互联星空网站
结果显示: on作为互联星空网站
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0325, LR: 0.0000100000
真实数据: 比奔驰快仿佛沿着它的
结果显示: 比奔驰快仿佛沿着它的
Epoch 0 Step 000200, model loss 0.4753, LR: 0.0000100000
真实数据: egulatorsi
结果显示: egulatorsi
Epoch 0 Step 000300, model loss 1.1271, LR: 0.0000100000
真实数据: 获得通过。但总体上讲
结果显示: 我得通过。但总体上讲
Epoch 0 Step 000400, model loss 0.8492, LR: 0.0000100000
真实数据: “它自动跳频抗干扰与
结果显示: “它自动跳频抗干扰与
Epoch 0 Step 000500, model loss 0.0620, LR: 0.0000100000
真实数据: 决定了各个经济实体追
结果显示: 决定了各个经济实体追
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 26.7716, LR: 0.0000100000
真实数据: 次染发顺其自然逍逍停
结果显示: 次染发顺其自然遵遵停
Epoch 0 Step 000700, model loss 1.2355, LR: 0.0000100000
真实数据: eersdomore
结果显示: eersdomore
Epoch 0 Step 000800, model loss 0.0152, LR: 0.0000100000
真实数据: 如同一切都没有发生过
结果显示: 如同一切都没有发生过
Epoch 0 Step 000900, model loss 4.2233, LR: 0.0000100000
真实数据: IRL（梦中女郎）》
结果显示: IRL（梦中女部）》
Epoch 0 Step 001000, model loss 0.0167, LR: 0.0000100000
真实数据: 点放在答题与书写的规
结果显示: 点放在答题与书写的规
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1039, LR: 0.0000100000
真实数据: 上述分析与介绍，还有
结果显示: 上述分析与介绍，还有
Epoch 0 Step 001200, model loss 9.0581, LR: 0.0000100000
真实数据: 现老张的两个儿子也患
结果显示: 现寿张的两个儿子也惠
Epoch 0 Step 001300, model loss 2.7249, LR: 0.0000100000
真实数据: 的时候，甚至有些妒忌
结果显示: 的时候，甚至有些妙忌
Epoch 0 Step 001400, model loss 6.7558, LR: 0.0000100000
真实数据: 土扬尘，婢至，”杨金
结果显示: 土扬尘，婢锉至，”杨余
Epoch 0 Step 001500, model loss 0.0144, LR: 0.0000100000
真实数据: 他相信，6、长生久视
结果显示: 他相信，6、长生久视
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.5071, LR: 0.0000100000
真实数据: 了了，派使者长途跋涉
结果显示: 了了，派使者长途跋涉
Epoch 0 Step 001700, model loss 0.0031, LR: 0.0000100000
真实数据: 我们公司有一个很大的
结果显示: 我们公司有一个很大的
Epoch 0 Step 001800, model loss 16.0134, LR: 0.0000100000
真实数据: 80,2006年普通
结果显示: 80.2006年普通
Epoch 0 Step 001900, model loss 0.9552, LR: 0.0000100000
真实数据: 常遭毒魔狠怪，午夜时
结果显示: 常遭毒度魔狠怪，午夜时
Epoch 0 Step 002000, model loss 0.0197, LR: 0.0000100000
真实数据: 大多数病人最后需要终
结果显示: 大多数病人最后需要终
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 17.2976, LR: 0.0000100000
真实数据: 媛在面试之后赶往地下
结果显示: 暖在面试之后赶往地下
Epoch 0 Step 002200, model loss 1.0002, LR: 0.0000100000
真实数据: 实际年龄其实还没有王
结果显示: 实际年龄其实还没有王
Epoch 0 Step 002300, model loss 0.0165, LR: 0.0000100000
真实数据: 学法学院法学专业的一
结果显示: 学法学院法学专业的一
Epoch 0 Step 002400, model loss 3.6703, LR: 0.0000100000
真实数据: 他们产生越来越大的诱
结果显示: 他们产生越来越大的鸿
Epoch 0 Step 002500, model loss 0.0792, LR: 0.0000100000
真实数据: 我认为那一段很能够引
结果显示: 我认为那一段很能够引
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1180, LR: 0.0000100000
真实数据: 您营造如家的spa感
结果显示: 您营造如家的spa感
Epoch 0 Step 002700, model loss 0.0310, LR: 0.0000100000
真实数据: 危坐移时，3、爱民思
结果显示: 危坐移时，3、爱民思
Epoch 0 Step 002800, model loss 0.0508, LR: 0.0000100000
真实数据: 邻城市的区位优势开发
结果显示: 邻城市的区位优势开发
Epoch 0 Step 002900, model loss 0.0209, LR: 0.0000100000
真实数据: 投资者，直到今年4月
结果显示: 投资者，直到今年4月
Epoch 0 Step 003000, model loss 0.0072, LR: 0.0000100000
真实数据: 许小弟坏了自己的夺冠
结果显示: 许小弟坏了自己的夺冠
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.8636, LR: 0.0000100000
真实数据: 米拉继子的威廉和哈里
结果显示: 米拉继子的威廉和哈里
Epoch 0 Step 003200, model loss 0.6816, LR: 0.0000100000
真实数据: 才能不断地除弊革新。
结果显示: 才能不断地除弊革新。
Epoch 0 Step 003300, model loss 0.0386, LR: 0.0000100000
真实数据: 好学习，文物古迹众多
结果显示: 好学习，文物古迹众多
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001EE4D609258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.4620, LR: 0.0000100000
真实数据: 及中国全境都在其作战
结果显示: 及中国全境都在其作战
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0301, LR: 0.0000100000
真实数据: 圣，病历是反映医疗过
结果显示: 圣，病历是反映医疗过
Epoch 0 Step 000200, model loss 1.0977, LR: 0.0000100000
真实数据: 找回记忆里故乡那片灿
结果显示: 找回记忆里故乡那片刘
Epoch 0 Step 000300, model loss 4.9146, LR: 0.0000100000
真实数据: ”。第一批进京大学生
结果显示: ”，第一批进京大学生
Epoch 0 Step 000400, model loss 0.5692, LR: 0.0000100000
真实数据: 达到我省联考专业合格
结果显示: 达到我省联考专业合格
Epoch 0 Step 000500, model loss 0.6751, LR: 0.0000100000
真实数据: eBay试图通过一个
结果显示: eBay试图通过一个
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0075, LR: 0.0000100000
真实数据: 、袭击日本人的排日运
结果显示: 、袭击日本人的排日运
Epoch 0 Step 000700, model loss 0.0042, LR: 0.0000100000
真实数据: 常与死为伍!相离三千
结果显示: 常与死为伍!相离三千
Epoch 0 Step 000800, model loss 0.2033, LR: 0.0000100000
真实数据: 8亿元人民币(约合3
结果显示: 8亿元人民币(约合3
Epoch 0 Step 000900, model loss 1.0330, LR: 0.0000100000
真实数据: 相关图书:富勒姆对米
结果显示: 相关图书:富勒姆对米
Epoch 0 Step 001000, model loss 1.2494, LR: 0.0000100000
真实数据: 票价格某一个交易日收
结果显示: 涨价格某一个交易日收
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.2028, LR: 0.0000100000
真实数据: 类材料以证明基督主义
结果显示: 类材料以证明基督主义
Epoch 0 Step 001200, model loss 17.8426, LR: 0.0000100000
真实数据: 《金沙奇葩》:窃意为
结果显示: 《金沙奇范》:笫意为
Epoch 0 Step 001300, model loss 9.1314, LR: 0.0000100000
真实数据: 8．65分。易边再战
结果显示: 8.的5分。易边再战
Epoch 0 Step 001400, model loss 1.6441, LR: 0.0000100000
真实数据: 在市场普遍预期到5%
结果显示: 在市场普遍甭预期到5%
Epoch 0 Step 001500, model loss 1.0833, LR: 0.0000100000
真实数据: 高薪收入行业。18.
结果显示: 高薪收入行业，18.
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 7.5690, LR: 0.0000100000
真实数据: 会务会展经济的衍生品
结果显示: 会务会展经济的餐生品
Epoch 0 Step 001700, model loss 34.7321, LR: 0.0000100000
真实数据: 年后，联合齐王司马
结果显示: 年后，联合齐王司马同
Epoch 0 Step 001800, model loss 0.1589, LR: 0.0000100000
真实数据: 墨挥毫，7健全的随访
结果显示: 墨挥毫，7健全的随访
Epoch 0 Step 001900, model loss 0.0606, LR: 0.0000100000
真实数据: ，coordinat
结果显示: ，coordinat
Epoch 0 Step 002000, model loss 14.0496, LR: 0.0000100000
真实数据: 005年初刚刚推出的
结果显示: 005年初冈冈推出的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.2516, LR: 0.0000100000
真实数据: 是貌合。女篮队员明显
结果显示: 是貌合。女篮队员明显
Epoch 0 Step 002200, model loss 8.2581, LR: 0.0000100000
真实数据: 司认为，多由分娩、流
结果显示: 司认为，多由分挽、流
Epoch 0 Step 002300, model loss 0.0854, LR: 0.0000100000
真实数据: 优质、可信的商品及服
结果显示: 优质、可信的商品及服
Epoch 0 Step 002400, model loss 2.6979, LR: 0.0000100000
真实数据: 至于“慈悲”，转侧不
结果显示: 至于“露悲”，转侧不
Epoch 0 Step 002500, model loss 0.1282, LR: 0.0000100000
真实数据: 化了成本结构。第3招
结果显示: 化了成本结构。第3招
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 10.2585, LR: 0.0000100000
真实数据: 的出路是确定旱作农业
结果显示: 的出路是确定早作农业
Epoch 0 Step 002700, model loss 4.6243, LR: 0.0000100000
真实数据: 两种情况发生时，不必
结果显示: 两种情观发生时，不必
Epoch 0 Step 002800, model loss 0.1481, LR: 0.0000100000
真实数据: 47万;日前有媒体报
结果显示: 47万;日前有媒体报
Epoch 0 Step 002900, model loss 6.0274, LR: 0.0000100000
真实数据: 位玩伴告诉我，收取学
结果显示: 位玩障告诉我，收取学
Epoch 0 Step 003000, model loss 3.2794, LR: 0.0000100000
真实数据: 怒叱曰:对方开口便问
结果显示: 怒叱曰:对方开口便问
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0332, LR: 0.0000100000
真实数据: 9师在长津湖战斗发起
结果显示: 9师在长津湖战斗发起
Epoch 0 Step 003200, model loss 10.8113, LR: 0.0000100000
真实数据: 必生嗔怒。-请想象一
结果显示: 必生镇怒。-请想象一
Epoch 0 Step 003300, model loss 5.2113, LR: 0.0000100000
真实数据: 结了上述两种片面性的
结果显示: 结了上述两旷片面性的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001F881769258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0592, LR: 0.0000100000
真实数据: 人事部第3号令和浙江
结果显示: 人事部第3号令和浙江
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.9652, LR: 0.0000100000
真实数据: 温柔和天真可爱的一面
结果显示: 温柔和天真可爱的一面
Epoch 0 Step 000200, model loss 4.6463, LR: 0.0000100000
真实数据: 司董事、副总经理、总
结果显示: 引董事、副总经理、总
Epoch 0 Step 000300, model loss 4.5099, LR: 0.0000100000
真实数据: 大约500个出版公司
结果显示: 大约500个出限公司
Epoch 0 Step 000400, model loss 0.0664, LR: 0.0000100000
真实数据: 也要和老太太说上两句
结果显示: 也要和老太太说上两句
Epoch 0 Step 000500, model loss 2.2749, LR: 0.0000100000
真实数据: 不知道该怎么“拒绝”
结果显示: 不知道读怎么“把绝”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 4.0861, LR: 0.0000100000
真实数据: 中主要原因有这样三条
结果显示: 中主要原因有这样三条
Epoch 0 Step 000700, model loss 0.0011, LR: 0.0000100000
真实数据: 两个以上机关岗位任职
结果显示: 两个以上机关岗位任职
Epoch 0 Step 000800, model loss 0.0118, LR: 0.0000100000
真实数据: 他的自信都没有吗?”
结果显示: 他的自信都没有吗?”
Epoch 0 Step 000900, model loss 0.3239, LR: 0.0000100000
真实数据: 女曰:在建设新农村中
结果显示: 女曰:在建设新农村中
Epoch 0 Step 001000, model loss 9.4200, LR: 0.0000100000
真实数据: 播员:科比2分1篮板
结果显示: 榻员:科比2分1媒板
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1235, LR: 0.0000100000
真实数据: 力好提供技术咨询与服
结果显示: 力好提供技术咨询与服
Epoch 0 Step 001200, model loss 10.8400, LR: 0.0000100000
真实数据: 元椿批评胡乔木就是反
结果显示: 元榨批评胡乔末就是反
Epoch 0 Step 001300, model loss 11.1785, LR: 0.0000100000
真实数据: 从小倩事故里面看到的
结果显示: 从小情事故里面看到的
Epoch 0 Step 001400, model loss 4.2733, LR: 0.0000100000
真实数据: ，品牌效应已经非常明
结果显示: ，晶牌效应已经非常明
Epoch 0 Step 001500, model loss 0.3152, LR: 0.0000100000
真实数据: 在台湾都没有民意基础
结果显示: 在台湾都没有民意基础
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.1750, LR: 0.0000100000
真实数据: 癌症发病逐渐有年轻化
结果显示: 癌症发病逐渐有年轻化
Epoch 0 Step 001700, model loss 4.6319, LR: 0.0000100000
真实数据: 在，一局未终，虚假做
结果显示: 在，一局未终，虚假做
Epoch 0 Step 001800, model loss 0.1825, LR: 0.0000100000
真实数据: 然后从南侧下来，正好
结果显示: 然后从南侧下来，正好
Epoch 0 Step 001900, model loss 1.2981, LR: 0.0000100000
真实数据: 但从实际发生的案件看
结果显示: 但从实际发生的案件看
Epoch 0 Step 002000, model loss 0.1968, LR: 0.0000100000
真实数据: 其后的多场战争中的实
结果显示: 其后的多场战争中的实
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0098, LR: 0.0000100000
真实数据: 很多职业经理人的权利
结果显示: 很多职业经理人的权利
Epoch 0 Step 002200, model loss 0.4552, LR: 0.0000100000
真实数据: 恒有欲也，到1930
结果显示: 恒有欲也，到1930
Epoch 0 Step 002300, model loss 0.0306, LR: 0.0000100000
真实数据: 个人的总资产高达9亿
结果显示: 个人的总资产高达9亿
Epoch 0 Step 002400, model loss 0.2281, LR: 0.0000100000
真实数据: 最高的男性得到牙周病
结果显示: 最高的男性得到牙周病
Epoch 0 Step 002500, model loss 0.0192, LR: 0.0000100000
真实数据: 设置、训练安排、各种
结果显示: 设置、训练安排、各种
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.4013, LR: 0.0000100000
真实数据: 姓王的国脚也增至五名
结果显示: 姓王的国脚舆也增至五名
Epoch 0 Step 002700, model loss 1.8458, LR: 0.0000100000
真实数据: 了这家公司的详细资料
结果显示: 了这家公司的详细究料
Epoch 0 Step 002800, model loss 2.4615, LR: 0.0000100000
真实数据: 的双币种结构性理财(
结果显示: 的双币种结构性理财（
Epoch 0 Step 002900, model loss 0.3180, LR: 0.0000100000
真实数据: 不仅如此，可是没过多
结果显示: 不仅如此，可是没过多
Epoch 0 Step 003000, model loss 2.5768, LR: 0.0000100000
真实数据: 成为墓葬标志物。”不
结果显示: 成为墓排标志物。”不
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0842, LR: 0.0000100000
真实数据: “我绝对绝对的感到失
结果显示: “我绝对绝对的感到失
Epoch 0 Step 003200, model loss 0.0096, LR: 0.0000100000
真实数据: 到了不少单位的面试通
结果显示: 到了不少单位的面试通
Epoch 0 Step 003300, model loss 1.4717, LR: 0.0000100000
真实数据: 个长期而又艰巨的过程
结果显示: 个长期而又眼巨的过程
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000228E9A09258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0318, LR: 0.0000100000
真实数据: 兼并重组也将大面积展
结果显示: 兼并重组也将大面积展
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.6788, LR: 0.0000100000
真实数据: 感觉到被扔在了大海中
结果显示: 感觉到被扔在了大海中
Epoch 0 Step 000200, model loss 0.8658, LR: 0.0000100000
真实数据: 接待过一位姓陈的工程
结果显示: 接待过一位姓陈的工程
Epoch 0 Step 000300, model loss 1.7557, LR: 0.0000100000
真实数据: 至邻邑。[1][2]
结果显示: 至殇邑。[1][2]
Epoch 0 Step 000400, model loss 3.7687, LR: 0.0000100000
真实数据: 同类产品要贵出千元以
结果显示: 同类产品要责出千元以
Epoch 0 Step 000500, model loss 2.2161, LR: 0.0000100000
真实数据: 明道，积半月为仆所窥
结果显示: 明道，积半月为仆所察
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0044, LR: 0.0000100000
真实数据: 行电化教学和网络化教
结果显示: 行电化教学和网络化教
Epoch 0 Step 000700, model loss 0.0799, LR: 0.0000100000
真实数据: 怀疑起整个行业的前景
结果显示: 怀疑起整个行业的前景
Epoch 0 Step 000800, model loss 0.0070, LR: 0.0000100000
真实数据: 省医保管理部门的高度
结果显示: 省医保管理部门的高度
Epoch 0 Step 000900, model loss 3.2611, LR: 0.0000100000
真实数据: 空间打开了想象的天窗
结果显示: 空间打开了想象的天丘
Epoch 0 Step 001000, model loss 2.8072, LR: 0.0000100000
真实数据: 收到intel人力M
结果显示: 收到itcel人力M
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0102, LR: 0.0000100000
真实数据: 事本来就不是技术工作
结果显示: 事本来就不是技术工作
Epoch 0 Step 001200, model loss 5.8187, LR: 0.0000100000
真实数据: 真是你一贯的做事方式
结果显示: 真是你一贸的做事方式
Epoch 0 Step 001300, model loss 0.0038, LR: 0.0000100000
真实数据: 是完美动人的故事都值
结果显示: 是完美动人的故事都值
Epoch 0 Step 001400, model loss 1.7301, LR: 0.0000100000
真实数据: ，染发剂含致癌物有害
结果显示: ，染发剂含致瘤物有害
Epoch 0 Step 001500, model loss 0.0672, LR: 0.0000100000
真实数据: 5、不能过分求新求异
结果显示: 5、不能过分求新求异
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.2162, LR: 0.0000100000
真实数据: 防和解决医疗事故和纠
结果显示: 防和解决医疗事故和纠
Epoch 0 Step 001700, model loss 5.6842, LR: 0.0000100000
真实数据: 百日红，诗人只能仰望
结果显示: 百日红，诗人只能钙望
Epoch 0 Step 001800, model loss 0.7172, LR: 0.0000100000
真实数据: 出做一个体贴的好老婆
结果显示: 出做一个体贴的好老婆
Epoch 0 Step 001900, model loss 0.0195, LR: 0.0000100000
真实数据: ）西安市大南门内西顺
结果显示: ）西安市大南门内西顺
Epoch 0 Step 002000, model loss 0.1603, LR: 0.0000100000
真实数据: 187人的78.82
结果显示: 187人的78.82
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0471, LR: 0.0000100000
真实数据: 要感谢伟哥所含的活性
结果显示: 要感谢伟哥所含的活性
Epoch 0 Step 002200, model loss 0.9796, LR: 0.0000100000
真实数据: ?推销是一种沉默的艺
结果显示: ?推销是一种沉默的艺
Epoch 0 Step 002300, model loss 1.5166, LR: 0.0000100000
真实数据: 现了一道闪电般的裂缝
结果显示: 现了一道闪电般的裂症
Epoch 0 Step 002400, model loss 3.5463, LR: 0.0000100000
真实数据: !不觉向暮。4、要经
结果显示: !不觉向荐。4、要经
Epoch 0 Step 002500, model loss 15.3382, LR: 0.0000100000
真实数据: 而时间的效益也大的多
结果显示: 而时润的频益也大的多
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0270, LR: 0.0000100000
真实数据: 电讯营销中心副总经理
结果显示: 电讯营销中心副总经理
Epoch 0 Step 002700, model loss 0.1033, LR: 0.0000100000
真实数据: 眼现代空降作战要求和
结果显示: 眼现代空降作战要求和
Epoch 0 Step 002800, model loss 0.0187, LR: 0.0000100000
真实数据: 最后也因为疲劳而付出
结果显示: 最后也因为疲劳而付出
Epoch 0 Step 002900, model loss 0.0622, LR: 0.0000100000
真实数据: 员也进入空军航空大学
结果显示: 员也进入空军航空大学
Epoch 0 Step 003000, model loss 0.0584, LR: 0.0000100000
真实数据: 出生就是为了死亡的木
结果显示: 出生就是为了死亡的木
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0036, LR: 0.0000100000
真实数据: 但把责任全部推给博士
结果显示: 但把责任全部推给博士
Epoch 0 Step 003200, model loss 0.0015, LR: 0.0000100000
真实数据: 收购人指北京物美商业
结果显示: 收购人指北京物美商业
Epoch 0 Step 003300, model loss 0.4840, LR: 0.0000100000
真实数据: 大唐王驾下钦差上西天
结果显示: 大唐王驾下钦差上西天
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001CBDB478258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.0504, LR: 0.0000100000
真实数据: 预留地”的名义辟出2
结果显示: 预留地”的名义晖出2
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1841, LR: 0.0000100000
真实数据: 我们所说的“洋鸡蛋”
结果显示: 我们所说的“洋鸡蛋”
Epoch 0 Step 000200, model loss 1.0913, LR: 0.0000100000
真实数据: 下选一本黑博士的阅读
结果显示: 下送一本黑博士的阅读
Epoch 0 Step 000300, model loss 0.5558, LR: 0.0000100000
真实数据: 疗改革或伊拉克的政权
结果显示: 疗改革或伊拉克的政权
Epoch 0 Step 000400, model loss 0.0209, LR: 0.0000100000
真实数据: 欢印度音乐和电影的游
结果显示: 欢印度音乐和电影的游
Epoch 0 Step 000500, model loss 0.0036, LR: 0.0000100000
真实数据: 经历和做老爸的心得写
结果显示: 经历和做老爸的心得写
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.2580, LR: 0.0000100000
真实数据: 痛片以后，临床上也可
结果显示: 痛片以后，临床上也可
Epoch 0 Step 000700, model loss 0.0526, LR: 0.0000100000
真实数据: 对于许多工作仍无着落
结果显示: 对于许多工作仍无着落
Epoch 0 Step 000800, model loss 2.1874, LR: 0.0000100000
真实数据: 费者的角度去重新定位
结果显示: 贡者的角度去重新定位
Epoch 0 Step 000900, model loss 0.1315, LR: 0.0000100000
真实数据: 第一盘比赛，新的标准
结果显示: 第一盘比赛，新的标准
Epoch 0 Step 001000, model loss 0.6037, LR: 0.0000100000
真实数据: 欧盟制药协会（EFP
结果显示: 欧盟制药协会（EFP
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1094, LR: 0.0000100000
真实数据: 长的情绪，挂牌提示3
结果显示: 长的情绪，挂牌提示3
Epoch 0 Step 001200, model loss 0.0047, LR: 0.0000100000
真实数据: 工人员应要求用人单位
结果显示: 工人员应要求用人单位
Epoch 0 Step 001300, model loss 0.1050, LR: 0.0000100000
真实数据: 的干眼症状的确缓解了
结果显示: 的干眼症状的确缓解了
Epoch 0 Step 001400, model loss 0.0021, LR: 0.0000100000
真实数据: 北京和上海都设有票务
结果显示: 北京和上海都设有票务
Epoch 0 Step 001500, model loss 10.4908, LR: 0.0000100000
真实数据: 场控球失误，为赦始平
结果显示: 场控球失误，为鼓始平
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.4053, LR: 0.0000100000
真实数据: ports007ce
结果显示: Ports007ce
Epoch 0 Step 001700, model loss 0.0359, LR: 0.0000100000
真实数据: 为网友来讲可能听了郑
结果显示: 为网友来讲可能听了郑
Epoch 0 Step 001800, model loss 2.9407, LR: 0.0000100000
真实数据: 的经济困难学生保障体
结果显示: 的经济困难学生保滕体
Epoch 0 Step 001900, model loss 2.4449, LR: 0.0000100000
真实数据: 17个黄金周今天画上
结果显示: 17个费金周今天画上
Epoch 0 Step 002000, model loss 0.0054, LR: 0.0000100000
真实数据: 者来到“动力100”
结果显示: 者来到“动力100”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.4141, LR: 0.0000100000
真实数据: 状在休息后会有所缓解
结果显示: 状在休息后会有所缓解
Epoch 0 Step 002200, model loss 0.0431, LR: 0.0000100000
真实数据: 以忘记自己曾处理过的
结果显示: 以忘记自己曾处理过的
Epoch 0 Step 002300, model loss 0.0014, LR: 0.0000100000
真实数据: 部分大学生在求职和就
结果显示: 部分大学生在求职和就
Epoch 0 Step 002400, model loss 13.5293, LR: 0.0000100000
真实数据: 自从“3・19”枪击
结果显示: 自从"3-19”枪击
Epoch 0 Step 002500, model loss 0.0393, LR: 0.0000100000
真实数据: 此，则是中国近代历史
结果显示: 此，则是中国近代历史
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.3108, LR: 0.0000100000
真实数据: 想把它们驱散。一定要
结果显示: 想把它们驱散。一定要
Epoch 0 Step 002700, model loss 4.8046, LR: 0.0000100000
真实数据: 年，处处显露出欧洲风
结果显示: 年，处处显露出政洲双
Epoch 0 Step 002800, model loss 0.0117, LR: 0.0000100000
真实数据: 作品却很少，她说她很
结果显示: 作品却很少，她说她很
Epoch 0 Step 002900, model loss 0.0496, LR: 0.0000100000
真实数据: 公司总股份的4.1%
结果显示: 公司总股份的4.1%
Epoch 0 Step 003000, model loss 0.0130, LR: 0.0000100000
真实数据: 高速前进时则跃出水面
结果显示: 高速前进时则跃出水面
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0240, LR: 0.0000100000
真实数据: 管理、法学、英语、日
结果显示: 管理、法学、英语、日
Epoch 0 Step 003200, model loss 0.0267, LR: 0.0000100000
真实数据: 内首次飞船返回舱模拟
结果显示: 内首次飞船返回舱模拟
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000220E8828258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0205, LR: 0.0000100000
真实数据: 006年5月9日但3
结果显示: 006年5月9日但3
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.4795, LR: 0.0000100000
真实数据: ，大教堂内部也有以日
结果显示: ，大教堂内部也有以日
Epoch 0 Step 000200, model loss 5.6951, LR: 0.0000100000
真实数据: 刚才游伟教授介绍我是
结果显示: 刚才游体教授介绍我是
Epoch 0 Step 000300, model loss 0.3965, LR: 0.0000100000
真实数据: 地当“地陪”、找“地
结果显示: 地当“地陪”、找“地
Epoch 0 Step 000400, model loss 22.2316, LR: 0.0000100000
真实数据: 漯河分行还通过委托贷
结果显示: 漂河分行还通过委托贷
Epoch 0 Step 000500, model loss 0.0197, LR: 0.0000100000
真实数据: 1日至7日每天上午1
结果显示: 1日至7日每天上午1
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 2.5245, LR: 0.0000100000
真实数据: 一定要履行当初允婚的
结果显示: 一定要履行当初允婚的
Epoch 0 Step 000700, model loss 0.0031, LR: 0.0000100000
真实数据: 拥有先进的食品加工、
结果显示: 拥有先进的食品加工、
Epoch 0 Step 000800, model loss 7.5234, LR: 0.0000100000
真实数据: 我道“你有意偷宝真不
结果显示: 我道“你有必偷宝具不
Epoch 0 Step 000900, model loss 0.0123, LR: 0.0000100000
真实数据: 后逐年递增。将以强合
结果显示: 后逐年递增。将以强合
Epoch 0 Step 001000, model loss 9.7433, LR: 0.0000100000
真实数据: 基酸在高温下常可形成
结果显示: 基在高漫下常可形成
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.5162, LR: 0.0000100000
真实数据: 跳。这样，专科(含高
结果显示: 跳。这样，专科(含高
Epoch 0 Step 001200, model loss 0.1677, LR: 0.0000100000
真实数据: 要使她再受刺激。”第
结果显示: 要使她再受刺激。”第
Epoch 0 Step 001300, model loss 0.1278, LR: 0.0000100000
真实数据: 关系《后汉书》以“南
结果显示: 关系《后汉书》以“南
Epoch 0 Step 001400, model loss 0.4040, LR: 0.0000100000
真实数据: 犹望女至。“零薪应聘
结果显示: 犹望女至。“零薪应聘
Epoch 0 Step 001500, model loss 0.0068, LR: 0.0000100000
真实数据: Grace首先在一位
结果显示: Grace首先在一位
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 5.3242, LR: 0.0000100000
真实数据: 头控老牝马，某如梦索
结果显示: 头控老井马，某如梦索
Epoch 0 Step 001700, model loss 2.3515, LR: 0.0000100000
真实数据: 要保护自己，说明在欧
结果显示: 要保护自己，说明在欧
Epoch 0 Step 001800, model loss 24.6636, LR: 0.0000100000
真实数据: 苇浮连片，无字之经，
结果显示: 管得连片，无字之经，
Epoch 0 Step 001900, model loss 0.0590, LR: 0.0000100000
真实数据: 3月31日的第四财季
结果显示: 3月31日的第四财季
Epoch 0 Step 002000, model loss 0.0037, LR: 0.0000100000
真实数据: 大作用?多年流行的看
结果显示: 大作用?多年流行的看
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.6960, LR: 0.0000100000
真实数据: PSTN）上短消息传
结果显示: PSTN)上短消息传
Epoch 0 Step 002200, model loss 0.0474, LR: 0.0000100000
真实数据: ”杨诺之。心情很不爽
结果显示: ”杨诺之。心情很不爽
Epoch 0 Step 002300, model loss 2.8748, LR: 0.0000100000
真实数据: ”国王便教取一口大锅
结果显示: ”国王便教取一日大锅
Epoch 0 Step 002400, model loss 1.5879, LR: 0.0000100000
真实数据: (章田/雅龙)小姐们
结果显示: (章田/雅推龙)小姐们
Epoch 0 Step 002500, model loss 3.7904, LR: 0.0000100000
真实数据: 孔雀:并发布了全市动
结果显示: 孔省:并发布了全市动
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 1.1598, LR: 0.0000100000
真实数据: 是很多单身写字楼白领
结果显示: 是很多单身写字楼白领
Epoch 0 Step 002700, model loss 0.0632, LR: 0.0000100000
真实数据: 她那极具传染力的消极
结果显示: 她那极具传染力的消极
Epoch 0 Step 002800, model loss 0.0044, LR: 0.0000100000
真实数据: 由训练骨干组成的示范
结果显示: 由训练骨干组成的示范
Epoch 0 Step 002900, model loss 1.7958, LR: 0.0000100000
真实数据: 大唐发电（0991）
结果显示: 大唐发电（0991)
Epoch 0 Step 003000, model loss 0.0039, LR: 0.0000100000
真实数据: 三是理清意脉优化组合
结果显示: 三是理清意脉优化组合
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.6467, LR: 0.0000100000
真实数据: 其次，000.00●
结果显示: 其次，000.00●
Epoch 0 Step 003200, model loss 0.0272, LR: 0.0000100000
真实数据: 有时间和男人为一点小
结果显示: 有时间和男人为一点小
Epoch 0 Step 003300, model loss 0.3016, LR: 0.0000100000
真实数据: 航总局从安全考虑曾一
结果显示: 航总局从安全考虑曾一
Epoch 0 Step 003400, model loss 0.0299, LR: 0.0000100000
真实数据: 报》3月2日报道了广
结果显示: 报》3月2日报道了广
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000192001D8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0046, LR: 0.0000100000
真实数据: 我不比任何人差。急当
结果显示: 我不比任何人差。急当
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0030, LR: 0.0000100000
真实数据: 今年是第一年采用“3
结果显示: 今年是第一年采用“3
Epoch 0 Step 000200, model loss 0.0022, LR: 0.0000100000
真实数据: 职业中心会为他们提供
结果显示: 职业中心会为他们提供
Epoch 0 Step 000300, model loss 1.7045, LR: 0.0000100000
真实数据: 而赂通朝士，在对方大
结果显示: 而赂通朝士，在对方大
Epoch 0 Step 000400, model loss 1.8075, LR: 0.0000100000
真实数据: 飞(代码:00076
结果显示: 飞（代码:00076
Epoch 0 Step 000500, model loss 0.5300, LR: 0.0000100000
真实数据: 也说明机构做多意图加
结果显示: 也说明机构做多意图加
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.6867, LR: 0.0000100000
真实数据: 公司的粘胶纤维年产量
结果显示: 公司的粘胶纤维年产量
Epoch 0 Step 000700, model loss 9.8236, LR: 0.0000100000
真实数据: 促进冷冻饮品质量的提
结果显示: 促进冷康饮品质量的捉
Epoch 0 Step 000800, model loss 0.0031, LR: 0.0000100000
真实数据: -1于1997年生产
结果显示: -1于1997年生产
Epoch 0 Step 000900, model loss 0.0722, LR: 0.0000100000
真实数据: 斯基小说的精读来建构
结果显示: 斯基小说的精读来建构
Epoch 0 Step 001000, model loss 0.0200, LR: 0.0000100000
真实数据: 在北京奥运会上再展雄
结果显示: 在北京奥运会上再展雄
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 4.0144, LR: 0.0000100000
真实数据: 匪劫镇时，涨幅2.2
结果显示: 团劫镇时，涨幅2.2
Epoch 0 Step 001200, model loss 0.1217, LR: 0.0000100000
真实数据: 易造成对问题判断能力
结果显示: 易造成对问题判断能力
Epoch 0 Step 001300, model loss 1.0519, LR: 0.0000100000
真实数据: 让伤口自然暴露在空气
结果显示: 让伤口自然暴露在空气
Epoch 0 Step 001400, model loss 7.6350, LR: 0.0000100000
真实数据: 46林毓生:实德的主
结果显示: 46林生:实德的主
Epoch 0 Step 001500, model loss 0.7170, LR: 0.0000100000
真实数据: 另陆航部队提供第3飞
结果显示: 另陆航部队提供第3飞
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.2376, LR: 0.0000100000
真实数据: 与当地的煤矿工业有着
结果显示: 与当地的煤矿工业有着
Epoch 0 Step 001700, model loss 6.2853, LR: 0.0000100000
真实数据: 众多热爱书籍、酷爱读
结果显示: 多热爱书籍、耐爱读
Epoch 0 Step 001800, model loss 0.4884, LR: 0.0000100000
真实数据: 。人民网北京2月10
结果显示: 。人民网北京2月10
Epoch 0 Step 001900, model loss 0.0382, LR: 0.0000100000
真实数据: 过了共和国宪法，好物
结果显示: 过了共和国宪法，好物
Epoch 0 Step 002000, model loss 0.2865, LR: 0.0000100000
真实数据: ，制造公司的总经理是
结果显示: ，制造公司的总经理是
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0590, LR: 0.0000100000
真实数据: 另交通补助400/月
结果显示: 另交通补助400/月
Epoch 0 Step 002200, model loss 0.0289, LR: 0.0000100000
真实数据: 行制定货币政策的角度
结果显示: 行制定货币政策的角度
Epoch 0 Step 002300, model loss 1.9464, LR: 0.0000100000
真实数据: 术论坛2006年度会
结果显示: 术洛坛2006年度会
Epoch 0 Step 002400, model loss 0.0285, LR: 0.0000100000
真实数据: 合设计生产，马赛:斯
结果显示: 合设计生产，马赛:斯
Epoch 0 Step 002500, model loss 0.0023, LR: 0.0000100000
真实数据: 必要时能独立进行作战
结果显示: 必要时能独立进行作战
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 10.4309, LR: 0.0000100000
真实数据: 在婴幼儿期缺少抚育与
结果显示: 在要动儿期缺少抚育与
Epoch 0 Step 002700, model loss 0.0115, LR: 0.0000100000
真实数据: 自己的将来有什么计划
结果显示: 自己的将来有什么计划
Epoch 0 Step 002800, model loss 12.3688, LR: 0.0000100000
真实数据: 给曲线下滑而不是上扬
结果显示: 能曲线下滑而不是上也标
Epoch 0 Step 002900, model loss 0.0230, LR: 0.0000100000
真实数据: 统的总体拥有成本也因
结果显示: 统的总体拥有成本也因
Epoch 0 Step 003000, model loss 4.8238, LR: 0.0000100000
真实数据: 能锻造出自己的屠龙宝
结果显示: 能锻造出自己的着龙宝
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0164, LR: 0.0000100000
真实数据: 对股指、人气的影响将
结果显示: 对股指、人气的影响将
Epoch 0 Step 003200, model loss 4.3114, LR: 0.0000100000
真实数据: 战术素养再次得到了体
结果显示: 战术多养再次得到了体
Epoch 0 Step 003300, model loss 3.3786, LR: 0.0000100000
真实数据: 务行业同样是性骚扰的
结果显示: 务行业同样是性强扰的
Epoch 0 Step 003400, model loss 0.8150, LR: 0.0000100000
真实数据: 的是其既有的C2C市
结果显示: 的是其既有的C2C市
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001CC09B28258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0009, LR: 0.0000100000
真实数据: 本方面再加上我们两个
结果显示: 本方面再加上我们两个
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0010, LR: 0.0000100000
真实数据: 料的局限和方法的不完
结果显示: 料的局限和方法的不完
Epoch 0 Step 000200, model loss 0.0285, LR: 0.0000100000
真实数据: erationspu
结果显示: erationspu
Epoch 0 Step 000300, model loss 0.0049, LR: 0.0000100000
真实数据: 都是使用排线与线路板
结果显示: 都是使用排线与线路板
Epoch 0 Step 000400, model loss 0.1690, LR: 0.0000100000
真实数据: 们在镜头面前如此的泰
结果显示: 们在镜头面前如此的泰
Epoch 0 Step 000500, model loss 10.7481, LR: 0.0000100000
真实数据: 一童急取水半盏递与大
结果显示: 一童急取水半盖遂与大
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.1222, LR: 0.0000100000
真实数据: 因为陆平给一个人理发
结果显示: 因为陆平给一个人理发
Epoch 0 Step 000700, model loss 0.0012, LR: 0.0000100000
真实数据: 如果使用手机国际漫游
结果显示: 如果使用手机国际漫游
Epoch 0 Step 000800, model loss 0.4491, LR: 0.0000100000
真实数据: 就业难的局面就会得到
结果显示: 就业难的局面就会得到
Epoch 0 Step 000900, model loss 0.0252, LR: 0.0000100000
真实数据: 1946年远东国际法
结果显示: 1946年远东国际法
Epoch 0 Step 001000, model loss 0.6419, LR: 0.0000100000
真实数据: 人大战太阳科比与贝尔
结果显示: 人大战太阳科比与贝尔
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0409, LR: 0.0000100000
真实数据: 罗斯是个人口严重缺乏
结果显示: 罗斯是个人口严重缺乏
Epoch 0 Step 001200, model loss 0.1405, LR: 0.0000100000
真实数据: 现中长期科技发展战略
结果显示: 现中长期科技发展战略
Epoch 0 Step 001300, model loss 0.0459, LR: 0.0000100000
真实数据: 深的还要算那条“世界
结果显示: 深的还要算那条“世界
Epoch 0 Step 001400, model loss 2.4196, LR: 0.0000100000
真实数据: 。给中国官员和候补官
结果显示: ，给中国官员和候补官
Epoch 0 Step 001500, model loss 0.0215, LR: 0.0000100000
真实数据: 还有很多高尔夫练习场
结果显示: 还有很多高尔夫练习场
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.2518, LR: 0.0000100000
真实数据: 再把这套试题从头看一
结果显示: 再把这套试题从头看一
Epoch 0 Step 001700, model loss 8.3510, LR: 0.0000100000
真实数据: 直播员:张海丽连续进
结果显示: 直播员钺海丽连续进
Epoch 0 Step 001800, model loss 0.0743, LR: 0.0000100000
真实数据: )反对关系训练质量明
结果显示: )反对关系训练质量明
Epoch 0 Step 001900, model loss 0.0093, LR: 0.0000100000
真实数据: 做好规划，意义很重大
结果显示: 做好规划，意义很重大
Epoch 0 Step 002000, model loss 0.0042, LR: 0.0000100000
真实数据: 合、民族医医院督导后
结果显示: 合、民族医医院督导后
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0008, LR: 0.0000100000
真实数据: 后赛第二轮的首场比赛
结果显示: 后赛第二轮的首场比赛
Epoch 0 Step 002200, model loss 0.0182, LR: 0.0000100000
真实数据: 是滋味。从这个意义上
结果显示: 是滋味。从这个意义上
Epoch 0 Step 002300, model loss 1.0172, LR: 0.0000100000
真实数据: 323,比如，戒公子
结果显示: 323,比如，戒公子
Epoch 0 Step 002400, model loss 0.0103, LR: 0.0000100000
真实数据: 开2005年度股东大
结果显示: 开2005年度股东大
Epoch 0 Step 002500, model loss 10.1502, LR: 0.0000100000
真实数据: 吗?三个澡堂另外相同
结果显示: 吗?三个躁堂另外相同
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.2239, LR: 0.0000100000
真实数据: 表示目前自己还未接到
结果显示: 表示目前自己还未接到
Epoch 0 Step 002700, model loss 0.0263, LR: 0.0000100000
真实数据: 透过欧美各地的旅客回
结果显示: 透过欧美各地的旅客回
Epoch 0 Step 002800, model loss 0.7178, LR: 0.0000100000
真实数据: 边细看，某专业媒体称
结果显示: 边细看，某专业媒体称
Epoch 0 Step 002900, model loss 7.9958, LR: 0.0000100000
真实数据: 师父，烟气穿过贮水的
结果显示: 师父，烟气穿过讦水的
Epoch 0 Step 003000, model loss 0.2935, LR: 0.0000100000
真实数据: 有什么错误要好好检查
结果显示: 有什么错误要好好检查
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 30.0524, LR: 0.0000100000
真实数据: 年通过新的教科书编纂
结果显示: 年通过新的教科书伸基
Epoch 0 Step 003200, model loss 0.0076, LR: 0.0000100000
真实数据: 大约占到总数的33%
结果显示: 大约占到总数的33%
Epoch 0 Step 003300, model loss 4.3705, LR: 0.0000100000
真实数据: 是用来培养数学家的啦
结果显示: 是用来培养数学家的驴
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000024D67798258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0199, LR: 0.0000100000
真实数据: 才30来岁，有害无益
结果显示: 才30来岁，有害无益
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0297, LR: 0.0000100000
真实数据: 不必像常规战争那样先
结果显示: 不必像常规战争那样先
Epoch 0 Step 000200, model loss 0.3709, LR: 0.0000100000
真实数据: 睡大觉，见壁间挂子昂
结果显示: 睡大觉，见壁间挂子昂
Epoch 0 Step 000300, model loss 0.0194, LR: 0.0000100000
真实数据: 要回过头将所有积分的
结果显示: 要回过头将所有积分的
Epoch 0 Step 000400, model loss 0.2361, LR: 0.0000100000
真实数据: 二年级结束后有一次在
结果显示: 二年级结束后有一次在
Epoch 0 Step 000500, model loss 0.0034, LR: 0.0000100000
真实数据: 今年新版中推出的线路
结果显示: 今年新版中推出的线路
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.1460, LR: 0.0000100000
真实数据: 。虽然在北京业绩做得
结果显示: 。虽然在北京业绩做得
Epoch 0 Step 000700, model loss 0.0626, LR: 0.0000100000
真实数据: 高曰:现在读者可以根
结果显示: 高曰:现在读者可以根
Epoch 0 Step 000800, model loss 0.0304, LR: 0.0000100000
真实数据: 福建省34个厅(局、
结果显示: 福建省34个厅(局、
Epoch 0 Step 000900, model loss 0.0030, LR: 0.0000100000
真实数据: 生又说:还有一群关系
结果显示: 生又说:还有一群关系
Epoch 0 Step 001000, model loss 0.1251, LR: 0.0000100000
真实数据: 金队效力的293场比
结果显示: 金队效力的293场比
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0374, LR: 0.0000100000
真实数据: 埋死者的右派都很难找
结果显示: 埋死者的右派都很难找
Epoch 0 Step 001200, model loss 1.2251, LR: 0.0000100000
真实数据: 眼里，叫“刘领队”了
结果显示: 眼里，则“刘领队”了
Epoch 0 Step 001300, model loss 0.0032, LR: 0.0000100000
真实数据: 无助于低收入群体增加
结果显示: 无助于低收入群体增加
Epoch 0 Step 001400, model loss 1.4887, LR: 0.0000100000
真实数据: 2003年的罗伯特-
结果显示: 2003年的罗伯特-
Epoch 0 Step 001500, model loss 1.2403, LR: 0.0000100000
真实数据: 甫近巢，是世界上最大
结果显示: 甫近巢，是世界上最大
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.6654, LR: 0.0000100000
真实数据: 堆满了乱七八糟的东西
结果显示: 堆满了乱七八糟的东西
Epoch 0 Step 001700, model loss 0.1269, LR: 0.0000100000
真实数据: 门客。我和女人略近些
结果显示: 门客。我和女人略近些
Epoch 0 Step 001800, model loss 0.0264, LR: 0.0000100000
真实数据: 家庭而不想工作的女性
结果显示: 家庭而不想工作的女性
Epoch 0 Step 001900, model loss 0.4034, LR: 0.0000100000
真实数据: )conducted
结果显示: )conducted
Epoch 0 Step 002000, model loss 15.0684, LR: 0.0000100000
真实数据: 有十来个协会呢!武磊
结果显示: 有十来个协会呢!武务
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0644, LR: 0.0000100000
真实数据: 旅游提供了集中展示产
结果显示: 旅游提供了集中展示产
Epoch 0 Step 002200, model loss 0.5132, LR: 0.0000100000
真实数据: 、与会计政策变更相联
结果显示: 、与会计政策变更相联
Epoch 0 Step 002300, model loss 15.9247, LR: 0.0000100000
真实数据: 脸如枯菜叶。”（同上
结果显示: 脸如九柴叶.”（同上
Epoch 0 Step 002400, model loss 0.3121, LR: 0.0000100000
真实数据: 他们都坚持送法到基层
结果显示: 他们都坚持送法到基层
Epoch 0 Step 002500, model loss 1.9428, LR: 0.0000100000
真实数据: 值观的国际法和国际习
结果显示: 值双的国际法和国际习
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0121, LR: 0.0000100000
真实数据: 路易斯-加西亚送出直
结果显示: 路易斯-加西亚送出直
Epoch 0 Step 002700, model loss 0.2121, LR: 0.0000100000
真实数据: 曰:提高自身的竞争能
结果显示: 曰:提高自身的竞争能
Epoch 0 Step 002800, model loss 2.8980, LR: 0.0000100000
真实数据: 云云雾雾，景区每年盈
结果显示: 云云雾雾，景区每年盈
Epoch 0 Step 002900, model loss 0.0081, LR: 0.0000100000
真实数据: 卫国赵长者家与他诵了
结果显示: 卫国赵长者家与他诵了
Epoch 0 Step 003000, model loss 0.0132, LR: 0.0000100000
真实数据: 并以6-4拿下第一盘
结果显示: 并以6-4拿下第一盘
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 15.7954, LR: 0.0000100000
真实数据: 会发现在暴风和潮浪蹂
结果显示: 会发现在暴风和潮浪踩
Epoch 0 Step 003200, model loss 0.5468, LR: 0.0000100000
真实数据: 的9月19日沈阳金德
结果显示: 的9月19日沈阳金德
Epoch 0 Step 003300, model loss 14.4699, LR: 0.0000100000
真实数据: 其慷慨豪爽，台军声称
结果显示: 其炼概豪爽，台军声称
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000024ADFFC8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 5.1433, LR: 0.0000100000
真实数据: 起草了整个事件的书面
结果显示: 起草了整个事件的书西
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 2.2764, LR: 0.0000100000
真实数据: 想教授课程的客座教授
结果显示: 想教授谋程的客座教授
Epoch 0 Step 000200, model loss 0.0235, LR: 0.0000100000
真实数据: 部要求各省市招办和高
结果显示: 部要求各省市招办和高
Epoch 0 Step 000300, model loss 0.0583, LR: 0.0000100000
真实数据: ，新的竞争焦点表决结
结果显示: ，新的竞争焦点表决结
Epoch 0 Step 000400, model loss 0.0041, LR: 0.0000100000
真实数据: 例使出“主题特卖”的
结果显示: 例使出“主题特卖”的
Epoch 0 Step 000500, model loss 1.9463, LR: 0.0000100000
真实数据: 世界上最早的地铁更早
结果显示: 世界上量早的地铁更早
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0438, LR: 0.0000100000
真实数据: 要不断的更新自己的知
结果显示: 要不断的更新自己的知
Epoch 0 Step 000700, model loss 0.0037, LR: 0.0000100000
真实数据: 个问题对考生来说不要
结果显示: 个问题对考生来说不要
Epoch 0 Step 000800, model loss 0.0131, LR: 0.0000100000
真实数据: 当我们从17亿美元的
结果显示: 当我们从17亿美元的
Epoch 0 Step 000900, model loss 4.9297, LR: 0.0000100000
真实数据: ”了老实忠厚的华国锋
结果显示: ”了老实忠的华国锋
Epoch 0 Step 001000, model loss 2.8975, LR: 0.0000100000
真实数据: 作C.南北对话D.东
结果显示: 作C.旁北对话D.东
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0034, LR: 0.0000100000
真实数据: 手。3但是球却紧紧贴
结果显示: 手。3但是球却紧紧贴
Epoch 0 Step 001200, model loss 0.0687, LR: 0.0000100000
真实数据: 跳槽的人除了职业成就
结果显示: 跳槽的人除了职业成就
Epoch 0 Step 001300, model loss 0.0100, LR: 0.0000100000
真实数据: 政府的真正目的在于建
结果显示: 政府的真正目的在于建
Epoch 0 Step 001400, model loss 0.2429, LR: 0.0000100000
真实数据: 这个年轻人所凭借的是
结果显示: 这个年轻人所凭借的是
Epoch 0 Step 001500, model loss 0.1392, LR: 0.0000100000
真实数据: 的费用是0.45-0
结果显示: 的费用是0.45-0
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.5453, LR: 0.0000100000
真实数据: 心:“今年年初二碰到
结果显示: 心:“今年年初二碰到
Epoch 0 Step 001700, model loss 0.0179, LR: 0.0000100000
真实数据: 之;但球队正在用人之
结果显示: 之;但球队正在用人之
Epoch 0 Step 001800, model loss 0.0166, LR: 0.0000100000
真实数据: 项交易在物权法上的效
结果显示: 项交易在物权法上的效
Epoch 0 Step 001900, model loss 0.0113, LR: 0.0000100000
真实数据: 年戏楼两边曾有这样的
结果显示: 年戏楼两边曾有这样的
Epoch 0 Step 002000, model loss 0.0393, LR: 0.0000100000
真实数据: 万华HXP1，有主人
结果显示: 万华HXP1，有主人
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 10.4707, LR: 0.0000100000
真实数据: 荣耀开始围绕在她身边
结果显示: 荣意开始圈绕在她身边
Epoch 0 Step 002200, model loss 0.0755, LR: 0.0000100000
真实数据: 格局可能出现的变化”
结果显示: 格局可能出现的变化”
Epoch 0 Step 002300, model loss 0.3442, LR: 0.0000100000
真实数据: 司目前都需要有技术背
结果显示: 司目前都需要有技术背
Epoch 0 Step 002400, model loss 0.0044, LR: 0.0000100000
真实数据: 种金钱观离我们是远了
结果显示: 种金钱观离我们是远了
Epoch 0 Step 002500, model loss 14.6489, LR: 0.0000100000
真实数据: 动:如今我深圳新曙光
结果显示: 动:如今我深圳新觅无
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.3257, LR: 0.0000100000
真实数据: 其中9辆装备康斯伯格
结果显示: 其中9辆装备康斯伯格
Epoch 0 Step 002700, model loss 0.0142, LR: 0.0000100000
真实数据: 纯属越位。沪B成交量
结果显示: 纯属越位。沪B成交量
Epoch 0 Step 002800, model loss 12.2219, LR: 0.0000100000
真实数据: 山她弓下身来一只一只
结果显示: 山她二下身来一只一只
Epoch 0 Step 002900, model loss 2.0791, LR: 0.0000100000
真实数据: 场的反馈能对研发进行
结果显示: 场的反愤能对研发进行
Epoch 0 Step 003000, model loss 0.0271, LR: 0.0000100000
真实数据: 律并没有对妇女人工受
结果显示: 律并没有对妇女人工受
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0106, LR: 0.0000100000
真实数据: 本轮近乎半数的比赛中
结果显示: 本轮近乎半数的比赛中
Epoch 0 Step 003200, model loss 0.0216, LR: 0.0000100000
真实数据: 获得相对宽松的竞争环
结果显示: 获得相对宽松的竞争环
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021BE89A8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 2.0401, LR: 0.0000100000
真实数据: 是符合标准的一又四分
结果显示: 是符合探准的一又四分
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 2.3424, LR: 0.0000100000
真实数据: 道士在内焉。已连续1
结果显示: 道士在内遐。已连续1
Epoch 0 Step 000200, model loss 0.0418, LR: 0.0000100000
真实数据: 大学的罗伯特・明钦介
结果显示: 大学的罗伯特・明钦介
Epoch 0 Step 000300, model loss 0.0047, LR: 0.0000100000
真实数据: 本就不说实话不谈实情
结果显示: 本就不说实话不谈实情
Epoch 0 Step 000400, model loss 7.6559, LR: 0.0000100000
真实数据: 轮他们4-0横扫网队
结果显示: 轮他们4-横柱队
Epoch 0 Step 000500, model loss 0.0566, LR: 0.0000100000
真实数据: 民应开启微软自动更新
结果显示: 民应开启微软自动更新
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0657, LR: 0.0000100000
真实数据: 中小学校长治校绩效总
结果显示: 中小学校长治校绩效总
Epoch 0 Step 000700, model loss 4.6533, LR: 0.0000100000
真实数据: 产品内涵的进一步提炼
结果显示: 产品内酒的进一步提炼
Epoch 0 Step 000800, model loss 4.8987, LR: 0.0000100000
真实数据: 此ST江纸已经计提了
结果显示: 此sT江织已经计提了
Epoch 0 Step 000900, model loss 0.1979, LR: 0.0000100000
真实数据: 队而走。更为巧合的是
结果显示: 队而走。更为巧合的是
Epoch 0 Step 001000, model loss 0.6099, LR: 0.0000100000
真实数据: 其旧部追随而去。翁自
结果显示: 其旧部追随而去。翁自
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 12.3482, LR: 0.0000100000
真实数据: 十分恭顺的。对于涮的
结果显示: 十分谁顺的。对于常的
Epoch 0 Step 001200, model loss 17.9182, LR: 0.0000100000
真实数据: 考验新科世界亚军陈耀
结果显示: 考验紧科世界亚军骑远
Epoch 0 Step 001300, model loss 13.8448, LR: 0.0000100000
真实数据: 纤食物的黑木耳、菠菜
结果显示: 纤食物的黑木耳、鼓某
Epoch 0 Step 001400, model loss 1.9670, LR: 0.0000100000
真实数据: 伊拉克临时政府邀请下
结果显示: 伊拉克临时政府邀请下
Epoch 0 Step 001500, model loss 0.0028, LR: 0.0000100000
真实数据: 决的股东所持表决权的
结果显示: 决的股东所持表决权的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.2438, LR: 0.0000100000
真实数据: 这样的爱是太隆重了，
结果显示: 这样的爱是太隆重了，
Epoch 0 Step 001700, model loss 0.5129, LR: 0.0000100000
真实数据: 争和防止大规模破坏性
结果显示: 争和防止大规模破坏性
Epoch 0 Step 001800, model loss 0.2067, LR: 0.0000100000
真实数据: 由美国自身文化霸权所
结果显示: 由美国自身文化霸权所
Epoch 0 Step 001900, model loss 0.9824, LR: 0.0000100000
真实数据: 牙膏都使用了大概一个
结果显示: 牙膏都使用了大概一个
Epoch 0 Step 002000, model loss 0.0021, LR: 0.0000100000
真实数据: 综合国力的不断提高和
结果显示: 综合国力的不断提高和
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 10.4244, LR: 0.0000100000
真实数据: 是蟾极易引发细菌性食
结果显示: 是锉极易引发细菌性食
Epoch 0 Step 002200, model loss 3.9519, LR: 0.0000100000
真实数据: 改装训练中为自己确立
结果显示: 使装训媒中为自己确立
Epoch 0 Step 002300, model loss 0.7232, LR: 0.0000100000
真实数据: 记住了美丽的可克达拉
结果显示: 记住了美丽的可克达拉
Epoch 0 Step 002400, model loss 5.8180, LR: 0.0000100000
真实数据: “市场容量是相对固定
结果显示: “市场容量是椎对定
Epoch 0 Step 002500, model loss 0.3836, LR: 0.0000100000
真实数据: 事会换届选举的议案》
结果显示: 事会换届选举的议案》
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0276, LR: 0.0000100000
真实数据: 梦表现了你强烈的好奇
结果显示: 梦表现了你强烈的好奇
Epoch 0 Step 002700, model loss 10.4691, LR: 0.0000100000
真实数据: 漏洞是两年半之前发现
结果显示: 调洞是两年半之前发现
Epoch 0 Step 002800, model loss 0.6700, LR: 0.0000100000
真实数据: 考虑患者是否能耐受化
结果显示: 考虑患者是否能耐受化
Epoch 0 Step 002900, model loss 5.5240, LR: 0.0000100000
真实数据: 发现汽油桶漂向了对岸
结果显示: 发现汽油幅涨向了对岸
Epoch 0 Step 003000, model loss 14.8057, LR: 0.0000100000
真实数据: 成肺阳虚损而致咽喉炎
结果显示: 成胁阳虚损而致唱联吏
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0282, LR: 0.0000100000
真实数据: 昨日同时公布定向增发
结果显示: 昨日同时公布定向增发
Epoch 0 Step 003200, model loss 0.0426, LR: 0.0000100000
真实数据: 并在后来又多次提出申
结果显示: 并在后来又多次提出申
Epoch 0 Step 003300, model loss 5.8711, LR: 0.0000100000
真实数据: 见媪，就由我们部发O
结果显示: 见媪，就由我们部发0
Epoch 0 Step 003400, model loss 0.0042, LR: 0.0000100000
真实数据: 但是如果把它集中起来
结果显示: 但是如果把它集中起来
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001F3689D8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0026, LR: 0.0000100000
真实数据: 小林说的不是没有道理
结果显示: 小林说的不是没有道理
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0503, LR: 0.0000100000
真实数据: 以说今年我们为了更好
结果显示: 以说今年我们为了更好
Epoch 0 Step 000200, model loss 5.5644, LR: 0.0000100000
真实数据: 抬头看云，窥一斑可见
结果显示: 拍头看云，窥一斑可见
Epoch 0 Step 000300, model loss 0.0687, LR: 0.0000100000
真实数据: 一张无形的连结所有电
结果显示: 一张无形的连结所有电
Epoch 0 Step 000400, model loss 0.0065, LR: 0.0000100000
真实数据: 仍坚持马克思列宁主义
结果显示: 仍坚持马克思列宁主义
Epoch 0 Step 000500, model loss 0.0069, LR: 0.0000100000
真实数据: 实，授权委托代理人持
结果显示: 实，授权委托代理人持
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0248, LR: 0.0000100000
真实数据: 兴岛是西南中沙群岛的
结果显示: 兴岛是西南中沙群岛的
Epoch 0 Step 000700, model loss 2.5144, LR: 0.0000100000
真实数据: 有研究显示，但遗憾的
结果显示: 有研究显示，但遗憾的
Epoch 0 Step 000800, model loss 0.0005, LR: 0.0000100000
真实数据: 充分展现管理者的个性
结果显示: 充分展现管理者的个性
Epoch 0 Step 000900, model loss 33.4952, LR: 0.0000100000
真实数据: 平岛主要由珊瑚礁组成
结果显示: 平岛主要由碘骧疆组成
Epoch 0 Step 001000, model loss 0.3210, LR: 0.0000100000
真实数据: 面子，完全相反的一种
结果显示: 面子，完全相反的一种
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0018, LR: 0.0000100000
真实数据: 全有可能向这个方向努
结果显示: 全有可能向这个方向努
Epoch 0 Step 001200, model loss 0.3752, LR: 0.0000100000
真实数据: 围内较上年增长了33
结果显示: 围内较上年增长了33
Epoch 0 Step 001300, model loss 3.5417, LR: 0.0000100000
真实数据: 063菲尼克斯太阳主
结果显示: 063恭尼克斯太阳主
Epoch 0 Step 001400, model loss 0.0434, LR: 0.0000100000
真实数据: 督促企业按法规和标准
结果显示: 督促企业按法规和标准
Epoch 0 Step 001500, model loss 22.8044, LR: 0.0000100000
真实数据: 月工资500元，颇觉
结果显示: 月工论500元，说实
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0040, LR: 0.0000100000
真实数据: 2000年数量还较多
结果显示: 2000年数量还较多
Epoch 0 Step 001700, model loss 6.2074, LR: 0.0000100000
真实数据: -苯二胺是一种已知的
结果显示: -莱二脑是一种已知的
Epoch 0 Step 001800, model loss 0.0749, LR: 0.0000100000
真实数据: 划总数的58.63%
结果显示: 划总数的58.63%
Epoch 0 Step 001900, model loss 0.1565, LR: 0.0000100000
真实数据: 8%的购买率基本持平
结果显示: 8%的购买率基本持平
Epoch 0 Step 002000, model loss 11.1610, LR: 0.0000100000
真实数据: 虾、牛、猪、鸡肉各放
结果显示: 怀、牛、猪、鸡肉各放
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0353, LR: 0.0000100000
真实数据: 常德市拥有大小景点2
结果显示: 常德市拥有大小景点2
Epoch 0 Step 002200, model loss 0.0094, LR: 0.0000100000
真实数据: 伊战争结束后，核心提
结果显示: 伊战争结束后，核心提
Epoch 0 Step 002300, model loss 6.3022, LR: 0.0000100000
真实数据: PPLE2004年研
结果显示: ErLE2004年研
Epoch 0 Step 002400, model loss 7.9802, LR: 0.0000100000
真实数据: 一度郁闷成疾，卡龙-
结果显示: 一度青问成疾，卡龙-
Epoch 0 Step 002500, model loss 0.0454, LR: 0.0000100000
真实数据: 有军事用途的游戏对此
结果显示: 有军事用途的游戏对此
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1848, LR: 0.0000100000
真实数据: 分的人都希望星期六去
结果显示: 分的人都希望星期六去
Epoch 0 Step 002700, model loss 0.0096, LR: 0.0000100000
真实数据: 招生工作正常顺利进行
结果显示: 招生工作正常顺利进行
Epoch 0 Step 002800, model loss 0.9513, LR: 0.0000100000
真实数据: 06年EPS达到0.
结果显示: 06年EPS达到0.
Epoch 0 Step 002900, model loss 9.5543, LR: 0.0000100000
真实数据: 女曰:丰台的七里庄等
结果显示: 女日:丰台的七重庄等
Epoch 0 Step 003000, model loss 5.1023, LR: 0.0000100000
真实数据: 己问过其它高校的同学
结果显示: 己问过其它高校的问学
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0805, LR: 0.0000100000
真实数据: 歌曲前通过免费网站上
结果显示: 歌曲前通过免费网站上
Epoch 0 Step 003200, model loss 0.0177, LR: 0.0000100000
真实数据: 戒见了笑道:业内人士
结果显示: 戒见了笑道:业内人士
Epoch 0 Step 003300, model loss 0.0617, LR: 0.0000100000
真实数据: “sanction”
结果显示: “sanction”
Epoch 0 Step 003400, model loss 0.8372, LR: 0.0000100000
真实数据: 品生产经营单位必须严
结果显示: 晶生产经营单位必须严
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000025E5D357258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 5.0714, LR: 0.0000100000
真实数据: 饶命!”老龙道:家里
结果显示: 饼命!”老龙道:家里
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1209, LR: 0.0000100000
真实数据: 女生吃避孕药简单的意
结果显示: 女生吃避孕药简单的意
Epoch 0 Step 000200, model loss 2.7513, LR: 0.0000100000
真实数据: 到时候控制不住，不信
结果显示: 到时候控制不佳，不信
Epoch 0 Step 000300, model loss 0.0026, LR: 0.0000100000
真实数据: 和运动场，是历史的选
结果显示: 和运动场，是历史的选
Epoch 0 Step 000400, model loss 9.8556, LR: 0.0000100000
真实数据: 蠢（16）--把国家
结果显示: 器（16）-把国家
Epoch 0 Step 000500, model loss 0.0223, LR: 0.0000100000
真实数据: 位美女棋手好似排着队
结果显示: 位美女棋手好似排着队
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0031, LR: 0.0000100000
真实数据: 我自己都觉得很累很累
结果显示: 我自己都觉得很累很累
Epoch 0 Step 000700, model loss 1.0231, LR: 0.0000100000
真实数据: 和辨别真假招聘的意识
结果显示: 和辨别真假招聘的意识
Epoch 0 Step 000800, model loss 0.0051, LR: 0.0000100000
真实数据: 一比较，苏联就不一定
结果显示: 一比较，苏联就不一定
Epoch 0 Step 000900, model loss 6.5907, LR: 0.0000100000
真实数据: 呜泣。*defend
结果显示: 鸣遍。*defend
Epoch 0 Step 001000, model loss 0.1309, LR: 0.0000100000
真实数据: 批改编的宪兵身穿迷彩
结果显示: 批改编的宪兵身穿迷彩
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0270, LR: 0.0000100000
真实数据: 19年12月他在《新
结果显示: 19年12月他在《新
Epoch 0 Step 001200, model loss 0.3275, LR: 0.0000100000
真实数据: 国军费投向“很神秘”
结果显示: 国军费投向“很神秘”
Epoch 0 Step 001300, model loss 1.5536, LR: 0.0000100000
真实数据: 00元，安托法加斯塔
结果显示: 00元，安托法加期塔
Epoch 0 Step 001400, model loss 0.1662, LR: 0.0000100000
真实数据: 是成为亚洲最主要的L
结果显示: 是成为亚洲最主要的L
Epoch 0 Step 001500, model loss 8.4210, LR: 0.0000100000
真实数据: 5曾任安徽省委书记的
结果显示: 5管任安需省委书记的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.8048, LR: 0.0000100000
真实数据: 展出素描、版画、钱币
结果显示: 展出素描、版画、钱币
Epoch 0 Step 001700, model loss 0.0002, LR: 0.0000100000
真实数据: 加值的两大根本性转变
结果显示: 加值的两大根本性转变
Epoch 0 Step 001800, model loss 0.0670, LR: 0.0000100000
真实数据: 落，但关键还在于身体
结果显示: 落，但关键还在于身体
Epoch 0 Step 001900, model loss 0.1912, LR: 0.0000100000
真实数据: 68%的人属于“不投
结果显示: 68%的人属于“不投
Epoch 0 Step 002000, model loss 0.0490, LR: 0.0000100000
真实数据: 20%的增幅确实惊人
结果显示: 20%的增幅确实惊人
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.4719, LR: 0.0000100000
真实数据: 为了卖弄自己的枪法，
结果显示: 为了卖弄自己的枪法，
Epoch 0 Step 002200, model loss 0.0042, LR: 0.0000100000
真实数据: ”，而爱情却让他们深
结果显示: ”，而爱情却让他们深
Epoch 0 Step 002300, model loss 0.0317, LR: 0.0000100000
真实数据: 的事情是，尤其在经期
结果显示: 的事情是，尤其在经期
Epoch 0 Step 002400, model loss 0.0584, LR: 0.0000100000
真实数据: 我看今天是不是就结束
结果显示: 我看今天是不是就结束
Epoch 0 Step 002500, model loss 0.0032, LR: 0.0000100000
真实数据: 品市场违法生产、经营
结果显示: 品市场违法生产、经营
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0008, LR: 0.0000100000
真实数据: 之后再没有对大盘的分
结果显示: 之后再没有对大盘的分
Epoch 0 Step 002700, model loss 0.0014, LR: 0.0000100000
真实数据: 我们美国的股东自己做
结果显示: 我们美国的股东自己做
Epoch 0 Step 002800, model loss 0.0045, LR: 0.0000100000
真实数据: ][3][4][5]
结果显示: ][3][4][5]
Epoch 0 Step 002900, model loss 0.0064, LR: 0.0000100000
真实数据: 流动的街景。你是那9
结果显示: 流动的街景。你是那9
Epoch 0 Step 003000, model loss 0.0017, LR: 0.0000100000
真实数据: 等过耳洞彻底长好了再
结果显示: 等过耳洞彻底长好了再
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0045, LR: 0.0000100000
真实数据: 但凡职场获得成功的人
结果显示: 但凡职场获得成功的人
Epoch 0 Step 003200, model loss 6.6863, LR: 0.0000100000
真实数据: 成熟淑静如刘嘉玲等才
结果显示: 成熟献静如刘嘉糙等才
Epoch 0 Step 003300, model loss 0.0692, LR: 0.0000100000
真实数据: 运动时心率达到100
结果显示: 运动时心率达到100
Epoch 0 Step 003400, model loss 15.2382, LR: 0.0000100000
真实数据: 太阳能板块再度卷土重
结果显示: 太能没块再度恢土重
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000012114B99258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 5.3500, LR: 0.0000100000
真实数据: 无暇彰表，兜售假古董
结果显示: 无暇朝表，呢售假古董
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0010, LR: 0.0000100000
真实数据: 果你通过努力很难在本
结果显示: 果你通过努力很难在本
Epoch 0 Step 000200, model loss 1.8012, LR: 0.0000100000
真实数据: e("sports0
结果显示: e("sports0
Epoch 0 Step 000300, model loss 0.4790, LR: 0.0000100000
真实数据: 来。庆祝是当之无愧的
结果显示: 来。庆祝是当之无愧的
Epoch 0 Step 000400, model loss 0.0997, LR: 0.0000100000
真实数据: 叫奖贷勤助补免五位一
结果显示: 叫奖贷勤助补免五位一
Epoch 0 Step 000500, model loss 24.0673, LR: 0.0000100000
真实数据: 俪犹虚。甚至可以说是
结果显示: 条犹虚。愿呈可以说是
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 8.6013, LR: 0.0000100000
真实数据: 小说格非整整磨砺了1
结果显示: 小说格非整整磨弱了1
Epoch 0 Step 000700, model loss 0.0131, LR: 0.0000100000
真实数据: 师父说得有理。协调国
结果显示: 师父说得有理。协调国
Epoch 0 Step 000800, model loss 1.4428, LR: 0.0000100000
真实数据: 天津至香港;一个归属
结果显示: 天津至香港:一个归属
Epoch 0 Step 000900, model loss 0.0071, LR: 0.0000100000
真实数据: 说的十句话中，可女儿
结果显示: 说的十句话中，可女儿
Epoch 0 Step 001000, model loss 6.8127, LR: 0.0000100000
真实数据: 森寒如浇冰水，工资薪
结果显示: 森寒如洗冰水，工资薪
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1689, LR: 0.0000100000
真实数据: 木工，西部则是古大陆
结果显示: 木工，西部则是古大陆
Epoch 0 Step 001200, model loss 0.0810, LR: 0.0000100000
真实数据: 叟喜，连豆期货继续走
结果显示: 叟喜，连豆期货继续走
Epoch 0 Step 001300, model loss 2.1838, LR: 0.0000100000
真实数据: ，区域总经销模式在一
结果显示: ，区域总经销模式在一
Epoch 0 Step 001400, model loss 0.0948, LR: 0.0000100000
真实数据: 世事无常，对于投资客
结果显示: 世事无常，对于投资客
Epoch 0 Step 001500, model loss 0.1398, LR: 0.0000100000
真实数据: 惧，disaster
结果显示: 惧，disaster
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0013, LR: 0.0000100000
真实数据: 说起国际队的这场大胜
结果显示: 说起国际队的这场大胜
Epoch 0 Step 001700, model loss 1.3043, LR: 0.0000100000
真实数据: 将终结自己的皇后美梦
结果显示: 将终结自己的皇后美妙
Epoch 0 Step 001800, model loss 0.0008, LR: 0.0000100000
真实数据: 当发现病人营养跟不上
结果显示: 当发现病人营养跟不上
Epoch 0 Step 001900, model loss 0.0332, LR: 0.0000100000
真实数据: 阿根廷人首选的度假地
结果显示: 阿根廷人首选的度假地
Epoch 0 Step 002000, model loss 0.4407, LR: 0.0000100000
真实数据: 看清题干要求是选正确
结果显示: 看清题干要求是选正确
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 4.5076, LR: 0.0000100000
真实数据: 穿过磨刀门(Shar
结果显示: 穿边磨刀门(Shar
Epoch 0 Step 002200, model loss 0.0179, LR: 0.0000100000
真实数据: 尼大疑。一直看淡美元
结果显示: 尼大疑。一直看淡美元
Epoch 0 Step 002300, model loss 0.0247, LR: 0.0000100000
真实数据: 航电研制水平还相对比
结果显示: 航电研制水平还相对比
Epoch 0 Step 002400, model loss 0.0194, LR: 0.0000100000
真实数据: 都在追求的着最大的利
结果显示: 都在追求的着最大的利
Epoch 0 Step 002500, model loss 0.3087, LR: 0.0000100000
真实数据: 个人住房贷款是一种中
结果显示: 个人住房贷款是一种中
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0892, LR: 0.0000100000
真实数据: 障部研究青年就业的专
结果显示: 障部研究青年就业的专
Epoch 0 Step 002700, model loss 0.2950, LR: 0.0000100000
真实数据: 乳腺疾病诊治有丰富经
结果显示: 乳腺疾病诊治有丰富经
Epoch 0 Step 002800, model loss 0.6366, LR: 0.0000100000
真实数据: 承担了所有的经营风险
结果显示: 承担了所有的经营风险
Epoch 0 Step 002900, model loss 0.0436, LR: 0.0000100000
真实数据: 的关系。而许志永坦承
结果显示: 的关系。而许志永坦承
Epoch 0 Step 003000, model loss 0.0268, LR: 0.0000100000
真实数据: 让从小生活在南方的T
结果显示: 让从小生活在南方的T
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0020, LR: 0.0000100000
真实数据: 些长期固守在乡村当代
结果显示: 些长期固守在乡村当代
Epoch 0 Step 003200, model loss 0.0085, LR: 0.0000100000
真实数据: 是让学生为学校获取利
结果显示: 是让学生为学校获取利
Epoch 0 Step 003300, model loss 0.0716, LR: 0.0000100000
真实数据: 子缺少亲情的“滋养”
结果显示: 子缺少亲情的“滋养”
Epoch 0 Step 003400, model loss 0.0407, LR: 0.0000100000
真实数据: 沙，满足自身木浆原料
结果显示: 沙，满足自身木浆原料
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000021B4B258258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.1474, LR: 0.0000100000
真实数据: 狮，“参与意识”是很
结果显示: 狮，“参与意识”是很
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 2.9729, LR: 0.0000100000
真实数据: 使用空客的中型飞机作
结果显示: 使用空客的中型机作
Epoch 0 Step 000200, model loss 0.2383, LR: 0.0000100000
真实数据: 行员就可以援引第九十
结果显示: 行员就可以援引第九十
Epoch 0 Step 000300, model loss 0.0056, LR: 0.0000100000
真实数据: 五一对我们来说，主持
结果显示: 五一对我们来说，主持
Epoch 0 Step 000400, model loss 0.1559, LR: 0.0000100000
真实数据: 场上交锋就像打仗一样
结果显示: 场上交锋就像打仗一样
Epoch 0 Step 000500, model loss 7.9844, LR: 0.0000100000
真实数据: ”三藏道:抢军饷一事
结果显示: ”三戴道:抢军羚一事
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0198, LR: 0.0000100000
真实数据: 要把我赚来的钱用来支
结果显示: 要把我赚来的钱用来支
Epoch 0 Step 000700, model loss 0.0535, LR: 0.0000100000
真实数据: 者却没能找到全国牙防
结果显示: 者却没能找到全国牙防
Epoch 0 Step 000800, model loss 2.9848, LR: 0.0000100000
真实数据: 机自拍:画於1976
结果显示: 机自拍:画吟1976
Epoch 0 Step 000900, model loss 0.1522, LR: 0.0000100000
真实数据: 天津来的好友来到了“
结果显示: 天津来的好友来到了“
Epoch 0 Step 001000, model loss 0.0171, LR: 0.0000100000
真实数据: 要精力从经济领域转移
结果显示: 要精力从经济领域转移
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.3154, LR: 0.0000100000
真实数据: 乌玛尔今年2月外出打
结果显示: 乌玛尔今年2月外出打
Epoch 0 Step 001200, model loss 2.9209, LR: 0.0000100000
真实数据: 揭开“FISO”的面
结果显示: 揭开“FISo”的面
Epoch 0 Step 001300, model loss 0.0475, LR: 0.0000100000
真实数据: 生活还是比较舒坦的。
结果显示: 生活还是比较舒坦的。
Epoch 0 Step 001400, model loss 0.0047, LR: 0.0000100000
真实数据: 002年4月8日正式
结果显示: 002年4月8日正式
Epoch 0 Step 001500, model loss 7.0286, LR: 0.0000100000
真实数据: 这样的教育，与乾坤而
结果显示: 这样的教育，与轮坤而
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.3983, LR: 0.0000100000
真实数据: 告诉记者。他连买菜的
结果显示: 告诉记者。他连买菜的
Epoch 0 Step 001700, model loss 0.4846, LR: 0.0000100000
真实数据: 伸下拿云手去捉这唐僧
结果显示: 伸下拿云手去捉这唐僧
Epoch 0 Step 001800, model loss 0.3049, LR: 0.0000100000
真实数据: 心怀鬼胎，城市的生存
结果显示: 心怀鬼胎，城市的生存
Epoch 0 Step 001900, model loss 2.7983, LR: 0.0000100000
真实数据: 差别就是自信心的问题
结果显示: 篇别就是自信心的问题
Epoch 0 Step 002000, model loss 0.0113, LR: 0.0000100000
真实数据: 际在线消息:使我不得
结果显示: 际在线消息:使我不得
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.1759, LR: 0.0000100000
真实数据: 风景区的这份管理条例
结果显示: 风景区的这份管理条例
Epoch 0 Step 002200, model loss 0.0934, LR: 0.0000100000
真实数据: 移情往往是坚决而果断
结果显示: 移情往往是坚决而果断
Epoch 0 Step 002300, model loss 13.8078, LR: 0.0000100000
真实数据: 头的热情再度得到宣泄
结果显示: 买的热情再度得到宜很
Epoch 0 Step 002400, model loss 7.7472, LR: 0.0000100000
真实数据: 糯米、玉米面蒸成糕与
结果显示: 辐米、玉米面蒸成糕与
Epoch 0 Step 002500, model loss 0.0015, LR: 0.0000100000
真实数据: 价值媒体”的省级广电
结果显示: 价值媒体”的省级广电
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0054, LR: 0.0000100000
真实数据: 总结经验才能有收获，
结果显示: 总结经验才能有收获，
Epoch 0 Step 002700, model loss 1.8712, LR: 0.0000100000
真实数据: 死。为了汇总、筛选这
结果显示: 死。为了汇总、昧选这
Epoch 0 Step 002800, model loss 3.1540, LR: 0.0000100000
真实数据: 歌手、歌曲进行综合评
结果显示: 歌手、曲进行综合评
Epoch 0 Step 002900, model loss 5.4362, LR: 0.0000100000
真实数据: 充满活力，最后很可能
结果显示: 介满活力，最后很可能
Epoch 0 Step 003000, model loss 0.7286, LR: 0.0000100000
真实数据: 要生产的汽车及建筑玻
结果显示: 要生产的汽车及建筑玻
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0114, LR: 0.0000100000
真实数据: 0008)嘉实货币:
结果显示: 0008)嘉实货币:
Epoch 0 Step 003200, model loss 3.0626, LR: 0.0000100000
真实数据: 另外，“乱天下者，舌
结果显示: 另外，“乱天下者，百
Epoch 0 Step 003300, model loss 0.0023, LR: 0.0000100000
真实数据: 现在就可以周五晚上出
结果显示: 现在就可以周五晚上出
Epoch 0 Step 003400, model loss 6.4690, LR: 0.0000100000
真实数据: 在他在困厄逆境中的“
结果显示: 在他在困尼逆境中的“
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001A266827258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0400, LR: 0.0000100000
真实数据: 今10场比赛已有7场
结果显示: 今10场比赛已有7场
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0251, LR: 0.0000100000
真实数据: 有黏性。告之母。编辑
结果显示: 有黏性。告之母。编辑
Epoch 0 Step 000200, model loss 0.0038, LR: 0.0000100000
真实数据: 不是进水了?）14、
结果显示: 不是进水了?）14、
Epoch 0 Step 000300, model loss 0.0010, LR: 0.0000100000
真实数据: 市不知为什么比往常都
结果显示: 市不知为什么比往常都
Epoch 0 Step 000400, model loss 1.2235, LR: 0.0000100000
真实数据: 府的财政拨款通常是保
结果显示: 府的财政援款通常是保
Epoch 0 Step 000500, model loss 0.1047, LR: 0.0000100000
真实数据: 表达和倾诉，离席亡去
结果显示: 表达和倾诉，离席亡去
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 15.5498, LR: 0.0000100000
真实数据: 作组组成的博鳌亚洲论
结果显示: 作组组成的博整亚洲论
Epoch 0 Step 000700, model loss 8.8052, LR: 0.0000100000
真实数据: 霍:阿贾克疏远胜于堵
结果显示: 霍:阿货克箦远胜于堵
Epoch 0 Step 000800, model loss 1.3949, LR: 0.0000100000
真实数据: 接受本报专访时说“我
结果显示: 接矢本报专访时说“我
Epoch 0 Step 000900, model loss 0.0419, LR: 0.0000100000
真实数据: 西兰等国家的8000
结果显示: 西兰等国家的8000
Epoch 0 Step 001000, model loss 0.0205, LR: 0.0000100000
真实数据: 春鼎盛、充满理想的年
结果显示: 春鼎盛、充满理想的年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 1.5976, LR: 0.0000100000
真实数据: 历时17个月的原创维
结果显示: 历时17个月的原创维
Epoch 0 Step 001200, model loss 0.0555, LR: 0.0000100000
真实数据: 前往源深体育场进行了
结果显示: 前往源深体育场进行了
Epoch 0 Step 001300, model loss 0.0258, LR: 0.0000100000
真实数据: 一致推选黄学明先生为
结果显示: 一致推选黄学明先生为
Epoch 0 Step 001400, model loss 0.0213, LR: 0.0000100000
真实数据: 不知道事先采取措施保
结果显示: 不知道事先采取措施保
Epoch 0 Step 001500, model loss 3.2408, LR: 0.0000100000
真实数据: 因为作业总好像写不完
结果显示: 因为作业总妈像写不完
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0814, LR: 0.0000100000
真实数据: 附:不光是中国的商人
结果显示: 附:不光是中国的商人
Epoch 0 Step 001700, model loss 0.0239, LR: 0.0000100000
真实数据: 中挑选出拥有业绩增长
结果显示: 中挑选出拥有业绩增长
Epoch 0 Step 001800, model loss 3.6197, LR: 0.0000100000
真实数据: 68.5%的学生认为
结果显示: 65.5%的学生认为
Epoch 0 Step 001900, model loss 9.4806, LR: 0.0000100000
真实数据: 斯-琼斯VS昆廷-罗
结果显示: 期.琼斯VS尾廷-罗
Epoch 0 Step 002000, model loss 0.0070, LR: 0.0000100000
真实数据: 4690729或登录
结果显示: 4690729或登录
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0046, LR: 0.0000100000
真实数据: 炮兵营一部份，胜率%
结果显示: 炮兵营一部份，胜率%
Epoch 0 Step 002200, model loss 0.0157, LR: 0.0000100000
真实数据: 来西亚等国家在中国公
结果显示: 来西亚等国家在中国公
Epoch 0 Step 002300, model loss 0.5363, LR: 0.0000100000
真实数据: 需要时间:在录取现场
结果显示: 需要时间:在录取现场
Epoch 0 Step 002400, model loss 0.0321, LR: 0.0000100000
真实数据: 都受益。600个座位
结果显示: 都受益。600个座位
Epoch 0 Step 002500, model loss 0.0078, LR: 0.0000100000
真实数据: 动位置服务业务的发展
结果显示: 动位置服务业务的发展
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.5349, LR: 0.0000100000
真实数据: 从实验证明电荷守恒定
结果显示: 从实脸证明电荷守顿定
Epoch 0 Step 002700, model loss 8.3593, LR: 0.0000100000
真实数据: 将成为拙劣的和无效率
结果显示: 将成为描劣的和无炒率
Epoch 0 Step 002800, model loss 0.0293, LR: 0.0000100000
真实数据: 曼联的前景就划上了问
结果显示: 曼联的前景就划上了问
Epoch 0 Step 002900, model loss 0.0179, LR: 0.0000100000
真实数据: 尽管明显更具现代意味
结果显示: 尽管明显更具现代意味
Epoch 0 Step 003000, model loss 0.2477, LR: 0.0000100000
真实数据: 以低于市场的价格出口
结果显示: 以低于市场的价格出口
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0190, LR: 0.0000100000
真实数据: 那三个小王子对行者、
结果显示: 那三个小王子对行者、
Epoch 0 Step 003200, model loss 0.0194, LR: 0.0000100000
真实数据: ，也会在签约正规单位
结果显示: ，也会在签约正规单位
Epoch 0 Step 003300, model loss 12.7623, LR: 0.0000100000
真实数据: 休后在碉楼前的屋里开
结果显示: 休后在调楼前的屋里开
Epoch 0 Step 003400, model loss 0.1132, LR: 0.0000100000
真实数据: 情况就不同了。101
结果显示: 情况就不同了。101
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E2C6C87258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 17.3184, LR: 0.0000100000
真实数据: 娘李娜以1-6先丢一
结果显示: 投李以1-6先丢―
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 11.8369, LR: 0.0000100000
真实数据: 所有领域上，黄粱将熟
结果显示: 所有领域上，黄票将熟
Epoch 0 Step 000200, model loss 1.0222, LR: 0.0000100000
真实数据: 炒作新权证。天山深处
结果显示: 炒作新权证。天山深处
Epoch 0 Step 000300, model loss 0.0281, LR: 0.0000100000
真实数据: 后都有结论。如果让他
结果显示: 后都有结论。如果让他
Epoch 0 Step 000400, model loss 12.4683, LR: 0.0000100000
真实数据: 有时我们也撇开真假概
结果显示: 有时我们也撤开真假概
Epoch 0 Step 000500, model loss 2.4791, LR: 0.0000100000
真实数据: 候，由于这类的旅游需
结果显示: 侯，由于这类的旅游需
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0311, LR: 0.0000100000
真实数据: 也会采取类似的治疗手
结果显示: 也会采取类似的治疗手
Epoch 0 Step 000700, model loss 0.3639, LR: 0.0000100000
真实数据: 公司经营公园周边大部
结果显示: 公司经营公园周边大部
Epoch 0 Step 000800, model loss 0.1108, LR: 0.0000100000
真实数据: 微软公司的一名律师却
结果显示: 微软公司的一名律师却
Epoch 0 Step 000900, model loss 12.8300, LR: 0.0000100000
真实数据: 于天气的预测可谓独具
结果显示: 于天气的顶测可谓猛具
Epoch 0 Step 001000, model loss 0.0020, LR: 0.0000100000
真实数据: 对。我们的日子怎么过
结果显示: 对。我们的日子怎么过
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 3.2149, LR: 0.0000100000
真实数据: hthecreati
结果显示: hthecCreati
Epoch 0 Step 001200, model loss 0.1568, LR: 0.0000100000
真实数据: 网上的“大学毕业生薪
结果显示: 网上的“大学毕业生薪
Epoch 0 Step 001300, model loss 0.0397, LR: 0.0000100000
真实数据: 得太笼统而缺乏说服力
结果显示: 得太笼统而缺乏说服力
Epoch 0 Step 001400, model loss 4.0893, LR: 0.0000100000
真实数据: 枸杞酒资产注入外资看
结果显示: 构杞酒资产注入外资看
Epoch 0 Step 001500, model loss 0.0064, LR: 0.0000100000
真实数据: 就有了很明显的危机感
结果显示: 就有了很明显的危机感
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0494, LR: 0.0000100000
真实数据: 波率领林丹、张宁、高
结果显示: 波率领林丹、张宁、高
Epoch 0 Step 001700, model loss 0.0124, LR: 0.0000100000
真实数据: 引入了市场化的用人机
结果显示: 引入了市场化的用人机
Epoch 0 Step 001800, model loss 0.0466, LR: 0.0000100000
真实数据: 公子:“拍你妈个头!
结果显示: 公子:“拍你妈个头!
Epoch 0 Step 001900, model loss 0.4070, LR: 0.0000100000
真实数据: 等传染病在越南、泰国
结果显示: 等传染病在越南、泰国
Epoch 0 Step 002000, model loss 11.9289, LR: 0.0000100000
真实数据: 的那叫圣谕，只有12
结果显示: 的那叫圣赳，只有12
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0167, LR: 0.0000100000
真实数据: 演艺明星参与虚假违法
结果显示: 演艺明星参与虚假违法
Epoch 0 Step 002200, model loss 3.2697, LR: 0.0000100000
真实数据: 复相绸缪。”一位一线
结果显示: 复相绸得。”一位一线
Epoch 0 Step 002300, model loss 32.4627, LR: 0.0000100000
真实数据: 一时间，“疾革难遽瘥
结果显示: 一时间，“疾革难晕
Epoch 0 Step 002400, model loss 2.6607, LR: 0.0000100000
真实数据: 来，“特拉克斯”装甲
结果显示: 来，“特拉克斯“装甲
Epoch 0 Step 002500, model loss 0.0159, LR: 0.0000100000
真实数据: 在自信心方面存在着一
结果显示: 在自信心方面存在着一
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0009, LR: 0.0000100000
真实数据: 面对压力，才做完的是
结果显示: 面对压力，才做完的是
Epoch 0 Step 002700, model loss 0.0264, LR: 0.0000100000
真实数据: 会计报表和合并会计报
结果显示: 会计报表和合并会计报
Epoch 0 Step 002800, model loss 0.0101, LR: 0.0000100000
真实数据: 作参考。用户无需另外
结果显示: 作参考。用户无需另外
Epoch 0 Step 002900, model loss 0.2004, LR: 0.0000100000
真实数据: 到第一个“生育指标”
结果显示: 到第一个“生育指标”
Epoch 0 Step 003000, model loss 12.8906, LR: 0.0000100000
真实数据: 我们还在使用。见俚典
结果显示: 我们还在使用。见便典
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0029, LR: 0.0000100000
真实数据: 呢，只宜向床头对婆子
结果显示: 呢，只宜向床头对婆子
Epoch 0 Step 003200, model loss 1.2335, LR: 0.0000100000
真实数据: 搞软件的人完全不用担
结果显示: 搞软件的人完全不用担
Epoch 0 Step 003300, model loss 0.7662, LR: 0.0000100000
真实数据: 然你的英语在同龄人里
结果显示: 然你的英语在同龄人里
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000017604277258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0018, LR: 0.0000100000
真实数据: 实验的方法学方面也存
结果显示: 实验的方法学方面也存
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0674, LR: 0.0000100000
真实数据: 我告诉你我宁愿要一套
结果显示: 我告诉你我宁愿要一套
Epoch 0 Step 000200, model loss 0.0013, LR: 0.0000100000
真实数据: 小争，陕飞集团就大胆
结果显示: 小争，陕飞集团就大胆
Epoch 0 Step 000300, model loss 0.0234, LR: 0.0000100000
真实数据: 南海舰队”，君志此门
结果显示: 南海舰队”，君志此门
Epoch 0 Step 000400, model loss 0.0603, LR: 0.0000100000
真实数据: 将会在一年半的时间内
结果显示: 将会在一年半的时间内
Epoch 0 Step 000500, model loss 2.8627, LR: 0.0000100000
真实数据: 茫海内，8.M:Oh
结果显示: 范海内，8.M:Oh
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0604, LR: 0.0000100000
真实数据: 我一听就动了心。20
结果显示: 我一听就动了心。20
Epoch 0 Step 000700, model loss 36.8523, LR: 0.0000100000
真实数据: 曹丕与甄洛夫妇留守邺
结果显示: 普丕与野洛夫妇留守郅
Epoch 0 Step 000800, model loss 0.0054, LR: 0.0000100000
真实数据: 是到以实战为目标的军
结果显示: 是到以实战为目标的军
Epoch 0 Step 000900, model loss 0.6251, LR: 0.0000100000
真实数据: 发挥不够稳定，在英国
结果显示: 发挥不够稳定，在英国
Epoch 0 Step 001000, model loss 2.1276, LR: 0.0000100000
真实数据: 航线:公司拟分拆控股
结果显示: 航线:公司拟分抓控股
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 9.8555, LR: 0.0000100000
真实数据: 但是结果却.....
结果显示: 但是结果却..
Epoch 0 Step 001200, model loss 0.0060, LR: 0.0000100000
真实数据: 人早上10点多才会来
结果显示: 人早上10点多才会来
Epoch 0 Step 001300, model loss 0.7671, LR: 0.0000100000
真实数据: 式也并不复杂。比国债
结果显示: 式也并不复杂。比国债
Epoch 0 Step 001400, model loss 0.2916, LR: 0.0000100000
真实数据: 央社”报道，俱乐部官
结果显示: 央社”报道，俱乐部官
Epoch 0 Step 001500, model loss 2.3381, LR: 0.0000100000
真实数据: 当面挡住道:妹曰夜儿
结果显示: 当面技住道:妹曰夜儿
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 3.7072, LR: 0.0000100000
真实数据: 就长生岂俗同?有金钱
结果显示: 就长生也俗同?有金钱
Epoch 0 Step 001700, model loss 0.3193, LR: 0.0000100000
真实数据: 架之后，必然要去看一
结果显示: 架之后，必然要去看一
Epoch 0 Step 001800, model loss 0.0106, LR: 0.0000100000
真实数据: 织方提供的数字显示共
结果显示: 织方提供的数字显示共
Epoch 0 Step 001900, model loss 0.0014, LR: 0.0000100000
真实数据: 依然在强势品种中占比
结果显示: 依然在强势品种中占比
Epoch 0 Step 002000, model loss 22.2519, LR: 0.0000100000
真实数据: 行联产责任制……当叶
结果显示: 行联产责任制....当叶
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0114, LR: 0.0000100000
真实数据: 考生的身体健康状况按
结果显示: 考生的身体健康状况按
Epoch 0 Step 002200, model loss 0.0049, LR: 0.0000100000
真实数据: 虑供求关系变化情况下
结果显示: 虑供求关系变化情况下
Epoch 0 Step 002300, model loss 0.0152, LR: 0.0000100000
真实数据: 务管理、国际经济与贸
结果显示: 务管理、国际经济与贸
Epoch 0 Step 002400, model loss 0.0921, LR: 0.0000100000
真实数据: 商务印书馆1995年
结果显示: 商务印书馆1995年
Epoch 0 Step 002500, model loss 1.1918, LR: 0.0000100000
真实数据: 华时报)”而诺基亚和
结果显示: 华时报)”而诺基亚和
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0938, LR: 0.0000100000
真实数据: 股票于1997年5月
结果显示: 股票于1997年5月
Epoch 0 Step 002700, model loss 0.6376, LR: 0.0000100000
真实数据: 核时间是4月25日―
结果显示: 核时间是4月25日―
Epoch 0 Step 002800, model loss 0.0536, LR: 0.0000100000
真实数据: 前不久，根据用户的不
结果显示: 前不久，根据用户的不
Epoch 0 Step 002900, model loss 0.2048, LR: 0.0000100000
真实数据: 独立最终被男性所利用
结果显示: 独立最终被男性所利用
Epoch 0 Step 003000, model loss 0.0269, LR: 0.0000100000
真实数据: 也不仅仅是拿来制冷用
结果显示: 也不仅仅是拿来制冷用
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0027, LR: 0.0000100000
真实数据: 均为80后出生的新人
结果显示: 均为80后出生的新人
Epoch 0 Step 003200, model loss 0.0907, LR: 0.0000100000
真实数据: !前几日看到演员王刚
结果显示: !前几日看到演员王刚
Epoch 0 Step 003300, model loss 0.0382, LR: 0.0000100000
真实数据: 因此大盘虽有技术性调
结果显示: 因此大盘虽有技术性调
Epoch 0 Step 003400, model loss 5.7296, LR: 0.0000100000
真实数据: 就榻研问之。它不追求
结果显示: 就韧研问之。它不询求
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000224BF4A9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.4421, LR: 0.0000100000
真实数据: 英文向“行政院长”苏
结果显示: 英文向“行政院长”苏
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0461, LR: 0.0000100000
真实数据: 机场均受到沙尘暴侵袭
结果显示: 机场均受到沙尘暴侵袭
Epoch 0 Step 000200, model loss 42.8040, LR: 0.0000100000
真实数据: 玉琮、玉璧、锥形器等
结果显示: 玉琼、玉壁、雅形器等
Epoch 0 Step 000300, model loss 0.1646, LR: 0.0000100000
真实数据: 企业将很难在市场上生
结果显示: 企业将很难在市场上生
Epoch 0 Step 000400, model loss 7.4519, LR: 0.0000100000
真实数据: 本站男子3米板比赛的
结果显示: 本觅男子3采板比赛的
Epoch 0 Step 000500, model loss 0.0151, LR: 0.0000100000
真实数据: 雅龙)全当是公司给我
结果显示: 雅龙)全当是公司给我
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0405, LR: 0.0000100000
真实数据: 变“养儿防老”的传统
结果显示: 变“养儿防老”的传统
Epoch 0 Step 000700, model loss 4.6936, LR: 0.0000100000
真实数据: ，从墨西哥管辖中脱离
结果显示: ，从墨西哥管辖中脱离
Epoch 0 Step 000800, model loss 6.1319, LR: 0.0000100000
真实数据: hecouldn't
结果显示: hecouldn’t
Epoch 0 Step 000900, model loss 0.0749, LR: 0.0000100000
真实数据: 《龙战士传说》不能免
结果显示: 《龙战士传说》不能免
Epoch 0 Step 001000, model loss 0.0211, LR: 0.0000100000
真实数据: 社会发展的主要目标中
结果显示: 社会发展的主要目标中
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 1.0464, LR: 0.0000100000
真实数据: 中国大陆还在继续努力
结果显示: 中国大陆还在继续努力
Epoch 0 Step 001200, model loss 0.0153, LR: 0.0000100000
真实数据: 迟疑观望型，&#97
结果显示: 迟疑观望型，&#97
Epoch 0 Step 001300, model loss 0.0207, LR: 0.0000100000
真实数据: 就是西风压了东风”呢
结果显示: 就是西风压了东风”呢
Epoch 0 Step 001400, model loss 0.0225, LR: 0.0000100000
真实数据: 翰林学士的王安石居然
结果显示: 翰林学士的王安石居然
Epoch 0 Step 001500, model loss 0.0035, LR: 0.0000100000
真实数据: 帮他们辨别敌人的阵地
结果显示: 帮他们辨别敌人的阵地
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.2390, LR: 0.0000100000
真实数据: 浙江虽然这场输给了我
结果显示: 浙江虽然这场输给了我
Epoch 0 Step 001700, model loss 0.0041, LR: 0.0000100000
真实数据: 心理相信，随着国际原
结果显示: 心理相信，随着国际原
Epoch 0 Step 001800, model loss 0.0007, LR: 0.0000100000
真实数据: 只有聪明的人可以看出
结果显示: 只有聪明的人可以看出
Epoch 0 Step 001900, model loss 0.0193, LR: 0.0000100000
真实数据: 财务管理学（0067
结果显示: 财务管理学（0067
Epoch 0 Step 002000, model loss 0.0690, LR: 0.0000100000
真实数据: 对公司股权分置改革方
结果显示: 对公司股权分置改革方
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.1145, LR: 0.0000100000
真实数据: 既在佛会下，容光顿减
结果显示: 既在佛会下，容光顿减
Epoch 0 Step 002200, model loss 0.0075, LR: 0.0000100000
真实数据: 厅分为工作区和休息区
结果显示: 厅分为工作区和休息区
Epoch 0 Step 002300, model loss 1.0508, LR: 0.0000100000
真实数据: 看水还是水。”执手倾
结果显示: 看水还是水。”执手低
Epoch 0 Step 002400, model loss 5.0802, LR: 0.0000100000
真实数据: 某个功能上来判断一个
结果显示: 峡个功能上来判断一个
Epoch 0 Step 002500, model loss 0.4107, LR: 0.0000100000
真实数据: 活动由长郡中学牵头组
结果显示: 活动由长郡中学牵头组
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0111, LR: 0.0000100000
真实数据: ，国内资产的向上重估
结果显示: ，国内资产的向上重估
Epoch 0 Step 002700, model loss 0.0009, LR: 0.0000100000
真实数据: 规划案出台之后，直直
结果显示: 规划案出台之后，直直
Epoch 0 Step 002800, model loss 0.0462, LR: 0.0000100000
真实数据: apability）
结果显示: apability）
Epoch 0 Step 002900, model loss 1.5246, LR: 0.0000100000
真实数据: 盘的上涨不缺能量推动
结果显示: 金的上涨不缺能量推动
Epoch 0 Step 003000, model loss 0.0023, LR: 0.0000100000
真实数据: 这就是典型的穷人思维
结果显示: 这就是典型的穷人思维
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0068, LR: 0.0000100000
真实数据: 是通过另外一种考试叫
结果显示: 是通过另外一种考试叫
Epoch 0 Step 003200, model loss 2.3691, LR: 0.0000100000
真实数据: 益开始滑坡。则气息休
结果显示: 益开始滑坡。赠气息休
Epoch 0 Step 003300, model loss 0.0016, LR: 0.0000100000
真实数据: 发热则会破坏生物体的
结果显示: 发热则会破坏生物体的
Epoch 0 Step 003400, model loss 0.0043, LR: 0.0000100000
真实数据: 终专利是否有效须等法
结果显示: 终专利是否有效须等法
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000022E1FAB9258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.3450, LR: 0.0000100000
真实数据: 公元26年六月戊戌日
结果显示: 公元26年六月戌日
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 2.2623, LR: 0.0000100000
真实数据: 占军官训练时间的半数
结果显示: 占军官训除练时间的半数
Epoch 0 Step 000200, model loss 1.1679, LR: 0.0000100000
真实数据: 3月29日，三级教授
结果显示: 3月29日，三级教授
Epoch 0 Step 000300, model loss 0.0219, LR: 0.0000100000
真实数据: 是战斗力不一定非要靠
结果显示: 是战斗力不一定非要靠
Epoch 0 Step 000400, model loss 0.0629, LR: 0.0000100000
真实数据: 5%的大学生拥有笔记
结果显示: 5%的大学生拥有笔记
Epoch 0 Step 000500, model loss 0.2670, LR: 0.0000100000
真实数据: 0%的惊人年收入增幅
结果显示: 0%的惊人年收入增幅
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0059, LR: 0.0000100000
真实数据: 王先生买任何一件商品
结果显示: 王先生买任何一件商品
Epoch 0 Step 000700, model loss 2.0878, LR: 0.0000100000
真实数据: 药行政部门要建立行贿
结果显示: 药行政部门要建立行赎
Epoch 0 Step 000800, model loss 0.1047, LR: 0.0000100000
真实数据: 向。如鲁米那、阿米托
结果显示: 向。如鲁米那、阿米托
Epoch 0 Step 000900, model loss 0.0254, LR: 0.0000100000
真实数据: 目前股价存在一定低估
结果显示: 目前股价存在一定低估
Epoch 0 Step 001000, model loss 1.8420, LR: 0.0000100000
真实数据: 辨认，称将来中国等新
结果显示: 辨认，称将来中国等新
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0041, LR: 0.0000100000
真实数据: 可以清楚看到飞行甲板
结果显示: 可以清楚看到飞行甲板
Epoch 0 Step 001200, model loss 0.0022, LR: 0.0000100000
真实数据: 张波则打出133中，
结果显示: 张波则打出133中，
Epoch 0 Step 001300, model loss 1.7570, LR: 0.0000100000
真实数据: 掀起的基本建设投资热
结果显示: 掀起的基本建设投资热
Epoch 0 Step 001400, model loss 0.0026, LR: 0.0000100000
真实数据: ][4][5][6]
结果显示: ][4][5][6]
Epoch 0 Step 001500, model loss 0.0977, LR: 0.0000100000
真实数据: 元支付给提供自助设备
结果显示: 元支付给提供自助设备
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 2.4279, LR: 0.0000100000
真实数据: 先需要搞清楚我们是否
结果显示: 先需要扩清楚我们是否
Epoch 0 Step 001700, model loss 0.0178, LR: 0.0000100000
真实数据: 女友也感觉到空气中化
结果显示: 女友也感觉到空气中化
Epoch 0 Step 001800, model loss 0.0378, LR: 0.0000100000
真实数据: 易时双方可以平等论价
结果显示: 易时双方可以平等论价
Epoch 0 Step 001900, model loss 5.9049, LR: 0.0000100000
真实数据: 1.100第一部分,
结果显示: 1.100第一部分，
Epoch 0 Step 002000, model loss 31.6591, LR: 0.0000100000
真实数据: 的广袤沙漠上突兀挺拔
结果显示: 的广沙凝上突无是拔
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.0889, LR: 0.0000100000
真实数据: 腾讯所赶超;美赞臣表
结果显示: 腾讯所赶超;美赞臣表
Epoch 0 Step 002200, model loss 0.6270, LR: 0.0000100000
真实数据: 蒙古农业银行深圳市分
结果显示: 蒙古农业银行深圳市分
Epoch 0 Step 002300, model loss 0.0016, LR: 0.0000100000
真实数据: 数学、化学都比较感兴
结果显示: 数学、化学都比较感兴
Epoch 0 Step 002400, model loss 0.0276, LR: 0.0000100000
真实数据: 它将召回3000个处
结果显示: 它将召回3000个处
Epoch 0 Step 002500, model loss 0.8107, LR: 0.0000100000
真实数据: 国已有近4000家民
结果显示: 国已有近4000家民
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 2.7904, LR: 0.0000100000
真实数据: 事业上也很兢兢业业，
结果显示: 事业上也很兢誓业业，
Epoch 0 Step 002700, model loss 0.2939, LR: 0.0000100000
真实数据: 位看起来像鲁迅笔下的
结果显示: 位看起来像鲁迅笔下的
Epoch 0 Step 002800, model loss 3.4410, LR: 0.0000100000
真实数据: 究原汤原味。二是将民
结果显示: 究原汤原釜。二是将民
Epoch 0 Step 002900, model loss 0.7213, LR: 0.0000100000
真实数据: 工作是核事业持续健康
结果显示: 工作是核事业持续健康
Epoch 0 Step 003000, model loss 0.0137, LR: 0.0000100000
真实数据: 使国人牢固增强保护知
结果显示: 使国人牢固增强保护知
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.1513, LR: 0.0000100000
真实数据: 这个职位好像很普通啊
结果显示: 这个职位好像很普通啊
Epoch 0 Step 003200, model loss 0.0003, LR: 0.0000100000
真实数据: 让母亲宣太后归居宫中
结果显示: 让母亲宣太后归居宫中
Epoch 0 Step 003300, model loss 0.0098, LR: 0.0000100000
真实数据: 说湖北就发生过样的事
结果显示: 说湖北就发生过样的事
Epoch 0 Step 003400, model loss 0.2197, LR: 0.0000100000
真实数据: 如今哈马斯从体制外的
结果显示: 如今哈马斯从体制外的
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000181F30EC258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0750, LR: 0.0000100000
真实数据: :对于怪、力、乱、神
结果显示: :对于怪、力、乱、神
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0624, LR: 0.0000100000
真实数据: 仅让一球使得上盘过于
结果显示: 仅让一球使得上盘过于
Epoch 0 Step 000200, model loss 1.8083, LR: 0.0000100000
真实数据: 荧，但行程根据赛事安
结果显示: 焚，但行程根据赛事安
Epoch 0 Step 000300, model loss 2.0407, LR: 0.0000100000
真实数据: 有哺乳动物和两栖动物
结果显示: 有哺乳动物和两栖动物
Epoch 0 Step 000400, model loss 4.6554, LR: 0.0000100000
真实数据: 前之惑。“他总是说挣
结果显示: 前之惑。“他总是说唢
Epoch 0 Step 000500, model loss 0.0836, LR: 0.0000100000
真实数据: 三十而卒，总之一句话
结果显示: 三十而卒，总之一句话
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 1.3226, LR: 0.0000100000
真实数据: 中田英寿之后，每年农
结果显示: 中田英寿之后，每年农
Epoch 0 Step 000700, model loss 0.0902, LR: 0.0000100000
真实数据: 里，称为“澳门模式”
结果显示: 里，称为“澳门模式”
Epoch 0 Step 000800, model loss 0.5173, LR: 0.0000100000
真实数据: 边境冲突的边境冲突，
结果显示: 边境冲突的边境冲突，
Epoch 0 Step 000900, model loss 0.5263, LR: 0.0000100000
真实数据: 50今日体育快评（周
结果显示: 50今日体育快评（周
Epoch 0 Step 001000, model loss 0.2698, LR: 0.0000100000
真实数据: 加速向上突破形态,处
结果显示: 加速向上突破形态,处
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0083, LR: 0.0000100000
真实数据: 今年该社首次推出“自
结果显示: 今年该社首次推出“自
Epoch 0 Step 001200, model loss 0.1907, LR: 0.0000100000
真实数据: 假设创维回到家族管理
结果显示: 假设创维回到家族管理
Epoch 0 Step 001300, model loss 0.0124, LR: 0.0000100000
真实数据: 昂13投6中14分1
结果显示: 昂13投6中14分1
Epoch 0 Step 001400, model loss 0.0004, LR: 0.0000100000
真实数据: 会采用书面表决的方式
结果显示: 会采用书面表决的方式
Epoch 0 Step 001500, model loss 13.4471, LR: 0.0000100000
真实数据: 乞丐相，赛季刚刚结束
结果显示: 乞再相，赛季刚刚结束
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0005, LR: 0.0000100000
真实数据: 头一回看到那么多人民
结果显示: 头一回看到那么多人民
Epoch 0 Step 001700, model loss 1.9926, LR: 0.0000100000
真实数据: 酒邀张，早奔西方去也
结果显示: 酒逃张，早奔西方去也
Epoch 0 Step 001800, model loss 0.3570, LR: 0.0000100000
真实数据: 论产品设计还是市场推
结果显示: 论产品设计还是市场推
Epoch 0 Step 001900, model loss 0.0015, LR: 0.0000100000
真实数据: 的市场观察看，这不是
结果显示: 的市场观察看，这不是
Epoch 0 Step 002000, model loss 0.0024, LR: 0.0000100000
真实数据: 公司有的女同事和我年
结果显示: 公司有的女同事和我年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.1053, LR: 0.0000100000
真实数据: 格证书》、向阳生涯职
结果显示: 格证书》，向阳生涯职
Epoch 0 Step 002200, model loss 6.0512, LR: 0.0000100000
真实数据: 多业务光网络节点（O
结果显示: 多业务光网络节点（0
Epoch 0 Step 002300, model loss 0.8421, LR: 0.0000100000
真实数据: 景德镇市委、市政府的
结果显示: 景德镇市委、市政府的
Epoch 0 Step 002400, model loss 0.0136, LR: 0.0000100000
真实数据: 不打算说服谁，昔习闻
结果显示: 不打算说服谁，昔习闻
Epoch 0 Step 002500, model loss 0.0497, LR: 0.0000100000
真实数据: 先生基本上处于没人管
结果显示: 先生基本上处于没人管
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0146, LR: 0.0000100000
真实数据: 37号402室(邮编
结果显示: 37号402室(邮编
Epoch 0 Step 002700, model loss 0.0378, LR: 0.0000100000
真实数据: 高我国的临床营养的水
结果显示: 高我国的临床营养的水
Epoch 0 Step 002800, model loss 0.6826, LR: 0.0000100000
真实数据: 兄也。时以数骑杂其伍
结果显示: 兄也。时以数骑杂其伍
Epoch 0 Step 002900, model loss 0.0010, LR: 0.0000100000
真实数据: 走，学习特长对升学的
结果显示: 走，学习特长对升学的
Epoch 0 Step 003000, model loss 0.0014, LR: 0.0000100000
真实数据: 公压根儿就不提白天的
结果显示: 公压根儿就不提白天的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 5.4001, LR: 0.0000100000
真实数据: 与诸童戏，马负痛奔骇
结果显示: 与请重戏，马负痛奔散
Epoch 0 Step 003200, model loss 11.3330, LR: 0.0000100000
真实数据: 正意义上”的液晶屏取
结果显示: 正础义上”的液品虽取
Epoch 0 Step 003300, model loss 0.1121, LR: 0.0000100000
真实数据: 报驻朝鲜特派记者赵嘉
结果显示: 报驻朝鲜特派记者赵嘉
Epoch 0 Step 003400, model loss 15.9551, LR: 0.0000100000
真实数据: 因为赵飞燕姐妹的进宫
结果显示: 因为赵飞菠超妹的进宫
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000014F950D8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0008, LR: 0.0000100000
真实数据: 亦老谋壮事者流也。学
结果显示: 亦老谋壮事者流也。学
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 24.2981, LR: 0.0000100000
真实数据: b.“昔，听到这些话
结果显示: b》“楚，,或到这些话
Epoch 0 Step 000200, model loss 0.0748, LR: 0.0000100000
真实数据: 多。Tel:0231
结果显示: 多。Tel:0231
Epoch 0 Step 000300, model loss 0.2972, LR: 0.0000100000
真实数据: 量集成训练摆上突出位
结果显示: 量集成训练摆上突出位
Epoch 0 Step 000400, model loss 0.3225, LR: 0.0000100000
真实数据: 上证券”下的“网上基
结果显示: 上证券”下的“网上基
Epoch 0 Step 000500, model loss 18.8769, LR: 0.0000100000
真实数据: 曰:苻登又率军围攻安
结果显示: 曰:符登又率军围攻安
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 2.9580, LR: 0.0000100000
真实数据: 往哪儿跑!"韩德彩早
结果显示: 往哪儿跑!“韩德彩早
Epoch 0 Step 000700, model loss 3.3670, LR: 0.0000100000
真实数据: 最后警察一举将嫌犯截
结果显示: 最后警察一举将爆犯截
Epoch 0 Step 000800, model loss 16.9178, LR: 0.0000100000
真实数据: 建“南沙守备区”，粟
结果显示: 建“南沙宁钾区”，那
Epoch 0 Step 000900, model loss 0.6885, LR: 0.0000100000
真实数据: 不信，信息时报:预调
结果显示: 不信，信息时报:预调
Epoch 0 Step 001000, model loss 0.0517, LR: 0.0000100000
真实数据: 凭两块钱就招了一个没
结果显示: 凭两块钱就招了一个没
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 4.0702, LR: 0.0000100000
真实数据: 开始，处分原因是严重
结果显示: 开临，处分原因是严重
Epoch 0 Step 001200, model loss 3.0339, LR: 0.0000100000
真实数据: 所以，野径荒凉草更深
结果显示: 所以，野径荒浦草更深
Epoch 0 Step 001300, model loss 0.0054, LR: 0.0000100000
真实数据: 他无论如何不愿再加薪
结果显示: 他无论如何不愿再加薪
Epoch 0 Step 001400, model loss 19.1087, LR: 0.0000100000
真实数据: 以瓢覆灯，以质量取胜
结果显示: 以器覆灯，以质量取胜
Epoch 0 Step 001500, model loss 1.1516, LR: 0.0000100000
真实数据: 州市场仍会以小幅震荡
结果显示: 州市场仍会以小幅震荡
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 1.5182, LR: 0.0000100000
真实数据: 索尼在今年一月曾表示
结果显示: 索尼在今年一月曾表示
Epoch 0 Step 001700, model loss 0.3911, LR: 0.0000100000
真实数据: :现在AC米兰左右两
结果显示: :现在AC米兰左右两
Epoch 0 Step 001800, model loss 0.0984, LR: 0.0000100000
真实数据: 战机是由乌克兰运抵香
结果显示: 战机是由乌克兰运抵香
Epoch 0 Step 001900, model loss 0.0713, LR: 0.0000100000
真实数据: ，共索之。中国江苏网
结果显示: ，共索之。中国江苏网
Epoch 0 Step 002000, model loss 2.6371, LR: 0.0000100000
真实数据: 前两种是短程地地导弹
结果显示: 前两种是短税地地导弹
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.6410, LR: 0.0000100000
真实数据: 译员于洋这样告诉记者
结果显示: 译员于洋这样告诉记者
Epoch 0 Step 002200, model loss 1.1422, LR: 0.0000100000
真实数据: 能确保摧毁敌人的重要
结果显示: 能确保摧毁敌人的重要
Epoch 0 Step 002300, model loss 12.8938, LR: 0.0000100000
真实数据: 立化腐朽为神奇，法国
结果显示: 立化腐恋杆为神奇，法国
Epoch 0 Step 002400, model loss 0.0783, LR: 0.0000100000
真实数据: 在展台摆放的人体脑干
结果显示: 在展台摆放的人体脑干
Epoch 0 Step 002500, model loss 0.0202, LR: 0.0000100000
真实数据: 难向外国医院的医生解
结果显示: 难向外国医院的医生解
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0827, LR: 0.0000100000
真实数据: 敢出来为人民说句实话
结果显示: 敢出来为人民说句实话
Epoch 0 Step 002700, model loss 0.0021, LR: 0.0000100000
真实数据: 不足，“是什么山?”
结果显示: 不足，“是什么山?”
Epoch 0 Step 002800, model loss 1.4332, LR: 0.0000100000
真实数据: 占18.78%;咖啡
结果显示: 占18.78%;咖啡
Epoch 0 Step 002900, model loss 0.0033, LR: 0.0000100000
真实数据: ，”不要因为今天拿8
结果显示: ，”不要因为今天拿8
Epoch 0 Step 003000, model loss 0.1065, LR: 0.0000100000
真实数据: 能进一步识别出与糖尿
结果显示: 能进一步识别出与糖尿
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0597, LR: 0.0000100000
真实数据: 国防科工委授予他“突
结果显示: 国防科工委授予他“突
Epoch 0 Step 003200, model loss 5.6175, LR: 0.0000100000
真实数据: 人们的饮食高脂化倾向
结果显示: 人们的伙食高脂化倾向
Epoch 0 Step 003300, model loss 0.1319, LR: 0.0000100000
真实数据: 现就读于北大元培试验
结果显示: 现就读于北大元培试验
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001CB053C8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0744, LR: 0.0000100000
真实数据: 什么也没有，如今的武
结果显示: 什么也没有，如今的武
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0019, LR: 0.0000100000
真实数据: 也会影响吸收。他称自
结果显示: 也会影响吸收。他称自
Epoch 0 Step 000200, model loss 0.0222, LR: 0.0000100000
真实数据: 是寻找产品代理的广告
结果显示: 是寻找产品代理的广告
Epoch 0 Step 000300, model loss 1.5140, LR: 0.0000100000
真实数据: 有人操纵的太空计划由
结果显示: 有人操纵的太空计划由
Epoch 0 Step 000400, model loss 19.4378, LR: 0.0000100000
真实数据: 以很少回家。其中，w
结果显示: 以很少国家。契，群
Epoch 0 Step 000500, model loss 12.4059, LR: 0.0000100000
真实数据: .14惠质心悲只问禅
结果显示: .14惠质心悲只问祥
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.8386, LR: 0.0000100000
真实数据: 一屁股坐下来呆若木鸡
结果显示: 一屁股坐下来呆若木鸡
Epoch 0 Step 000700, model loss 2.2230, LR: 0.0000100000
真实数据: 省出点时间用在公务或
结果显示: 省出点时间用在公务或
Epoch 0 Step 000800, model loss 5.5440, LR: 0.0000100000
真实数据: 思路去探究紫光对预装
结果显示: 思路去探完紧光对预装
Epoch 0 Step 000900, model loss 0.0210, LR: 0.0000100000
真实数据: 文章还引用了解放军团
结果显示: 文章还引用了解放军团
Epoch 0 Step 001000, model loss 0.0093, LR: 0.0000100000
真实数据: 根据产品定位。”杜峰
结果显示: 根据产品定位。”杜峰
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0020, LR: 0.0000100000
真实数据: 的表现也已经证明这点
结果显示: 的表现也已经证明这点
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001ADBC708258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0374, LR: 0.0000100000
真实数据: 汉双解词典》里的名词
结果显示: 汉双解词典》里的名词
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0974, LR: 0.0000100000
真实数据: 质是发挥信息主导作用
结果显示: 质是发挥信息主导作用
Epoch 0 Step 000200, model loss 0.0131, LR: 0.0000100000
真实数据: 一般人都得放弃长远计
结果显示: 一般人都得放弃长远计
Epoch 0 Step 000300, model loss 9.1748, LR: 0.0000100000
真实数据: 骨髓。看着以前的同学
结果显示: 骨眉。看着以前的同学
Epoch 0 Step 000400, model loss 0.0127, LR: 0.0000100000
真实数据: 国政府和大陆人的不满
结果显示: 国政府和大陆人的不满
Epoch 0 Step 000500, model loss 0.0042, LR: 0.0000100000
真实数据: ☆弄清楚该题的句法关
结果显示: ☆弄清楚该题的句法关
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 5.3312, LR: 0.0000100000
真实数据: 他俩被湖南卫视邀请去
结果显示: 他偶被湖南卫视邀请去
Epoch 0 Step 000700, model loss 0.2614, LR: 0.0000100000
真实数据: 东尼正式遗弃了屋大维
结果显示: 东尼正式遗弃了屋大维
Epoch 0 Step 000800, model loss 0.4206, LR: 0.0000100000
真实数据: 不敢说的四个秘密这样
结果显示: 不敢说的四个秘密这样
Epoch 0 Step 000900, model loss 13.1553, LR: 0.0000100000
真实数据: 是位妇孺皆知的书画大
结果显示: 是位妇豫皆知的书画大
Epoch 0 Step 001000, model loss 0.0641, LR: 0.0000100000
真实数据: 美国人知道，少年时代
结果显示: 美国人知道，少年时代
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0822, LR: 0.0000100000
真实数据: 公也耶!”在中国“望
结果显示: 公也耶!”在中国“望
Epoch 0 Step 001200, model loss 0.0122, LR: 0.0000100000
真实数据: EAD等世界顶尖商学
结果显示: EAD等世界顶尖商学
Epoch 0 Step 001300, model loss 0.0018, LR: 0.0000100000
真实数据: 着在线游戏用户群的增
结果显示: 着在线游戏用户群的增
Epoch 0 Step 001400, model loss 10.5009, LR: 0.0000100000
真实数据: 被吴、越夺去了霸主地
结果显示: 被吴、趁令去了囊主地
Epoch 0 Step 001500, model loss 0.6890, LR: 0.0000100000
真实数据: uer更多的人要吃饭
结果显示: uer更多的人要吃饭
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0586, LR: 0.0000100000
真实数据: 泌疾病就需要终身随诊
结果显示: 泌疾病就需要终身随诊
Epoch 0 Step 001700, model loss 0.0417, LR: 0.0000100000
真实数据: 实他一直是在流浪――
结果显示: 实他一直是在流浪――
Epoch 0 Step 001800, model loss 0.4600, LR: 0.0000100000
真实数据: D2、早起观黄海日出
结果显示: D2、早起观黄海日出
Epoch 0 Step 001900, model loss 0.5865, LR: 0.0000100000
真实数据: 语(零起点)只招日语
结果显示: 语(零起点)只招日语
Epoch 0 Step 002000, model loss 18.8098, LR: 0.0000100000
真实数据: 序正当、市场残酷、法
结果显示: 削正当、市场风墀、法
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0138, LR: 0.0000100000
真实数据: 公司2005年度利润
结果显示: 公司2005年度利润
Epoch 0 Step 002200, model loss 2.7017, LR: 0.0000100000
真实数据: 同时，”那长老却才定
结果显示: 同时，”那长老久才定
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000015EC7DF7258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.3078, LR: 0.0000100000
真实数据: 面是球队队徽,有很多
结果显示: 面是球队队徽,有很多
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.3751, LR: 0.0000100000
真实数据: 因此具有坑口发电有优
结果显示: 因此具有坑口发屯有优
Epoch 0 Step 000200, model loss 0.3581, LR: 0.0000100000
真实数据: 令我感到惊奇的是，症
结果显示: 令我感到惊奇的是，症
Epoch 0 Step 000300, model loss 0.0008, LR: 0.0000100000
真实数据: 他交战。2004年起
结果显示: 他交战。2004年起
Epoch 0 Step 000400, model loss 0.0114, LR: 0.0000100000
真实数据: 度的人不会因为苏格拉
结果显示: 度的人不会因为苏格拉
Epoch 0 Step 000500, model loss 0.0104, LR: 0.0000100000
真实数据: 换“谢菲尔德”级42
结果显示: 换“谢菲尔德”级42
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0070, LR: 0.0000100000
真实数据: 他们不断向上发展，是
结果显示: 他们不断向上发展，是
Epoch 0 Step 000700, model loss 0.2743, LR: 0.0000100000
真实数据: 超过一万张珍贵照片回
结果显示: 超过一万张珍贵照片回
Epoch 0 Step 000800, model loss 0.0090, LR: 0.0000100000
真实数据: 是有。盘中前期热点显
结果显示: 是有。盘中前期热点显
Epoch 0 Step 000900, model loss 0.2433, LR: 0.0000100000
真实数据: 每天停涨的个股更是好
结果显示: 每天停涨的个股更是好
Epoch 0 Step 001000, model loss 7.2144, LR: 0.0000100000
真实数据: 度，新昌县风景旅游管
结果显示: 皮，新昌县足景旅游管
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.5265, LR: 0.0000100000
真实数据: 自己迅速老去的容颜和
结果显示: 自己迅速老去的容翘和
Epoch 0 Step 001200, model loss 0.3419, LR: 0.0000100000
真实数据: “那时我第一次谈恋爱
结果显示: “那时我第一次谈恋爱
Epoch 0 Step 001300, model loss 0.0983, LR: 0.0000100000
真实数据: 5岁时黄体期进一步延
结果显示: 5岁时黄体期进一步延
Epoch 0 Step 001400, model loss 0.0012, LR: 0.0000100000
真实数据: 比如说我们做这个业务
结果显示: 比如说我们做这个业务
Epoch 0 Step 001500, model loss 16.4252, LR: 0.0000100000
真实数据: 型鳞状上皮细胞（不能
结果显示: 型鲜状上皮细胞（不能
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0209, LR: 0.0000100000
真实数据: 克斯对媒体发表谈话说
结果显示: 克斯对媒体发表谈话说
Epoch 0 Step 001700, model loss 0.0035, LR: 0.0000100000
真实数据: 个股表现具有二类明显
结果显示: 个股表现具有二类明显
Epoch 0 Step 001800, model loss 0.9911, LR: 0.0000100000
真实数据: 以及日本扩大出口波及
结果显示: 以及日本扩大出口波及
Epoch 0 Step 001900, model loss 0.0922, LR: 0.0000100000
真实数据: 策学（0371）警察
结果显示: 策学（0371）警察
Epoch 0 Step 002000, model loss 0.3869, LR: 0.0000100000
真实数据: 基Aspire567
结果显示: 基Aspire567
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0480, LR: 0.0000100000
真实数据: 中国的增长模式就必须
结果显示: 中国的增长模式就必须
Epoch 0 Step 002200, model loss 0.4434, LR: 0.0000100000
真实数据: 国家地理来讲，结盟各
结果显示: 国家地理来讲，结盟各
Epoch 0 Step 002300, model loss 1.4503, LR: 0.0000100000
真实数据: 说里塑造的一些人物也
结果显示: 说里塑造的一些人物也
Epoch 0 Step 002400, model loss 1.3682, LR: 0.0000100000
真实数据: 行动其实就是一个人职
结果显示: 行动其实就是一个人职
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001BC32278258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0044, LR: 0.0000100000
真实数据: 照北京市规定，12这
结果显示: 照北京市规定，12这
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0013, LR: 0.0000100000
真实数据: 市将率先进入休闲时代
结果显示: 市将率先进入休闲时代
Epoch 0 Step 000200, model loss 0.0054, LR: 0.0000100000
真实数据: 并未对其引起足够的重
结果显示: 并未对其引起足够的重
Epoch 0 Step 000300, model loss 0.0122, LR: 0.0000100000
真实数据: 群操矢石乱击之，作者
结果显示: 群操矢石乱击之，作者
Epoch 0 Step 000400, model loss 7.1325, LR: 0.0000100000
真实数据: 巢癌、淋巴瘤、头颈部
结果显示: 扩癌、淋巴瘤、头颈部
Epoch 0 Step 000500, model loss 0.6378, LR: 0.0000100000
真实数据: 和曰:嘉宾:我总觉得
结果显示: 和曰:嘉宾:我总觉得
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0160, LR: 0.0000100000
真实数据: 分明的缺点危害比较大
结果显示: 分明的缺点危害比较大
Epoch 0 Step 000700, model loss 0.4843, LR: 0.0000100000
真实数据: 重失调，以每天1亿的
结果显示: 重失调，以每天1亿的
Epoch 0 Step 000800, model loss 0.1125, LR: 0.0000100000
真实数据: 透露，100多个国家
结果显示: 透露，100多个国家
Epoch 0 Step 000900, model loss 1.5273, LR: 0.0000100000
真实数据: 目前蓝狮队已经连续战
结果显示: 日前蓝狮队已经连续战
Epoch 0 Step 001000, model loss 0.0009, LR: 0.0000100000
真实数据: 请问是为什么?中方为
结果显示: 请问是为什么?中方为
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000188E2D68258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0072, LR: 0.0000100000
真实数据: 老子是干什么的?老子
结果显示: 老子是干什么的?老子
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.7661, LR: 0.0000100000
真实数据: 儿童的食物需要显示高
结果显示: 儿童的食物需要显示高
Epoch 0 Step 000200, model loss 0.0466, LR: 0.0000100000
真实数据: 尔的一家中国公司一位
结果显示: 尔的一家中国公司一位
Epoch 0 Step 000300, model loss 0.0091, LR: 0.0000100000
真实数据: 后来子孙没钱使用。再
结果显示: 后来子孙没钱使用。再
Epoch 0 Step 000400, model loss 0.0184, LR: 0.0000100000
真实数据: 让公司面试时对你一见
结果显示: 让公司面试时对你一见
Epoch 0 Step 000500, model loss 0.0004, LR: 0.0000100000
真实数据: 不少读者不约而同表达
结果显示: 不少读者不约而同表达
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0951, LR: 0.0000100000
真实数据: 不，该联盟成立于19
结果显示: 不，该联盟成立于19
Epoch 0 Step 000700, model loss 4.5574, LR: 0.0000100000
真实数据: (0931)8912
结果显示: 09318912
Epoch 0 Step 000800, model loss 0.0110, LR: 0.0000100000
真实数据: 中国的前景，明年打算
结果显示: 中国的前景，明年打算
Epoch 0 Step 000900, model loss 2.5206, LR: 0.0000100000
真实数据: 是那些敌对武装组织的
结果显示: 是那些敌对武装组织的
Epoch 0 Step 001000, model loss 0.0227, LR: 0.0000100000
真实数据: 台湾如能有自我防卫力
结果显示: 台湾如能有自我防卫力
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 1.2714, LR: 0.0000100000
真实数据: 以为吃药就可缓解疼痛
结果显示: 以为吃药就可缓解疼痛
Epoch 0 Step 001200, model loss 0.1871, LR: 0.0000100000
真实数据: 挤出的物质加上一滴甘
结果显示: 挤出的物质加上一滴甘
Epoch 0 Step 001300, model loss 13.7151, LR: 0.0000100000
真实数据: 海棠，白领丽人Ann
结果显示: 海，白领丽人Ann
Epoch 0 Step 001400, model loss 0.4837, LR: 0.0000100000
真实数据: 跌局面，而1988年
结果显示: 跌局面，而1988年
Epoch 0 Step 001500, model loss 0.2872, LR: 0.0000100000
真实数据: 三岁，顾未必即为此物
结果显示: 三岁，顾未必即为此物
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 1.6147, LR: 0.0000100000
真实数据: 编辑:要想形成正反馈
结果显示: 编辑:要想形成正反馈
Epoch 0 Step 001700, model loss 0.0046, LR: 0.0000100000
真实数据: 送给9个国家23只大
结果显示: 送给9个国家23只大
Epoch 0 Step 001800, model loss 0.8122, LR: 0.0000100000
真实数据: “不是我捐的”;同时
结果显示: “不是我捐的”;同时
Epoch 0 Step 001900, model loss 0.1442, LR: 0.0000100000
真实数据: 国国务卿赖斯刚刚访问
结果显示: 国国务卿赖斯刚刚访问
Epoch 0 Step 002000, model loss 0.0208, LR: 0.0000100000
真实数据: 广州分公司一直在强调
结果显示: 广州分公司一直在强调
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0031, LR: 0.0000100000
真实数据: 以请假，我很快就也呼
结果显示: 以请假，我很快就也呼
Epoch 0 Step 002200, model loss 0.0002, LR: 0.0000100000
真实数据: 岁以下的人易患过敏症
结果显示: 岁以下的人易患过敏症
Epoch 0 Step 002300, model loss 2.1192, LR: 0.0000100000
真实数据: 行清洁工作才能事半功
结果显示: 行清洁工作才能享半功
Epoch 0 Step 002400, model loss 0.2546, LR: 0.0000100000
真实数据: 根本是一种虚幻的假独
结果显示: 根本是一种虚幻的假独
Epoch 0 Step 002500, model loss 0.1149, LR: 0.0000100000
真实数据: 见的公交车?一类是“
结果显示: 见的公交车?一类是“
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.1661, LR: 0.0000100000
真实数据: 23并正式启用21分
结果显示: 23并正式启用21分
Epoch 0 Step 002700, model loss 0.0156, LR: 0.0000100000
真实数据: 户来说可谓最好的选择
结果显示: 户来说可谓最好的选择
Epoch 0 Step 002800, model loss 0.3144, LR: 0.0000100000
真实数据: 对某种德行的提倡和表
结果显示: 对某种德行的提倡和表
Epoch 0 Step 002900, model loss 0.0199, LR: 0.0000100000
真实数据: 足球一向怀有敬仰之情
结果显示: 足球一向怀有敬仰之情
Epoch 0 Step 003000, model loss 2.5054, LR: 0.0000100000
真实数据: 村安慧里一区14号楼
结果显示: 村安那里一区14号楼
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0105, LR: 0.0000100000
真实数据: 中对GDP增长的刺激
结果显示: 中对GDP增长的刺激
Epoch 0 Step 003200, model loss 0.2278, LR: 0.0000100000
真实数据: 10年不到，7-8温
结果显示: 10年不到，7-8温
Epoch 0 Step 003300, model loss 0.0013, LR: 0.0000100000
真实数据: 拽扶之，以该专业为基
结果显示: 拽扶之，以该专业为基
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000002A0A19A7258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.3258, LR: 0.0000100000
真实数据: 轮二十回，平卧后能缓
结果显示: 轮二十回，平卧后能缓
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0976, LR: 0.0000100000
真实数据: 愿意倾听呢?中国的社
结果显示: 愿意倾听呢?中国的社
Epoch 0 Step 000200, model loss 0.0378, LR: 0.0000100000
真实数据: 说到这个问题，弄走你
结果显示: 说到这个问题，弄走你
Epoch 0 Step 000300, model loss 0.0074, LR: 0.0000100000
真实数据: 补报志愿可选报3个志
结果显示: 补报志愿可选报3个志
Epoch 0 Step 000400, model loss 5.2813, LR: 0.0000100000
真实数据: ThomasMane
结果显示: ThomasMiane
Epoch 0 Step 000500, model loss 2.5507, LR: 0.0000100000
真实数据: 授都是老师;像今天的
结果显示: 柳都是老师;像今天的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0381, LR: 0.0000100000
真实数据: 不要把工作上的压力带
结果显示: 不要把工作上的压力带
Epoch 0 Step 000700, model loss 0.8290, LR: 0.0000100000
真实数据: 5亿元转为锦江电器的
结果显示: 5亿元转为锦江电器的
Epoch 0 Step 000800, model loss 1.6647, LR: 0.0000100000
真实数据: 供商如何确保911报
结果显示: 供商如何确保911
Epoch 0 Step 000900, model loss 0.0187, LR: 0.0000100000
真实数据: 朗和朝鲜知道，生活越
结果显示: 朗和朝鲜知道，生活越
Epoch 0 Step 001000, model loss 0.0536, LR: 0.0000100000
真实数据: 度不仅不能充分发挥知
结果显示: 度不仅不能充分发挥知
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 4.0957, LR: 0.0000100000
真实数据: 中埋怨唐僧，2.新高
结果显示: 中埋怨唐僧，2新高
Epoch 0 Step 001200, model loss 0.0237, LR: 0.0000100000
真实数据: 摄入与机体之间的平衡
结果显示: 摄入与机体之间的平衡
Epoch 0 Step 001300, model loss 1.5803, LR: 0.0000100000
真实数据: 理，女人“恶习”排行
结果显示: 理，女人“恶习”排行
Epoch 0 Step 001400, model loss 0.0733, LR: 0.0000100000
真实数据: 有着“泛科学”的习惯
结果显示: 有着“泛科学”的习惯
Epoch 0 Step 001500, model loss 0.0246, LR: 0.0000100000
真实数据: 社会热点、焦点和人们
结果显示: 社会热点、焦点和人们
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.8915, LR: 0.0000100000
真实数据: 调究竟哪些正确可信?
结果显示: 调究竟哪些正确可信?
Epoch 0 Step 001700, model loss 3.2553, LR: 0.0000100000
真实数据: 不去，蕴藏巨大报复性
结果显示: 不去，蓝藏巨大报复性
Epoch 0 Step 001800, model loss 0.0262, LR: 0.0000100000
真实数据: 语言出现于史前，相对
结果显示: 语言出现于史前，相对
Epoch 0 Step 001900, model loss 0.3028, LR: 0.0000100000
真实数据: 所里面的卫生纸都要拿
结果显示: 所里面的卫生纸都要拿
Epoch 0 Step 002000, model loss 0.2138, LR: 0.0000100000
真实数据: erdevelopm
结果显示: erdevelopm
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0194, LR: 0.0000100000
真实数据: 全世界犹太人平均每年
结果显示: 全世界犹太人平均每年
Epoch 0 Step 002200, model loss 0.5402, LR: 0.0000100000
真实数据: 戏的基本原则就是‘迎
结果显示: 戏的基本原则就是‘迎
Epoch 0 Step 002300, model loss 0.0511, LR: 0.0000100000
真实数据: 用化妆品前，陶不与谈
结果显示: 用化妆品前，陶不与谈
Epoch 0 Step 002400, model loss 0.6592, LR: 0.0000100000
真实数据: 了很多球，查看资料大
结果显示: 了很多球，查看资料大
Epoch 0 Step 002500, model loss 4.1444, LR: 0.0000100000
真实数据: "sports007
结果显示: "sports007隶
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 1.6044, LR: 0.0000100000
真实数据: 1-1.3万名员工之
结果显示: 1一1.3万名员工之
Epoch 0 Step 002700, model loss 0.0022, LR: 0.0000100000
真实数据: !何劳致谢?”只要有
结果显示: !何劳致谢?”只要有
Epoch 0 Step 002800, model loss 0.0234, LR: 0.0000100000
真实数据: ，让他跟其它亲王一样
结果显示: ，让他跟其它亲王一样
Epoch 0 Step 002900, model loss 0.0034, LR: 0.0000100000
真实数据: 轮是对外开放，主要来
结果显示: 轮是对外开放，主要来
Epoch 0 Step 003000, model loss 0.0354, LR: 0.0000100000
真实数据: 、你会因为一个别致的
结果显示: 、你会因为一个别致的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 4.9946, LR: 0.0000100000
真实数据: 隐冀垂纳。可能还包括
结果显示: 隐龚垂纳。可能还包括
Epoch 0 Step 003200, model loss 0.2204, LR: 0.0000100000
真实数据: 历史上称为“海防”、
结果显示: 历史上称为“海防”、
Epoch 0 Step 003300, model loss 3.4661, LR: 0.0000100000
真实数据: 印度目前拥有8个国有
结果显示: 印度目前视有8个国有
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001E91E428258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0236, LR: 0.0000100000
真实数据: 又审视女仪容态度，共
结果显示: 又审视女仪容态度，共
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.3402, LR: 0.0000100000
真实数据: 婢转付生。账单”外，
结果显示: 婢转付生。账单”外，
Epoch 0 Step 000200, model loss 0.7911, LR: 0.0000100000
真实数据: 、清华可能支撑一阵子
结果显示: 、清华可能支撑一阵子
Epoch 0 Step 000300, model loss 31.6442, LR: 0.0000100000
真实数据: 以及释迦牟尼相提并论
结果显示: 以及释孤锏尼相提并论
Epoch 0 Step 000400, model loss 0.0177, LR: 0.0000100000
真实数据: 后可以不办理户口迁移
结果显示: 后可以不办理户口迁移
Epoch 0 Step 000500, model loss 0.1008, LR: 0.0000100000
真实数据: 杜绝生源地方化的关键
结果显示: 杜绝生源地方化的关键
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 11.3488, LR: 0.0000100000
真实数据: 况下，烂红薯（带有黑
结果显示: 况下，烂红著（带有黑
Epoch 0 Step 000700, model loss 2.5504, LR: 0.0000100000
真实数据: 早晨起床后较重，暴躁
结果显示: 早晨起床后较重，暴栗
Epoch 0 Step 000800, model loss 0.0029, LR: 0.0000100000
真实数据: 西洋画的手段，就会发
结果显示: 西洋画的手段，就会发
Epoch 0 Step 000900, model loss 1.1612, LR: 0.0000100000
真实数据: 、雪儿、洛史都华、莎
结果显示: 、雪儿、洛史都华、莎
Epoch 0 Step 001000, model loss 13.6626, LR: 0.0000100000
真实数据: 券通:乖獐、狡兔、长
结果显示: 券通:乖、校兔、长
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.6737, LR: 0.0000100000
真实数据: 也该对携假名牌者说“
结果显示: 也该对携假名牌者说“
Epoch 0 Step 001200, model loss 0.0671, LR: 0.0000100000
真实数据: p://www.on
结果显示: p://www.on
Epoch 0 Step 001300, model loss 0.0789, LR: 0.0000100000
真实数据: 起那离我们还不久远的
结果显示: 起那离我们还不久远的
Epoch 0 Step 001400, model loss 0.0198, LR: 0.0000100000
真实数据: 这样找工作必定颇费周
结果显示: 这样找工作必定颇费周
Epoch 0 Step 001500, model loss 0.0168, LR: 0.0000100000
真实数据: 二:他三人都睡在地上
结果显示: 二:他三人都睡在地上
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 8.0107, LR: 0.0000100000
真实数据: 队来熟悉西太平洋海区
结果显示: 队来整恶西太平洋海区
Epoch 0 Step 001700, model loss 22.5224, LR: 0.0000100000
真实数据: 恋人和别的男士愉快交
结果显示: 事人和别的男士恰快交
Epoch 0 Step 001800, model loss 0.0644, LR: 0.0000100000
真实数据: 尚言，但是，不要穿得
结果显示: 尚言，但是，不要穿得
Epoch 0 Step 001900, model loss 0.0462, LR: 0.0000100000
真实数据: 航电系统却是总设计师
结果显示: 航电系统却是总设计师
Epoch 0 Step 002000, model loss 2.7467, LR: 0.0000100000
真实数据: 投资额度能够进场操作
结果显示: 投资额度能够进场标作
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0189, LR: 0.0000100000
真实数据: 取时不确定考生具体专
结果显示: 取时不确定考生具体专
Epoch 0 Step 002200, model loss 0.0585, LR: 0.0000100000
真实数据: 东方体育日报》在文章
结果显示: 东方体育日报》在文章
Epoch 0 Step 002300, model loss 0.5973, LR: 0.0000100000
真实数据: 家队集训对我来说实在
结果显示: 家队集训对我来说实在
Epoch 0 Step 002400, model loss 1.0347, LR: 0.0000100000
真实数据: 从制冷到汽车的一系列
结果显示: 从制冷到汽车的一系列
Epoch 0 Step 002500, model loss 0.0132, LR: 0.0000100000
真实数据: 需提交公司2006年
结果显示: 需提交公司2006年
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.2572, LR: 0.0000100000
真实数据: 些家长却不答应，“能
结果显示: 些家长却不答应，“能
Epoch 0 Step 002700, model loss 0.0052, LR: 0.0000100000
真实数据: 能是重点中学排蒙最后
结果显示: 能是重点中学排蒙最后
Epoch 0 Step 002800, model loss 0.4722, LR: 0.0000100000
真实数据: 他在大学里承担着繁重
结果显示: 他在大学里承担着繁重
Epoch 0 Step 002900, model loss 0.0004, LR: 0.0000100000
真实数据: 面，有时我宁可让自己
结果显示: 面，有时我宁可让自己
Epoch 0 Step 003000, model loss 0.0056, LR: 0.0000100000
真实数据: 界第三。遇上不良刺激
结果显示: 界第三。遇上不良刺激
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0119, LR: 0.0000100000
真实数据: 绝对新鲜，(二)住宿
结果显示: 绝对新鲜，(二)住宿
Epoch 0 Step 003200, model loss 0.0044, LR: 0.0000100000
真实数据: 为，则治安性案件相对
结果显示: 为，则治安性案件相对
Epoch 0 Step 003300, model loss 1.0219, LR: 0.0000100000
真实数据: 镇学生是站在同一个起
结果显示: 镇学生是站在同一个起
Epoch 0 Step 003400, model loss 20.1757, LR: 0.0000100000
真实数据: 城市幼儿园那样对农村
结果显示: 域市结儿因那样对农村
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001D38B149258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0127, LR: 0.0000100000
真实数据: 着胆，今天是黄金周的
结果显示: 着胆，今天是黄金周的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0038, LR: 0.0000100000
真实数据: 回国与好友徐勇先生共
结果显示: 回国与好友徐勇先生共
Epoch 0 Step 000200, model loss 0.0294, LR: 0.0000100000
真实数据: 对夫妻带领着各自的部
结果显示: 对夫妻带领着各自的部
Epoch 0 Step 000300, model loss 0.0005, LR: 0.0000100000
真实数据: 几年以后可能变成非常
结果显示: 几年以后可能变成非常
Epoch 0 Step 000400, model loss 0.0064, LR: 0.0000100000
真实数据: ，一般要求应聘者能修
结果显示: ，一般要求应聘者能修
Epoch 0 Step 000500, model loss 0.0335, LR: 0.0000100000
真实数据: 此同时，你最了解李达
结果显示: 此同时，你最了解李达
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 4.6022, LR: 0.0000100000
真实数据: 总体规模发生了较大变
结果显示: 总体规模发生了较犬交
Epoch 0 Step 000700, model loss 0.0054, LR: 0.0000100000
真实数据: 仙厅）这样我们就可以
结果显示: 仙厅）这样我们就可以
Epoch 0 Step 000800, model loss 0.0088, LR: 0.0000100000
真实数据: （3）四大碗:再低调
结果显示: （3）四大碗:再低调
Epoch 0 Step 000900, model loss 2.1235, LR: 0.0000100000
真实数据: 父母有一天觉得“这孩
结果显示: 父母有一天看得“这孩
Epoch 0 Step 001000, model loss 0.0063, LR: 0.0000100000
真实数据: 对老祖宗。但是除去罗
结果显示: 对老祖宗。但是除去罗
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.3328, LR: 0.0000100000
真实数据: 也是全非洲第三大城市
结果显示: 也是全非洲第三大城市
Epoch 0 Step 001200, model loss 0.0032, LR: 0.0000100000
真实数据: 刀”，他又要稳定天下
结果显示: 刀”，他又要稳定天下
Epoch 0 Step 001300, model loss 17.1490, LR: 0.0000100000
真实数据: 帕尔玛VSAC米兰推
结果显示: 帕尔迈!sAC米兰推
Epoch 0 Step 001400, model loss 11.7584, LR: 0.0000100000
真实数据: 自己却冒着爆炸的危险
结果显示: 的己规冒着爆染的危险
Epoch 0 Step 001500, model loss 0.0064, LR: 0.0000100000
真实数据: 他才大呼上当。还得面
结果显示: 他才大呼上当。还得面
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0022, LR: 0.0000100000
真实数据: 是北京某公司驻济南办
结果显示: 是北京某公司驻济南办
Epoch 0 Step 001700, model loss 0.1024, LR: 0.0000100000
真实数据: 往中国武汉人才市场信
结果显示: 往中国武汉人才市场信
Epoch 0 Step 001800, model loss 0.4532, LR: 0.0000100000
真实数据: 我们估计出来一个学生
结果显示: 我们估计出来一个学生
Epoch 0 Step 001900, model loss 0.1701, LR: 0.0000100000
真实数据: 能够继续给对手施加一
结果显示: 能够继续给对手施加一
Epoch 0 Step 002000, model loss 0.0319, LR: 0.0000100000
真实数据: 发射需要2500万能
结果显示: 发射需要2500万能
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0006, LR: 0.0000100000
真实数据: 使自己的人生之路更加
结果显示: 使自己的人生之路更加
Epoch 0 Step 002200, model loss 2.6623, LR: 0.0000100000
真实数据: 见我何为哉?我亦犹人
结果显示: 兄我何为裁?我亦犹人
Epoch 0 Step 002300, model loss 0.0290, LR: 0.0000100000
真实数据: 没有获得成功……今天
结果显示: 没有获得成功……今天
Epoch 0 Step 002400, model loss 0.0659, LR: 0.0000100000
真实数据: 既然必须依据自然界的
结果显示: 既然必须依据自然界的
Epoch 0 Step 002500, model loss 0.2614, LR: 0.0000100000
真实数据: 不仅能积累一些工作经
结果显示: 不仅能积累一些工作经
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0018, LR: 0.0000100000
真实数据: 尼《国际日报》28日
结果显示: 尼《国际日报》28日
Epoch 0 Step 002700, model loss 0.0001, LR: 0.0000100000
真实数据: 是人民的教师，从而达
结果显示: 是人民的教师，从而达
Epoch 0 Step 002800, model loss 0.0563, LR: 0.0000100000
真实数据: 致伊朗强硬派走上了领
结果显示: 致伊朗强硬派走上了领
Epoch 0 Step 002900, model loss 6.9164, LR: 0.0000100000
真实数据: ”(沈寿:该病人情况
结果显示: ”《沈走寿:该病人情况
Epoch 0 Step 003000, model loss 0.6291, LR: 0.0000100000
真实数据: 要见皇上!最后大声喊
结果显示: 要见皇上!最后大声喊
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0100, LR: 0.0000100000
真实数据: 但是专业的男士内衣品
结果显示: 但是专业的男士内衣品
Epoch 0 Step 003200, model loss 0.0291, LR: 0.0000100000
真实数据: 十一五”期间有什么具
结果显示: 十一五”期间有什么具
Epoch 0 Step 003300, model loss 0.0044, LR: 0.0000100000
真实数据: 本人以及财产上的利害
结果显示: 本人以及财产上的利害
Epoch 0 Step 003400, model loss 0.0001, LR: 0.0000100000
真实数据: 反应就未免有点太具有
结果显示: 反应就未免有点太具有
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001715E1E8258>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0113, LR: 0.0000100000
真实数据: 有科技大学、理工大学
结果显示: 有科技大学、理工大学
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0191, LR: 0.0000100000
真实数据: 也罢，在自己的职权范
结果显示: 也罢，在自己的职权范
Epoch 0 Step 000200, model loss 0.0914, LR: 0.0000100000
真实数据: 所以根本没有必要去冒
结果显示: 所以根本没有必要去冒
Epoch 0 Step 000300, model loss 0.0112, LR: 0.0000100000
真实数据: 出货量增长速度最快世
结果显示: 出货量增长速度最快世
Epoch 0 Step 000400, model loss 0.0097, LR: 0.0000100000
真实数据: 钻，军事科研的创新能
结果显示: 钻，军事科研的创新能
Epoch 0 Step 000500, model loss 0.5212, LR: 0.0000100000
真实数据: 最后，这些面对挫折的
结果显示: 最后，这些面对挫折的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.4662, LR: 0.0000100000
真实数据: tionLoadWi
结果显示: tionLoadWi
Epoch 0 Step 000700, model loss 0.0309, LR: 0.0000100000
真实数据: 易商中有11家认为联
结果显示: 易商中有11家认为联
Epoch 0 Step 000800, model loss 0.0746, LR: 0.0000100000
真实数据: 是，正都在河边上吵闹
结果显示: 是，正都在河边上吵闹
Epoch 0 Step 000900, model loss 0.1850, LR: 0.0000100000
真实数据: 不承诺投资者获取收益
结果显示: 不承诺投资者获取收益
Epoch 0 Step 001000, model loss 3.0333, LR: 0.0000100000
真实数据: 地同心，情绪稍有稳定
结果显示: 地同心，情绪稍有杨定
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0831, LR: 0.0000100000
真实数据: 乐伊谁?抱刺于怀，且
结果显示: 乐伊谁?抱刺于怀，且
Epoch 0 Step 001200, model loss 0.0074, LR: 0.0000100000
真实数据: 性，你除了应努力做出
结果显示: 性，你除了应努力做出
Epoch 0 Step 001300, model loss 0.0023, LR: 0.0000100000
真实数据: 份有限公司00.11
结果显示: 份有限公司00.11
Epoch 0 Step 001400, model loss 0.0118, LR: 0.0000100000
真实数据: 是北方少数民族尤其是
结果显示: 是北方少数民族尤其是
Epoch 0 Step 001500, model loss 0.4434, LR: 0.0000100000
真实数据: 决把疫情消灭在疫点上
结果显示: 决把疫情消灭在疫点上
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 9.1598, LR: 0.0000100000
真实数据: 我是一个令您骄傲的儿
结果显示: 我是一个令您骄做的儿
Epoch 0 Step 001700, model loss 2.4093, LR: 0.0000100000
真实数据: 的战争为民众反军阀的
结果显示: 的战争为民众反军阅的
Epoch 0 Step 001800, model loss 0.8447, LR: 0.0000100000
真实数据: 政经费问题”还是“制
结果显示: 政经费问题”还是“制
Epoch 0 Step 001900, model loss 4.1446, LR: 0.0000100000
真实数据: 山―济南的票价散客5
结果显示: 山一济南的票价散客5
Epoch 0 Step 002000, model loss 0.0575, LR: 0.0000100000
真实数据: 可能买新车?并积极宣
结果显示: 可能买新车?并积极宣
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0003, LR: 0.0000100000
真实数据: 及，认为这样的工作比
结果显示: 及，认为这样的工作比
Epoch 0 Step 002200, model loss 0.0301, LR: 0.0000100000
真实数据: 在1分55秒跳投命中
结果显示: 在1分55秒跳投命中
Epoch 0 Step 002300, model loss 13.6084, LR: 0.0000100000
真实数据: ，摒弃所有引起人的贪
结果显示: ，振弃所有引起人的贪
Epoch 0 Step 002400, model loss 0.3256, LR: 0.0000100000
真实数据: 该所预测，切记带着你
结果显示: 该所预测，切记带着你
Epoch 0 Step 002500, model loss 0.7493, LR: 0.0000100000
真实数据: :欧盟的这种处罚措施
结果显示: :欧盟的这种处罚措施
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0112, LR: 0.0000100000
真实数据: 最能保持清醒。换财富
结果显示: 最能保持清醒。换财富
Epoch 0 Step 002700, model loss 7.0556, LR: 0.0000100000
真实数据: rseofhisin
结果显示: rseofisi
Epoch 0 Step 002800, model loss 0.0041, LR: 0.0000100000
真实数据: 人大脑中的思想能够在
结果显示: 人大脑中的思想能够在
Epoch 0 Step 002900, model loss 0.0034, LR: 0.0000100000
真实数据: 经典《基地》系列到《
结果显示: 经典《基地》系列到《
Epoch 0 Step 003000, model loss 0.0321, LR: 0.0000100000
真实数据: 走向军事大国的实际步
结果显示: 走向军事大国的实际步
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0185, LR: 0.0000100000
真实数据: 必须有一套政治家层级
结果显示: 必须有一套政治家层级
Epoch 0 Step 003200, model loss 15.4738, LR: 0.0000100000
真实数据: 入邑庠。动作时总怕她
结果显示: 入邑库。动作时总怕她
Epoch 0 Step 003300, model loss 0.0720, LR: 0.0000100000
真实数据: 的生存空间就被剥夺掉
结果显示: 的生存空间就被剥夺掉
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000231376651A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0116, LR: 0.0000100000
真实数据: 同样的道理，让自己更
结果显示: 同样的道理，让自己更
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 7.9727, LR: 0.0000100000
真实数据: 甘心让自己的情敌贵嫔
结果显示: 甘心让自己的情敌贵啻
Epoch 0 Step 000200, model loss 1.3491, LR: 0.0000100000
真实数据: 以此为题材，不要排除
结果显示: 以此为题钛，不要排除
Epoch 0 Step 000300, model loss 9.8030, LR: 0.0000100000
真实数据: 中市烹饪协会申报“河
结果显示: 中市烹昼协会申报“河
Epoch 0 Step 000400, model loss 0.0043, LR: 0.0000100000
真实数据: 这一洞对心理的考验要
结果显示: 这一洞对心理的考验要
Epoch 0 Step 000500, model loss 0.0224, LR: 0.0000100000
真实数据: 一面售货，如不以冥顽
结果显示: 一面售货，如不以冥顽
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0012, LR: 0.0000100000
真实数据: 表示，过去我们发现这
结果显示: 表示，过去我们发现这
Epoch 0 Step 000700, model loss 0.0142, LR: 0.0000100000
真实数据: 他们的确没必要为了一
结果显示: 他们的确没必要为了一
Epoch 0 Step 000800, model loss 4.7377, LR: 0.0000100000
真实数据: 鹰穿云破雾，今始苏耳
结果显示: 腌穿云破雾，今始苏耳
Epoch 0 Step 000900, model loss 0.9392, LR: 0.0000100000
真实数据: ，5km吃速食看你的
结果显示: ，5km吃速食看你的
Epoch 0 Step 001000, model loss 0.0714, LR: 0.0000100000
真实数据: 专门写到“余古官司”
结果显示: 专门写到“余古官司”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0181, LR: 0.0000100000
真实数据: 最最重要的手段还是手
结果显示: 最最重要的手段还是手
Epoch 0 Step 001200, model loss 0.2087, LR: 0.0000100000
真实数据: 心事很快就被曹操所了
结果显示: 心事很快就被曹操所了
Epoch 0 Step 001300, model loss 0.0077, LR: 0.0000100000
真实数据: 是者数四，机经只有听
结果显示: 是者数四，机经只有听
Epoch 0 Step 001400, model loss 0.0659, LR: 0.0000100000
真实数据: 30运动广场特此公告
结果显示: 30运动广场特此公告
Epoch 0 Step 001500, model loss 0.0291, LR: 0.0000100000
真实数据: 中信中国市场70%的
结果显示: 中信中国市场70%的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0920, LR: 0.0000100000
真实数据: 所引片段充满了关于刚
结果显示: 所引片段充满了关于刚
Epoch 0 Step 001700, model loss 11.8686, LR: 0.0000100000
真实数据: :荫荫花香。也是一条
结果显示: :前静花香。也是一条
Epoch 0 Step 001800, model loss 0.0059, LR: 0.0000100000
真实数据: 公司又是中信集团的全
结果显示: 公司又是中信集团的全
Epoch 0 Step 001900, model loss 0.0014, LR: 0.0000100000
真实数据: 与各高校招生自主权的
结果显示: 与各高校招生自主权的
Epoch 0 Step 002000, model loss 0.5096, LR: 0.0000100000
真实数据: 译的市场前景越来越被
结果显示: 译的市场前景越来越被
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001F0281441A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 2.4954, LR: 0.0000100000
真实数据: “国家”与“社会”关
结果显示: “国家”与“杜会”关
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0186, LR: 0.0000100000
真实数据: 则可以完全赞同;不多
结果显示: 则可以完全赞同;不多
Epoch 0 Step 000200, model loss 3.8999, LR: 0.0000100000
真实数据: 官不荐，积极发展初级
结果显示: 言不荐，积极发展初级
Epoch 0 Step 000300, model loss 1.0418, LR: 0.0000100000
真实数据: 长）、孟晓锁（三原县
结果显示: 长），孟晓锁（三原县
Epoch 0 Step 000400, model loss 7.3048, LR: 0.0000100000
真实数据: 水扁一旦跨过“红线”
结果显示: 水扁一,早跨过“红线”
Epoch 0 Step 000500, model loss 0.6275, LR: 0.0000100000
真实数据: 抱住、固定、牢固。联
结果显示: 抱住、固定、牢固。联
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 13.0104, LR: 0.0000100000
真实数据: 过去的测试中，十余筵
结果显示: 过击的测试中，十余简
Epoch 0 Step 000700, model loss 0.0018, LR: 0.0000100000
真实数据: 广东全省的战事爆发起
结果显示: 广东全省的战事爆发起
Epoch 0 Step 000800, model loss 13.5243, LR: 0.0000100000
真实数据: 为其生产196套Id
结果显示: 为其生产196套d
Epoch 0 Step 000900, model loss 11.4470, LR: 0.0000100000
真实数据: 同时透露，需要综合考
结果显示: 同时诱露，需要绕金考
Epoch 0 Step 001000, model loss 0.0023, LR: 0.0000100000
真实数据: 停后马刺立即给予还击
结果显示: 停后马刺立即给予还击
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 3.0056, LR: 0.0000100000
真实数据: 报业的控制似乎要严于
结果显示: 报业的控制似乎要严手
Epoch 0 Step 001200, model loss 0.0195, LR: 0.0000100000
真实数据: 达了对自己受到联们轻
结果显示: 达了对自己受到联们轻
Epoch 0 Step 001300, model loss 0.0062, LR: 0.0000100000
真实数据: 是不是门当户对能帮助
结果显示: 是不是门当户对能帮助
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000222AB0321A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 9.4483, LR: 0.0000100000
真实数据: 鲜血淋漓的枪伤吓坏了
结果显示: 鲜之淋流的枪伤吓坏了
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000014EF21621A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0020, LR: 0.0000100000
真实数据: 料记载，6.2045
结果显示: 料记载，6.2045
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 3.1361, LR: 0.0000100000
真实数据: 收这样的观点，莫知故
结果显示: 收这样的观点，奖知故
Epoch 0 Step 000200, model loss 0.0798, LR: 0.0000100000
真实数据: 不遇，有预测说，中间
结果显示: 不遇，有预测说，中间
Epoch 0 Step 000300, model loss 2.4292, LR: 0.0000100000
真实数据: 指挥学等7个学科群有
结果显示: 指折学等7个学科群有
Epoch 0 Step 000400, model loss 0.0186, LR: 0.0000100000
真实数据: SandyLin15
结果显示: SandyLin15
Epoch 0 Step 000500, model loss 6.1568, LR: 0.0000100000
真实数据: 求冲破了纲常礼教的网
结果显示: 求冲破了织常礼教的网
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0193, LR: 0.0000100000
真实数据: .近年英译汉考题的特
结果显示: .近年英译汉考题的特
Epoch 0 Step 000700, model loss 0.1117, LR: 0.0000100000
真实数据: 认得我么?”那妖抬头
结果显示: 认得我么?”那妖抬头
Epoch 0 Step 000800, model loss 1.1098, LR: 0.0000100000
真实数据: 怀信心地接受一种初看
结果显示: 怀信心地接受一种初有
Epoch 0 Step 000900, model loss 6.5261, LR: 0.0000100000
真实数据: 其效果自然会大打折扣
结果显示: 其效果自然会大打折打
Epoch 0 Step 001000, model loss 0.0025, LR: 0.0000100000
真实数据: 把活计都交给王爷去干
结果显示: 把活计都交给王爷去干
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.4606, LR: 0.0000100000
真实数据: 学课程搬进社会的成功
结果显示: 学课程椒进社会的成功
Epoch 0 Step 001200, model loss 0.1323, LR: 0.0000100000
真实数据: 是稻米梯田最美丽的时
结果显示: 是稻米梯田最美丽的时
Epoch 0 Step 001300, model loss 0.4224, LR: 0.0000100000
真实数据: 元对人民币8.009
结果显示: 元对人民币8.009
Epoch 0 Step 001400, model loss 0.0617, LR: 0.0000100000
真实数据: 一生有关立身、处世、
结果显示: 一生有关立身、处世、
Epoch 0 Step 001500, model loss 0.3338, LR: 0.0000100000
真实数据: 小王眼里小张的表现与
结果显示: 小王眼里小张的表现与
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.8182, LR: 0.0000100000
真实数据: 缺乏对人尊重的环境里
结果显示: 缺乏对人尊重的环境里
Epoch 0 Step 001700, model loss 2.9648, LR: 0.0000100000
真实数据: 本场比赛欧洲赔率及对
结果显示: 本场比赛欧洲赂率及对
Epoch 0 Step 001800, model loss 0.0039, LR: 0.0000100000
真实数据: 线的机动性和应变能力
结果显示: 线的机动性和应变能力
Epoch 0 Step 001900, model loss 0.0018, LR: 0.0000100000
真实数据: 是不科学的。毕业合格
结果显示: 是不科学的。毕业合格
Epoch 0 Step 002000, model loss 0.0651, LR: 0.0000100000
真实数据: 换工作或进入新的环境
结果显示: 换工作或进入新的环境
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0006, LR: 0.0000100000
真实数据: 扬声器立体声音效、还
结果显示: 扬声器立体声音效、还
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001B565AE31A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0236, LR: 0.0000100000
真实数据: 形式揭示了诗歌的本质
结果显示: 形式揭示了诗歌的本质
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0560, LR: 0.0000100000
真实数据: 握九枚总冠军戒指。凯
结果显示: 握九枚总冠军戒指。凯
Epoch 0 Step 000200, model loss 0.5153, LR: 0.0000100000
真实数据: 疾病。威，而况鬼乎?
结果显示: 疾病。威，而况鬼乎?
Epoch 0 Step 000300, model loss 0.0380, LR: 0.0000100000
真实数据: 我后来专门研究美国军
结果显示: 我后来专门研究美国军
Epoch 0 Step 000400, model loss 0.1359, LR: 0.0000100000
真实数据: 公司――北京亚拓士创
结果显示: 公司――北京亚拓士创
Epoch 0 Step 000500, model loss 22.0429, LR: 0.0000100000
真实数据: 题，“几惊怖煞人!”
结果显示: 题，“几惊饰贼人!”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0007, LR: 0.0000100000
真实数据: 券公司将成为其接下来
结果显示: 券公司将成为其接下来
Epoch 0 Step 000700, model loss 0.4851, LR: 0.0000100000
真实数据: 安丘青云山的门票收入
结果显示: 安丘青云山的门票收入
Epoch 0 Step 000800, model loss 0.3847, LR: 0.0000100000
真实数据: 要限期整改。而入浴后
结果显示: 要限期整改。而入浴后
Epoch 0 Step 000900, model loss 0.0001, LR: 0.0000100000
真实数据: 底，求职是件很自主化
结果显示: 底，求职是件很自主化
Epoch 0 Step 001000, model loss 0.0177, LR: 0.0000100000
真实数据: 生可以根据本人意愿填
结果显示: 生可以根据本人意愿填
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.1123, LR: 0.0000100000
真实数据: 8:余尝谓把男人当玩
结果显示: 8:余尝谓把男人当玩
Epoch 0 Step 001200, model loss 1.1811, LR: 0.0000100000
真实数据: 无不战栗。“既有官责
结果显示: 无不战。“既有官责
Epoch 0 Step 001300, model loss 0.0159, LR: 0.0000100000
真实数据: 统观点里，a.是b.
结果显示: 统观点里，a.是b.
Epoch 0 Step 001400, model loss 0.1586, LR: 0.0000100000
真实数据: 她的手机开始频频收到
结果显示: 她的手机开始频频收到
Epoch 0 Step 001500, model loss 0.0101, LR: 0.0000100000
真实数据: 采取国家奖学金的形式
结果显示: 采取国家奖学金的形式
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0392, LR: 0.0000100000
真实数据: 反而可以激发活力与创
结果显示: 反而可以激发活力与创
Epoch 0 Step 001700, model loss 0.0166, LR: 0.0000100000
真实数据: :那厢是个卖酒的人家
结果显示: :那厢是个卖酒的人家
Epoch 0 Step 001800, model loss 0.6026, LR: 0.0000100000
真实数据: 我深感责任重大，去胜
结果显示: 我深感责任重大，去胜
Epoch 0 Step 001900, model loss 0.0222, LR: 0.0000100000
真实数据: 如何泼得?好一似火上
结果显示: 如何泼得?好一似火上
Epoch 0 Step 002000, model loss 0.0655, LR: 0.0000100000
真实数据: 精英一个是培养大师级
结果显示: 精英一个是培养大师级
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0360, LR: 0.0000100000
真实数据: 划今年推出新景点，分
结果显示: 划今年推出新景点，分
Epoch 0 Step 002200, model loss 0.3975, LR: 0.0000100000
真实数据: 虐的天性。曹新宇也认
结果显示: 虐的天性。曹新宇也认
Epoch 0 Step 002300, model loss 0.0366, LR: 0.0000100000
真实数据: 影2000以及“阵风
结果显示: 影2000以及“阵风
Epoch 0 Step 002400, model loss 1.3801, LR: 0.0000100000
真实数据: 衍生息。妾境内网络赌
结果显示: 行生息。妾境内网络赌
Epoch 0 Step 002500, model loss 0.0524, LR: 0.0000100000
真实数据: ，有些什么人事送我们
结果显示: ，有些什么人事送我们
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.2307, LR: 0.0000100000
真实数据: 》及其摘要(修订稿)
结果显示: 》及其摘要(修订稿)
Epoch 0 Step 002700, model loss 5.3510, LR: 0.0000100000
真实数据: 毛氏犹弯弓跨马，还有
结果显示: 毛氏犹弯了跨马，还有
Epoch 0 Step 002800, model loss 0.0063, LR: 0.0000100000
真实数据: 告之。V41等ver
结果显示: 告之。V41等ver
Epoch 0 Step 002900, model loss 0.0199, LR: 0.0000100000
真实数据: 之，[进球]写上孙悟
结果显示: 之，[进球]写上孙悟
Epoch 0 Step 003000, model loss 0.0152, LR: 0.0000100000
真实数据: 士尼今天提早在上午九
结果显示: 士尼今天提早在上午九
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0154, LR: 0.0000100000
真实数据: 、休闲农业与乡村旅游
结果显示: 、休闲农业与乡村旅游
Epoch 0 Step 003200, model loss 14.6670, LR: 0.0000100000
真实数据: 要大力揉搓，相比之下
结果显示: 要大力排揪，相比之下
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000020A503C21A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0587, LR: 0.0000100000
真实数据: 便会在那里形成“冲击
结果显示: 便会在那里形成“冲击
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.5288, LR: 0.0000100000
真实数据: 生的幸福因了他们而实
结果显示: 生的幸福因了他们而实
Epoch 0 Step 000200, model loss 0.0005, LR: 0.0000100000
真实数据: 等等行业的股票占比居
结果显示: 等等行业的股票占比居
Epoch 0 Step 000300, model loss 0.0756, LR: 0.0000100000
真实数据: 闹闹家里发生严重爆炸
结果显示: 闹闹家里发生严重爆炸
Epoch 0 Step 000400, model loss 0.0043, LR: 0.0000100000
真实数据: :这次对特种精英部队
结果显示: :这次对特种精英部队
Epoch 0 Step 000500, model loss 1.1806, LR: 0.0000100000
真实数据: ");SetCook
结果显示: "）;SetCook
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0297, LR: 0.0000100000
真实数据: 如就算、就算我们家里
结果显示: 如就算、就算我们家里
Epoch 0 Step 000700, model loss 0.0429, LR: 0.0000100000
真实数据: 在全国一刀切不允许再
结果显示: 在全国一刀切不允许再
Epoch 0 Step 000800, model loss 0.0224, LR: 0.0000100000
真实数据: 沪铁路的走向大体并行
结果显示: 沪铁路的走向大体并行
Epoch 0 Step 000900, model loss 1.2042, LR: 0.0000100000
真实数据: 料图:这对保护自己和
结果显示: 料图:这对保护自己和
Epoch 0 Step 001000, model loss 0.3321, LR: 0.0000100000
真实数据: 按有关规定转入其他体
结果显示: 按有关规定转入其他体
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0006, LR: 0.0000100000
真实数据: 班里的学生利用假期有
结果显示: 班里的学生利用假期有
Epoch 0 Step 001200, model loss 0.1891, LR: 0.0000100000
真实数据: 对手因队伍新老交替而
结果显示: 对手因队伍新老交替而
Epoch 0 Step 001300, model loss 1.2472, LR: 0.0000100000
真实数据: 不足论报;一、维修无
结果显示: 不足论报:一、维修无
Epoch 0 Step 001400, model loss 4.1869, LR: 0.0000100000
真实数据: 灯溢彩，打下4架飞机
结果显示: 灯橡彩，打下4架飞机
Epoch 0 Step 001500, model loss 0.0152, LR: 0.0000100000
真实数据: 士建议对世界先进积体
结果显示: 士建议对世界先进积体
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0031, LR: 0.0000100000
真实数据: 4:1]搜狐直播员:
结果显示: 4:1]搜狐直播员:
Epoch 0 Step 001700, model loss 0.0059, LR: 0.0000100000
真实数据: thernecess
结果显示: thernecess
Epoch 0 Step 001800, model loss 2.7080, LR: 0.0000100000
真实数据: 关（GATEWAY）
结果显示: 关（GATEWAY)
Epoch 0 Step 001900, model loss 0.0029, LR: 0.0000100000
真实数据: 弃有神论的思想和宗教
结果显示: 弃有神论的思想和宗教
Epoch 0 Step 002000, model loss 0.0042, LR: 0.0000100000
真实数据: 每一位生者都应审视自
结果显示: 每一位生者都应审视自
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0041, LR: 0.0000100000
真实数据: 起，充分认识国家对军
结果显示: 起，充分认识国家对军
Epoch 0 Step 002200, model loss 0.0017, LR: 0.0000100000
真实数据: 身上取三分的武汉队最
结果显示: 身上取三分的武汉队最
Epoch 0 Step 002300, model loss 0.0117, LR: 0.0000100000
真实数据: 5月2日巩固基础回课
结果显示: 5月2日巩固基础回课
Epoch 0 Step 002400, model loss 0.0025, LR: 0.0000100000
真实数据: 考虑如何对待下一场比
结果显示: 考虑如何对待下一场比
Epoch 0 Step 002500, model loss 19.8224, LR: 0.0000100000
真实数据: 不可坐观沈溺而不拯救
结果显示: 不可坐观浇溜而不摆款
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0040, LR: 0.0000100000
真实数据: 工作去卖肉这类的报道
结果显示: 工作去卖肉这类的报道
Epoch 0 Step 002700, model loss 0.0219, LR: 0.0000100000
真实数据: 可以巧妙地组合成有趣
结果显示: 可以巧妙地组合成有趣
Epoch 0 Step 002800, model loss 0.0002, LR: 0.0000100000
真实数据: 围的人说你精神好多了
结果显示: 围的人说你精神好多了
Epoch 0 Step 002900, model loss 0.0168, LR: 0.0000100000
真实数据: )凡不符合录取要求或
结果显示: )凡不符合录取要求或
Epoch 0 Step 003000, model loss 1.7201, LR: 0.0000100000
真实数据: 以上议案进行投票表决
结果显示: 以上议案进行投票决
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 10.4941, LR: 0.0000100000
真实数据: 可允许的范畴内第5页
结果显示: 可允许的范啃内第5页
Epoch 0 Step 003200, model loss 0.0022, LR: 0.0000100000
真实数据: 手组成旅游“黄金大三
结果显示: 手组成旅游“黄金大三
Epoch 0 Step 003300, model loss 0.0081, LR: 0.0000100000
真实数据: 在偏远的老油区开采工
结果显示: 在偏远的老油区开采工
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000111864D21A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0112, LR: 0.0000100000
真实数据: 1只股改股今日网络投
结果显示: 1只股改股今日网络投
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0134, LR: 0.0000100000
真实数据: 讨厌的家伙吗?快做一
结果显示: 讨厌的家伙吗?快做一
Epoch 0 Step 000200, model loss 0.5038, LR: 0.0000100000
真实数据: 陈总:每天听到这些好
结果显示: 陈总:每天听到这些好
Epoch 0 Step 000300, model loss 11.8833, LR: 0.0000100000
真实数据: 个例子，羊祜五岁的时
结果显示: 个例子，羊社五岁的时
Epoch 0 Step 000400, model loss 0.0322, LR: 0.0000100000
真实数据: 国的军事学者，“楼上
结果显示: 国的军事学者，“楼上
Epoch 0 Step 000500, model loss 0.0049, LR: 0.0000100000
真实数据: 使用，也能支持互联网
结果显示: 使用，也能支持互联网
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0337, LR: 0.0000100000
真实数据: 征集对象:用上官兄的
结果显示: 征集对象:用上官兄的
Epoch 0 Step 000700, model loss 0.0037, LR: 0.0000100000
真实数据: 005大学生最佳雇主
结果显示: 005大学生最佳雇主
Epoch 0 Step 000800, model loss 0.0036, LR: 0.0000100000
真实数据: 道:比去年减少221
结果显示: 道:比去年减少221
Epoch 0 Step 000900, model loss 2.8011, LR: 0.0000100000
真实数据: 件被丹麦首相埃里克森
结果显示: 件被丹去首相埃里克森
Epoch 0 Step 001000, model loss 0.0006, LR: 0.0000100000
真实数据: 5由于对上市公司本身
结果显示: 5由于对上市公司本身
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 2.1578, LR: 0.0000100000
真实数据: ，可是往往自己痛快了
结果显示: ，可是佳往自己痛快了
Epoch 0 Step 001200, model loss 0.3732, LR: 0.0000100000
真实数据: 都是枝叶。丹皮尔两罚
结果显示: 都是枝叶。丹皮尔两罚
Epoch 0 Step 001300, model loss 0.0873, LR: 0.0000100000
真实数据: 3班的班牌走在最前面
结果显示: 3班的班牌走在最前面
Epoch 0 Step 001400, model loss 2.4629, LR: 0.0000100000
真实数据: 话题作为与他交流的序
结果显示: 话题作为与他交流的摩
Epoch 0 Step 001500, model loss 0.6464, LR: 0.0000100000
真实数据: 殿”画成一个城门楼子
结果显示: 殿”画成一个城门楼子
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.1268, LR: 0.0000100000
真实数据: 虽免，可影响胎盘对胎
结果显示: 虽免，可影响胎盘对胎
Epoch 0 Step 001700, model loss 0.0018, LR: 0.0000100000
真实数据: 会于2006年3月2
结果显示: 会于2006年3月2
Epoch 0 Step 001800, model loss 0.2239, LR: 0.0000100000
真实数据: 伤害它们，那先锋不能
结果显示: 伤害它们，那先锋不能
Epoch 0 Step 001900, model loss 0.0465, LR: 0.0000100000
真实数据: 成功的人力资源管理者
结果显示: 成功的人力资源管理者
Epoch 0 Step 002000, model loss 11.7590, LR: 0.0000100000
真实数据: 正立于星娥、微云之间
结果显示: 正立于星针、微云之间
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0057, LR: 0.0000100000
真实数据: 叫是因为一直处在一种
结果显示: 叫是因为一直处在一种
Epoch 0 Step 002200, model loss 1.4909, LR: 0.0000100000
真实数据: 这玩艺喷出的火焰能转
结果显示: 这玩艺喷出的火炮能转
Epoch 0 Step 002300, model loss 5.2214, LR: 0.0000100000
真实数据: 她一股脑倒出，他原本
结果显示: 她一股脑明出，他历本
Epoch 0 Step 002400, model loss 0.0008, LR: 0.0000100000
真实数据: 国的社工制度极不发达
结果显示: 国的社工制度极不发达
Epoch 0 Step 002500, model loss 0.0853, LR: 0.0000100000
真实数据: 坐着一个个浓妆艳抹的
结果显示: 坐着一个个浓妆艳抹的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.3029, LR: 0.0000100000
真实数据: 05年10月17日-
结果显示: 05年10月17日-
Epoch 0 Step 002700, model loss 0.0152, LR: 0.0000100000
真实数据: 1便生根开花，突破常
结果显示: 1便生根开花，突破常
Epoch 0 Step 002800, model loss 1.2525, LR: 0.0000100000
真实数据: K46Mod0式30
结果显示: K46Mod0式30
Epoch 0 Step 002900, model loss 0.0426, LR: 0.0000100000
真实数据: 与“玉山05”演习不
结果显示: 与“玉山05”演习不
Epoch 0 Step 003000, model loss 1.1372, LR: 0.0000100000
真实数据: 是美丽的匹兰斯堡国家
结果显示: 是美丽的匹兰斯堡国家
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.4919, LR: 0.0000100000
真实数据: 平遥古城墙现在就处于
结果显示: 平遥古城墙现在就处于
Epoch 0 Step 003200, model loss 0.0006, LR: 0.0000100000
真实数据: 以随便发挥的，要“投
结果显示: 以随便发挥的，要“投
Epoch 0 Step 003300, model loss 0.0051, LR: 0.0000100000
真实数据: 真正的销售员在面对客
结果显示: 真正的销售员在面对客
Epoch 0 Step 003400, model loss 0.0215, LR: 0.0000100000
真实数据: 加分或降低分数要求投
结果显示: 加分或降低分数要求投
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001F2B70621A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 28.1992, LR: 0.0000100000
真实数据: 省旅游质量监督所所长
结果显示: 省法游股质盈监雷济3长
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.8602, LR: 0.0000100000
真实数据: 辉煌的国家剧院到小p
结果显示: 辉煌的国家剧院到小p
Epoch 0 Step 000200, model loss 1.6282, LR: 0.0000100000
真实数据: 440490512-
结果显示: 440490512.
Epoch 0 Step 000300, model loss 0.0305, LR: 0.0000100000
真实数据: 杂岩是典型的‘早前寒
结果显示: 杂岩是典型的‘早前寒
Epoch 0 Step 000400, model loss 0.4986, LR: 0.0000100000
真实数据: 驾车:“绿色目标”不
结果显示: 驾车:“绿色目标”不
Epoch 0 Step 000500, model loss 0.0240, LR: 0.0000100000
真实数据: 何引导孩子健康使用网
结果显示: 何引导孩子健康使用网
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 1.5601, LR: 0.0000100000
真实数据: 9个经济适用住房地块
结果显示: 9个经济适用往房地块
Epoch 0 Step 000700, model loss 0.0031, LR: 0.0000100000
真实数据: 将危机出现的风险降到
结果显示: 将危机出现的风险降到
Epoch 0 Step 000800, model loss 0.8723, LR: 0.0000100000
真实数据: 非常经济。或者是对大
结果显示: 非常经济。或者是对大
Epoch 0 Step 000900, model loss 0.9824, LR: 0.0000100000
真实数据: 不断暴露出了其原有的
结果显示: 不断暴露出了其原有的
Epoch 0 Step 001000, model loss 0.7483, LR: 0.0000100000
真实数据: 出来的油漆厚度大于用
结果显示: 出来的油漆厚度大于用
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 6.1539, LR: 0.0000100000
真实数据: 卒不能追忆。随后的两
结果显示: 辛不能连忆。随后的两
Epoch 0 Step 001200, model loss 0.1128, LR: 0.0000100000
真实数据: 用住房或申请宅基地建
结果显示: 用住房或申请宅基地建
Epoch 0 Step 001300, model loss 0.2531, LR: 0.0000100000
真实数据: 司Noble-new
结果显示: 司Noble-new
Epoch 0 Step 001400, model loss 0.0094, LR: 0.0000100000
真实数据: 司的这一问题已经得到
结果显示: 司的这一问题已经得到
Epoch 0 Step 001500, model loss 0.0023, LR: 0.0000100000
真实数据: 托机制和大陆方面达成
结果显示: 托机制和大陆方面达成
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0061, LR: 0.0000100000
真实数据: 生活后出现肌肉酸痛的
结果显示: 生活后出现肌肉酸痛的
Epoch 0 Step 001700, model loss 0.0216, LR: 0.0000100000
真实数据: 载有50名乘客的火车
结果显示: 载有50名乘客的火车
Epoch 0 Step 001800, model loss 9.8869, LR: 0.0000100000
真实数据: 现实可行的短期目标最
结果显示: 勇实可行的翘期目标最
Epoch 0 Step 001900, model loss 0.0555, LR: 0.0000100000
真实数据: 试想，“水-人类的未
结果显示: 试想，“水-人类的未
Epoch 0 Step 002000, model loss 0.0027, LR: 0.0000100000
真实数据: 学收费不仅仅是高收费
结果显示: 学收费不仅仅是高收费
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 8.7213, LR: 0.0000100000
真实数据: ，李定国亲临肇庆城下
结果显示: ,李定国亲临叉庆城下
Epoch 0 Step 002200, model loss 0.0007, LR: 0.0000100000
真实数据: 当传染科大夫。图中人
结果显示: 当传染科大夫。图中人
Epoch 0 Step 002300, model loss 6.0673, LR: 0.0000100000
真实数据: 有很多解释，禹杀而戮
结果显示: 有很多解释，禹杀而数
Epoch 0 Step 002400, model loss 0.0118, LR: 0.0000100000
真实数据: 京市海淀区学院路30
结果显示: 京市海淀区学院路30
Epoch 0 Step 002500, model loss 0.8973, LR: 0.0000100000
真实数据: 相关网页.反被捏造!
结果显示: 相关网页.反被捏造!
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0004, LR: 0.0000100000
真实数据: 做题等，富人报人以财
结果显示: 做题等，富人报人以财
Epoch 0 Step 002700, model loss 0.1362, LR: 0.0000100000
真实数据: 然捧老孙领四健将随后
结果显示: 然捧老孙领四健将随后
Epoch 0 Step 002800, model loss 0.3054, LR: 0.0000100000
真实数据: ressiontha
结果显示: ressiontha
Epoch 0 Step 002900, model loss 0.0108, LR: 0.0000100000
真实数据: 提出“互助游”的方式
结果显示: 提出“互助游”的方式
Epoch 0 Step 003000, model loss 0.0066, LR: 0.0000100000
真实数据: 收取该项费用的国内银
结果显示: 收取该项费用的国内银
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0017, LR: 0.0000100000
真实数据: 我过去降妖?”八戒道
结果显示: 我过去降妖?”八戒道
Epoch 0 Step 003200, model loss 0.1340, LR: 0.0000100000
真实数据: 。与国内外优秀常规滑
结果显示: 。与国内外优秀常规滑
Epoch 0 Step 003300, model loss 2.4682, LR: 0.0000100000
真实数据: 红杏出墙,捷利物流与
结果显示: 红杏出墙,技利物流与
Epoch 0 Step 003400, model loss 0.0207, LR: 0.0000100000
真实数据: 的资料可以被用来进行
结果显示: 的资料可以被用来进行
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001DA037321A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.3988, LR: 0.0000100000
真实数据: 005职场十大精辟语
结果显示: 005职场十大精辟语
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1713, LR: 0.0000100000
真实数据: 可以实施战略欺骗、干
结果显示: 可以实施战略欺骗、干
Epoch 0 Step 000200, model loss 11.0887, LR: 0.0000100000
真实数据: 能痊愈。但那三怪，应
结果显示: 能步急。但那三怪，应
Epoch 0 Step 000300, model loss 0.0022, LR: 0.0000100000
真实数据: 指的就是小说的象征性
结果显示: 指的就是小说的象征性
Epoch 0 Step 000400, model loss 0.4334, LR: 0.0000100000
真实数据: 会好运常有，除了蔡惟
结果显示: 会好运常有，除了蔡惟
Epoch 0 Step 000500, model loss 0.0219, LR: 0.0000100000
真实数据: 战国各学派以及战国以
结果显示: 战国各学派以及战国以
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0433, LR: 0.0000100000
真实数据: 切队2胜4负，一些政
结果显示: 切队2胜4负，一些政
Epoch 0 Step 000700, model loss 0.8595, LR: 0.0000100000
真实数据: 那只能是“竹篮子打水
结果显示: 那只能是“竹篮子打水
Epoch 0 Step 000800, model loss 0.0007, LR: 0.0000100000
真实数据: 多求职者都有这样的经
结果显示: 多求职者都有这样的经
Epoch 0 Step 000900, model loss 12.9167, LR: 0.0000100000
真实数据: 款买房、买车是一个家
结果显示: 欧买求、买车是一个家
Epoch 0 Step 001000, model loss 0.0005, LR: 0.0000100000
真实数据: 如果周围环境的信号出
结果显示: 如果周围环境的信号出
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 4.8614, LR: 0.0000100000
真实数据: 曝光“注水肉”事件后
结果显示: 喝光“注水肉”事件后
Epoch 0 Step 001200, model loss 0.0770, LR: 0.0000100000
真实数据: 后就业情况。作者声明
结果显示: 后就业情况。作者声明
Epoch 0 Step 001300, model loss 0.8477, LR: 0.0000100000
真实数据: 境界事实上也颇令中国
结果显示: 境界事实上也颇令中国
Epoch 0 Step 001400, model loss 0.0797, LR: 0.0000100000
真实数据: 个好习惯。后来，分析
结果显示: 个好习惯。后来，分析
Epoch 0 Step 001500, model loss 0.0277, LR: 0.0000100000
真实数据: 。本次大赛由安捷伦科
结果显示: 。本次大赛由安捷伦科
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 12.5902, LR: 0.0000100000
真实数据: 得扑朔迷离。尸未出井
结果显示: 得扑轻迷离。尸来出井
Epoch 0 Step 001700, model loss 13.4333, LR: 0.0000100000
真实数据: 之二潭底因淤积水深恐
结果显示: 之二钾底因游积水深恐
Epoch 0 Step 001800, model loss 0.1174, LR: 0.0000100000
真实数据: 者据此入市,饮食简单
结果显示: 者据此入市,饮食简单
Epoch 0 Step 001900, model loss 10.6923, LR: 0.0000100000
真实数据: 又有人着甲胄，据记者
结果显示: 又有人着甲肖，据记者
Epoch 0 Step 002000, model loss 0.3457, LR: 0.0000100000
真实数据: 漠自助车游、骑马游、
结果显示: 漠自助车游、骑马游、
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0404, LR: 0.0000100000
真实数据: 们最初的期待仍相去甚
结果显示: 们最初的期待仍相去甚
Epoch 0 Step 002200, model loss 0.4758, LR: 0.0000100000
真实数据: 浙江省副省长盛昌黎介
结果显示: 浙江省副省长盛昌黎介
Epoch 0 Step 002300, model loss 0.0282, LR: 0.0000100000
真实数据: 理战取得谈判过程中的
结果显示: 理战取得谈判过程中的
Epoch 0 Step 002400, model loss 0.0430, LR: 0.0000100000
真实数据: 验所谓“反超限战”成
结果显示: 验所谓“反超限战”成
Epoch 0 Step 002500, model loss 6.4331, LR: 0.0000100000
真实数据: 报酬没有问题。我很容
结果显示: 最制铅没有问题。我很容
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0063, LR: 0.0000100000
真实数据: 人类经历过的冷兵器、
结果显示: 人类经历过的冷兵器、
Epoch 0 Step 002700, model loss 12.4654, LR: 0.0000100000
真实数据: 者邀请Google等
结果显示: 者龄请Googie等
Epoch 0 Step 002800, model loss 0.1180, LR: 0.0000100000
真实数据: 即使目前3毛钱的收费
结果显示: 即使目前3毛钱的收费
Epoch 0 Step 002900, model loss 0.0284, LR: 0.0000100000
真实数据: 且他自己也具有出色的
结果显示: 且他自己也具有出色的
Epoch 0 Step 003000, model loss 0.0031, LR: 0.0000100000
真实数据: 涨幅达1.4%。生亦
结果显示: 涨幅达1.4%。生亦
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0048, LR: 0.0000100000
真实数据: 境旅游重大和较大突发
结果显示: 境旅游重大和较大突发
Epoch 0 Step 003200, model loss 0.0005, LR: 0.0000100000
真实数据: ，四场决赛有三场是3
结果显示: ，四场决赛有三场是3
Epoch 0 Step 003300, model loss 0.9779, LR: 0.0000100000
真实数据: 息室的小型总结没有按
结果显示: 息空的小型总结没有按
Epoch 0 Step 003400, model loss 0.3130, LR: 0.0000100000
真实数据: 在跨国公司的白领阶层
结果显示: 在跨国公司的白领阶层
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000250BE5F21A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.3147, LR: 0.0000100000
真实数据: 默暗示如盗版少可考虑
结果显示: 默暗示如盗版少可考虑
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.0887, LR: 0.0000100000
真实数据: 的姑娘都必须明媒正娶
结果显示: 的姑娘都必须明媒正娶
Epoch 0 Step 000200, model loss 0.0084, LR: 0.0000100000
真实数据: 一个接一个诗人朗诵了
结果显示: 一个接一个诗人朗诵了
Epoch 0 Step 000300, model loss 0.0988, LR: 0.0000100000
真实数据: 者到窗明几净的西餐厅
结果显示: 者到窗明几净的西餐厅
Epoch 0 Step 000400, model loss 5.1231, LR: 0.0000100000
真实数据: 经不多见,比如擅长跟
结果显示: 经不多见，比如擅长跟
Epoch 0 Step 000500, model loss 18.5655, LR: 0.0000100000
真实数据: 喧嚣的音乐和影视节目
结果显示: 暗器的音乐和影视节目
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.3238, LR: 0.0000100000
真实数据: 还有其它一些学术活动
结果显示: 还有其它一些学术活动
Epoch 0 Step 000700, model loss 0.7270, LR: 0.0000100000
真实数据: 高点。杨琳共找到12
结果显示: 高点。杨琳共找到12
Epoch 0 Step 000800, model loss 0.2932, LR: 0.0000100000
真实数据: 们撒谎，晚上也开，一
结果显示: 们撒谎，晚上也开，一
Epoch 0 Step 000900, model loss 0.0069, LR: 0.0000100000
真实数据: 王，“何事不了于心?
结果显示: 王，“何事不了于心?
Epoch 0 Step 001000, model loss 1.1979, LR: 0.0000100000
真实数据: 脆就只充当公款酒桌上
结果显示: 跪就只充当公款酒桌上
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.2554, LR: 0.0000100000
真实数据: 是在北方舰队核潜艇基
结果显示: 是在北方舰队核潜艇基
Epoch 0 Step 001200, model loss 23.6468, LR: 0.0000100000
真实数据: 其中仔细地挑拣洋芋疙
结果显示: 其中仔细地挑练洋李疼
Epoch 0 Step 001300, model loss 0.0040, LR: 0.0000100000
真实数据: 来京半年。现在全部小
结果显示: 来京半年。现在全部小
Epoch 0 Step 001400, model loss 0.0017, LR: 0.0000100000
真实数据: 推广自己的产品还两次
结果显示: 推广自己的产品还两次
Epoch 0 Step 001500, model loss 0.0009, LR: 0.0000100000
真实数据: 住宅市场整体均价已经
结果显示: 住宅市场整体均价已经
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0097, LR: 0.0000100000
真实数据: 却是最低的区域，然而
结果显示: 却是最低的区域，然而
Epoch 0 Step 001700, model loss 0.8697, LR: 0.0000100000
真实数据: 强烈建议，赵铁锤表示
结果显示: 强烈建议，赵铁锤表示
Epoch 0 Step 001800, model loss 0.0051, LR: 0.0000100000
真实数据: 老大不知高低!”八戒
结果显示: 老大不知高低!”八戒
Epoch 0 Step 001900, model loss 0.0853, LR: 0.0000100000
真实数据: Suppli的统计数
结果显示: Suppli的统计数
Epoch 0 Step 002000, model loss 0.4967, LR: 0.0000100000
真实数据: 没有登上度蜜月的飞机
结果显示: 没有登上度蜜月的飞机
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.2298, LR: 0.0000100000
真实数据: 因此，一定会是另外一
结果显示: 因此，一定会是另外一
Epoch 0 Step 002200, model loss 0.0621, LR: 0.0000100000
真实数据: 待物时的礼貌。1代叟
结果显示: 待物时的礼貌。1代叟
Epoch 0 Step 002300, model loss 0.0262, LR: 0.0000100000
真实数据: 日子也开始不好过了”
结果显示: 日子也开始不好过了”
Epoch 0 Step 002400, model loss 1.5009, LR: 0.0000100000
真实数据: 身体较多。使耳道暴露
结果显示: 身体较多。使目道暴露
Epoch 0 Step 002500, model loss 0.0298, LR: 0.0000100000
真实数据: 论是我本人或我的部下
结果显示: 论是我本人或我的部下
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0011, LR: 0.0000100000
真实数据: 战术状况、飞机信息以
结果显示: 战术状况、飞机信息以
Epoch 0 Step 002700, model loss 2.0876, LR: 0.0000100000
真实数据: 曾央到西方见我佛如来
结果显示: 曾央到西方见我佛如来
Epoch 0 Step 002800, model loss 4.2649, LR: 0.0000100000
真实数据: 力利用融资恢复前的时
结果显示: 力利用叶资恢复前的时
Epoch 0 Step 002900, model loss 7.3293, LR: 0.0000100000
真实数据: 和几幢破败不堪、阴气
结果显示: 和几控破败不堪、阴气
Epoch 0 Step 003000, model loss 0.0249, LR: 0.0000100000
真实数据: ，我们确实遇到了一些
结果显示: ，我们确实遇到了一些
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0402, LR: 0.0000100000
真实数据: 卡卡站在了点球点上，
结果显示: 卡卡站在了点球点上，
Epoch 0 Step 003200, model loss 0.0400, LR: 0.0000100000
真实数据: 同样是F-35，固止
结果显示: 同样是F-35，固止
Epoch 0 Step 003300, model loss 31.3798, LR: 0.0000100000
真实数据: 榛芜中，还有的地方禁
结果显示: 稀先中，还有的地方禁
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000023910D121A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 6.6365, LR: 0.0000100000
真实数据: 死亦勿归也!’”昆生
结果显示: 死亦勿归也!”昆生
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0096, LR: 0.0000100000
真实数据: 审何时可复来。曹国伟
结果显示: 审何时可复来。曹国伟
Epoch 0 Step 000200, model loss 0.0029, LR: 0.0000100000
真实数据: 将军用计击毙曹操爱将
结果显示: 将军用计击毙曹操爱将
Epoch 0 Step 000300, model loss 2.4146, LR: 0.0000100000
真实数据: 叶刘淑仪的丈夫因病逝
结果显示: 叶刘淑仪的丈夫因病虚
Epoch 0 Step 000400, model loss 5.2299, LR: 0.0000100000
真实数据: 呵呵。为了应付排队，
结果显示: 呵。为了应付编队，
Epoch 0 Step 000500, model loss 0.0102, LR: 0.0000100000
真实数据: 进行的服装设计赢得了
结果显示: 进行的服装设计赢得了
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 7.6653, LR: 0.0000100000
真实数据: 壳鹭滩，由此可以想见
结果显示: 壳隗滩，由此可以想见
Epoch 0 Step 000700, model loss 0.1527, LR: 0.0000100000
真实数据: 务收入占总收入的比重
结果显示: 务收入占总收入的比重
Epoch 0 Step 000800, model loss 0.0701, LR: 0.0000100000
真实数据: 就已经在削减大西洋那
结果显示: 就已经在削减大西洋那
Epoch 0 Step 000900, model loss 12.3076, LR: 0.0000100000
真实数据: 即签下了一笔不小的订
结果显示: 足答下了一告不小的订
Epoch 0 Step 001000, model loss 0.0485, LR: 0.0000100000
真实数据: stretchD.s
结果显示: stretchD.s
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 1.2553, LR: 0.0000100000
真实数据: 刚刚冲上围甲的平煤集
结果显示: 刚刚冲上围甲的平煤集
Epoch 0 Step 001200, model loss 15.1978, LR: 0.0000100000
真实数据: 士们修蘸，但望乱山丛
结果显示: 士们修陈，但望乱出易
Epoch 0 Step 001300, model loss 0.0083, LR: 0.0000100000
真实数据: 、日、意等语种的单行
结果显示: 、日、意等语种的单行
Epoch 0 Step 001400, model loss 0.0285, LR: 0.0000100000
真实数据: 要穿上自己的民族服装
结果显示: 要穿上自己的民族服装
Epoch 0 Step 001500, model loss 2.6718, LR: 0.0000100000
真实数据: 古纳兰对媒体吹风时说
结果显示: 右纳兰对媒体吹风时说
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 1.9311, LR: 0.0000100000
真实数据: 都不宽恕”（鲁迅语）
结果显示: 都不宽想”（鲁迅语）
Epoch 0 Step 001700, model loss 1.7724, LR: 0.0000100000
真实数据: （二）纳粹报业政策特
结果显示: （二）纳卦报业政策特
Epoch 0 Step 001800, model loss 0.0029, LR: 0.0000100000
真实数据: 定的比列确定你的最终
结果显示: 定的比列确定你的最终
Epoch 0 Step 001900, model loss 7.1246, LR: 0.0000100000
真实数据: 此时败叶垂霜蕊，换一
结果显示: 此时败叶垂霜诃，换一
Epoch 0 Step 002000, model loss 1.9474, LR: 0.0000100000
真实数据: 凡此皆与遂山平时家教
结果显示: 凡此替与遂山平时家教
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0099, LR: 0.0000100000
真实数据: 次要发展，据我的经验
结果显示: 次要发展，据我的经验
Epoch 0 Step 002200, model loss 0.0009, LR: 0.0000100000
真实数据: ，在得知无法用和平手
结果显示: ，在得知无法用和平手
Epoch 0 Step 002300, model loss 0.0258, LR: 0.0000100000
真实数据: 去掉了自己的深度与厚
结果显示: 去掉了自己的深度与厚
Epoch 0 Step 002400, model loss 0.0052, LR: 0.0000100000
真实数据: 作与知识相对的“识知
结果显示: 作与知识相对的“识知
Epoch 0 Step 002500, model loss 0.1121, LR: 0.0000100000
真实数据: 不宜随意使用未经深思
结果显示: 不宜随意使用未经深思
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.2862, LR: 0.0000100000
真实数据: “重生后，我们一会见
结果显示: “重生后，我们一会见
Epoch 0 Step 002700, model loss 0.0025, LR: 0.0000100000
真实数据: 19要求考生说出特点
结果显示: 19要求考生说出特点
Epoch 0 Step 002800, model loss 0.0046, LR: 0.0000100000
真实数据: 像他那样深刻和系统地
结果显示: 像他那样深刻和系统地
Epoch 0 Step 002900, model loss 0.4132, LR: 0.0000100000
真实数据: 人在考前受到消极暗示
结果显示: 人在考前受到消极暗示
Epoch 0 Step 003000, model loss 0.0600, LR: 0.0000100000
真实数据: 即使没有上帝，依法追
结果显示: 即使没有上帝，依法追
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0236, LR: 0.0000100000
真实数据: 我度、如此尺度、如此
结果显示: 我度、如此尺度、如此
Epoch 0 Step 003200, model loss 0.0092, LR: 0.0000100000
真实数据: 旁边还有一张是他给我
结果显示: 旁边还有一张是他给我
Epoch 0 Step 003300, model loss 0.0039, LR: 0.0000100000
真实数据: 恩来特意指示选择这些
结果显示: 恩来特意指示选择这些
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000210C27A21A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 3.7560, LR: 0.0000100000
真实数据: 动，用手轻轻按压菠萝
结果显示: 动，用手轻轻按压潜萝
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 6.3795, LR: 0.0000100000
真实数据: ansion）;舍小
结果显示: ansion）;舍小I、
Epoch 0 Step 000200, model loss 0.2871, LR: 0.0000100000
真实数据: 销名令归。你两个既来
结果显示: 销名令归。你两个既来
Epoch 0 Step 000300, model loss 5.4162, LR: 0.0000100000
真实数据: 臭不可近。下列词语具
结果显示: 实不可近。下列词语具
Epoch 0 Step 000400, model loss 0.8130, LR: 0.0000100000
真实数据: 间3、简答题永绝琴瑟
结果显示: 间3、简答题永绝琴瑟
Epoch 0 Step 000500, model loss 0.0049, LR: 0.0000100000
真实数据: 以后就是看到了，“今
结果显示: 以后就是看到了，“今
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0126, LR: 0.0000100000
真实数据: 想内部人士透露，翘首
结果显示: 想内部人士透露，翘首
Epoch 0 Step 000700, model loss 0.0310, LR: 0.0000100000
真实数据: 狼星的光线，2006
结果显示: 狼星的光线，2006
Epoch 0 Step 000800, model loss 0.9410, LR: 0.0000100000
真实数据: 路由器B配置如下“倘
结果显示: 路由器B配置如下“倘
Epoch 0 Step 000900, model loss 5.4071, LR: 0.0000100000
真实数据: 民族本身是一种驳杂的
结果显示: 民族本身是一种股杂的
Epoch 0 Step 001000, model loss 5.5810, LR: 0.0000100000
真实数据: 考之前很多考生会听到
结果显示: 考之前福多考生会喷到
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0163, LR: 0.0000100000
真实数据: ，所幸他们只有笔杆子
结果显示: ，所幸他们只有笔杆子
Epoch 0 Step 001200, model loss 0.0039, LR: 0.0000100000
真实数据: 周帅说。但却是快乐的
结果显示: 周帅说。但却是快乐的
Epoch 0 Step 001300, model loss 0.0017, LR: 0.0000100000
真实数据: 永远不能主宰菜的品质
结果显示: 永远不能主宰菜的品质
Epoch 0 Step 001400, model loss 0.2124, LR: 0.0000100000
真实数据: 不敷出，也许事情还可
结果显示: 不敷出，也许事情还可
Epoch 0 Step 001500, model loss 1.8814, LR: 0.0000100000
真实数据: 强表示，B、鱼缸中的
结果显示: 强表示，B、鱼氨中的
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0361, LR: 0.0000100000
真实数据: 仅仅是一所师范类的院
结果显示: 仅仅是一所师范类的院
Epoch 0 Step 001700, model loss 0.0089, LR: 0.0000100000
真实数据: 何遽不如先生?”主人
结果显示: 何遽不如先生?”主人
Epoch 0 Step 001800, model loss 0.0188, LR: 0.0000100000
真实数据: 也曾天晚送黄昏。例如
结果显示: 也曾天晚送黄昏。例如
Epoch 0 Step 001900, model loss 0.0062, LR: 0.0000100000
真实数据: 理的位置上做了3年以
结果显示: 理的位置上做了3年以
Epoch 0 Step 002000, model loss 0.1249, LR: 0.0000100000
真实数据: （五）历年真题对于司
结果显示: （五）历年真题对于司
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0006, LR: 0.0000100000
真实数据: 的个股如G申能(行情
结果显示: 的个股如G申能(行情
Epoch 0 Step 002200, model loss 0.7914, LR: 0.0000100000
真实数据: 有利于帮助困难对象实
结果显示: 有利于帮助困难对象实
Epoch 0 Step 002300, model loss 0.0700, LR: 0.0000100000
真实数据: 放。球场上的孩子们遭
结果显示: 放。球场上的孩子们遭
Epoch 0 Step 002400, model loss 0.1650, LR: 0.0000100000
真实数据: 国与俄罗斯会在航天领
结果显示: 国与俄罗斯会在航天领
Epoch 0 Step 002500, model loss 1.8462, LR: 0.0000100000
真实数据: 最晚于5月17日复牌
结果显示: 最晚于5月17日复牌
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 18.9784, LR: 0.0000100000
真实数据: 参加过柬埔寨维和行动
结果显示: 参加过束捕察维和行动
Epoch 0 Step 002700, model loss 0.0221, LR: 0.0000100000
真实数据: shouldbego
结果显示: shouldbego
Epoch 0 Step 002800, model loss 0.0020, LR: 0.0000100000
真实数据: 。成为这座安静小镇的
结果显示: 。成为这座安静小镇的
Epoch 0 Step 002900, model loss 0.1826, LR: 0.0000100000
真实数据: !”那次战争中，它必
结果显示: !”那次战争中，它必
Epoch 0 Step 003000, model loss 4.9909, LR: 0.0000100000
真实数据: 最后得出结论为:竟许
结果显示: 最后得出结论为:竞许
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 9.0731, LR: 0.0000100000
真实数据: 行车十万余公里，目的
结果显示: 行车十万金公里，日的
Epoch 0 Step 003200, model loss 0.0009, LR: 0.0000100000
真实数据: 果农业银行也有意见了
结果显示: 果农业银行也有意见了
Epoch 0 Step 003300, model loss 0.0045, LR: 0.0000100000
真实数据: 2][3][4][5
结果显示: 2][3][4][5
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x000001B4645821A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.1765, LR: 0.0000100000
真实数据: 吹大作，哭而入，每天
结果显示: 吹大作，哭而入，每天
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0049, LR: 0.0000100000
真实数据: 巧合的是，也只能约略
结果显示: 巧合的是，也只能约略
Epoch 0 Step 000200, model loss 0.0119, LR: 0.0000100000
真实数据: 是中国企业发展的一个
结果显示: 是中国企业发展的一个
Epoch 0 Step 000300, model loss 0.0745, LR: 0.0000100000
真实数据: 五一期间购买R系列和
结果显示: 五一期间购买R系列和
Epoch 0 Step 000400, model loss 0.0017, LR: 0.0000100000
真实数据: 但是执行率只有30%
结果显示: 但是执行率只有30%
Epoch 0 Step 000500, model loss 0.4584, LR: 0.0000100000
真实数据: 的积极意义首先在于全
结果显示: 的积极意义首先在于全
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 1.0517, LR: 0.0000100000
真实数据: ‘考研是什么’还一无
结果显示: '考研是什么’还一无
Epoch 0 Step 000700, model loss 0.0011, LR: 0.0000100000
真实数据: 当日，andhapp
结果显示: 当日，andhapp
Epoch 0 Step 000800, model loss 0.1501, LR: 0.0000100000
真实数据: 料及动力购进价格的上
结果显示: 料及动力购进价格的上
Epoch 0 Step 000900, model loss 0.0018, LR: 0.0000100000
真实数据: “分析中国国防开支非
结果显示: “分析中国国防开支非
Epoch 0 Step 001000, model loss 0.0096, LR: 0.0000100000
真实数据: …第3页:B型职业女
结果显示: …第3页:B型职业女
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.5501, LR: 0.0000100000
真实数据: 的计算机制造商惠普公
结果显示: 的计算机制造商惠普公
Epoch 0 Step 001200, model loss 6.3698, LR: 0.0000100000
真实数据: 这等俊俏!”不敢表达
结果显示: 这等俊倩!”不敢表达
Epoch 0 Step 001300, model loss 0.0148, LR: 0.0000100000
真实数据: 一记叙型文体也会写复
结果显示: 一记叙型文体也会写复
Epoch 0 Step 001400, model loss 0.0029, LR: 0.0000100000
真实数据: 到非典之前没有做过广
结果显示: 到非典之前没有做过广
Epoch 0 Step 001500, model loss 0.5568, LR: 0.0000100000
真实数据: 字广播、企业级数据管
结果显示: 字广播、企业级数据管
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.3087, LR: 0.0000100000
真实数据: 映手机与人的关系。必
结果显示: 映手机与人的关系。必
Epoch 0 Step 001700, model loss 0.4233, LR: 0.0000100000
真实数据: 且至今我依然这么认为
结果显示: 且至今我依然这么认为
Epoch 0 Step 001800, model loss 0.0043, LR: 0.0000100000
真实数据: 是将这种话语传达给观
结果显示: 是将这种话语传达给观
Epoch 0 Step 001900, model loss 0.4381, LR: 0.0000100000
真实数据: 要平平安安，并在此筹
结果显示: 要平平安安，并在此筹
Epoch 0 Step 002000, model loss 0.0177, LR: 0.0000100000
真实数据: 工作和你目前的工作非
结果显示: 工作和你目前的工作非
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 1.2598, LR: 0.0000100000
真实数据: 潘玮柏（左二）昨天与
结果显示: 潘玮柏（左二）昨天与
Epoch 0 Step 002200, model loss 0.0274, LR: 0.0000100000
真实数据: 无疾病，一上井冈山就
结果显示: 无疾病，一上井冈山就
Epoch 0 Step 002300, model loss 0.0050, LR: 0.0000100000
真实数据: 司两家非流通股东表示
结果显示: 司两家非流通股东表示
Epoch 0 Step 002400, model loss 4.2485, LR: 0.0000100000
真实数据: 能说，”[图文]不会
结果显示: 能说，”[图文不会
Epoch 0 Step 002500, model loss 0.0004, LR: 0.0000100000
真实数据: 较好地完成了教学任务
结果显示: 较好地完成了教学任务
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.3088, LR: 0.0000100000
真实数据: 是打引号的，劝投行伍
结果显示: 是打引号的，劝投行伍
Epoch 0 Step 002700, model loss 0.0095, LR: 0.0000100000
真实数据: 也?”其人力辩生平不
结果显示: 也?”其人力辩生平不
Epoch 0 Step 002800, model loss 1.8989, LR: 0.0000100000
真实数据: 把所有的不快诉诸文字
结果显示: 把所有的不快诉衷文字
Epoch 0 Step 002900, model loss 0.5697, LR: 0.0000100000
真实数据: 旬，简上的文字达数十
结果显示: 旬，简上的文字达数十
Epoch 0 Step 003000, model loss 0.0051, LR: 0.0000100000
真实数据: 个人带来什么负面影响
结果显示: 个人带来什么负面影响
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.1389, LR: 0.0000100000
真实数据: ghtyC)vagu
结果显示: ghtyC)vagu
Epoch 0 Step 003200, model loss 1.0490, LR: 0.0000100000
真实数据: 龙降,倒是外国法制史
结果显示: 龙障,倒是外国法制史
Epoch 0 Step 003300, model loss 1.6507, LR: 0.0000100000
真实数据: 以成效如何，（1）把
结果显示: 以成效如何，（1）把
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000017EC23821A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0023, LR: 0.0000100000
真实数据: 考虑你该做哪些事期间
结果显示: 考虑你该做哪些事期间
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.1920, LR: 0.0000100000
真实数据: 本《女学杂志》513
结果显示: 本《女学杂志》513
Epoch 0 Step 000200, model loss 0.0297, LR: 0.0000100000
真实数据: 方便拍照，家中事就便
结果显示: 方便拍照，家中事就便
Epoch 0 Step 000300, model loss 4.6496, LR: 0.0000100000
真实数据: 有16枚M45弹道导
结果显示: 有16M45弹道导
Epoch 0 Step 000400, model loss 0.0024, LR: 0.0000100000
真实数据: 被中国青年报军事周刊
结果显示: 被中国青年报军事周刊
Epoch 0 Step 000500, model loss 7.8152, LR: 0.0000100000
真实数据: 个名叫魏继宗的平民上
结果显示: 个名叫赫继南的平民上
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.3302, LR: 0.0000100000
真实数据: 去走自己想走的路!他
结果显示: 去走自己想走的路!他
Epoch 0 Step 000700, model loss 0.0065, LR: 0.0000100000
真实数据: 分的法律人认为他们可
结果显示: 分的法律人认为他们可
Epoch 0 Step 000800, model loss 0.0382, LR: 0.0000100000
真实数据: 来;比如颠峰要不要背
结果显示: 来;比如颠峰要不要背
Epoch 0 Step 000900, model loss 0.0037, LR: 0.0000100000
真实数据: 他们学习一门或几门的
结果显示: 他们学习一门或几门的
Epoch 0 Step 001000, model loss 0.4064, LR: 0.0000100000
真实数据: Mansion上海报
结果显示: Mansion上海报
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0423, LR: 0.0000100000
真实数据: 自由发展只有百害而无
结果显示: 自由发展只有百害而无
Epoch 0 Step 001200, model loss 0.0138, LR: 0.0000100000
真实数据: 管此事的官员Mari
结果显示: 管此事的官员Mari
Epoch 0 Step 001300, model loss 0.0226, LR: 0.0000100000
真实数据: 部开始了名为战略无人
结果显示: 部开始了名为战略无人
Epoch 0 Step 001400, model loss 0.0795, LR: 0.0000100000
真实数据: ，例如由于中央翼盒产
结果显示: ，例如由于中央翼盒产
Epoch 0 Step 001500, model loss 0.2630, LR: 0.0000100000
真实数据: ，欧莱雅中国公司副总
结果显示: ，欧莱雅中国公司副总
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0439, LR: 0.0000100000
真实数据: 你们之间的心理距离扩
结果显示: 你们之间的心理距离扩
Epoch 0 Step 001700, model loss 0.0917, LR: 0.0000100000
真实数据: 哲学原理（0001）
结果显示: 哲学原理（0001）
Epoch 0 Step 001800, model loss 0.0476, LR: 0.0000100000
真实数据: 中更要仔细。市里有潮
结果显示: 中更要仔细。市里有潮
Epoch 0 Step 001900, model loss 0.0020, LR: 0.0000100000
真实数据: 从前期比赛的过程来看
结果显示: 从前期比赛的过程来看
Epoch 0 Step 002000, model loss 0.0064, LR: 0.0000100000
真实数据: RAAF订购了5架A
结果显示: RAAF订购了5架A
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0192, LR: 0.0000100000
真实数据: 房价问题已经变成上海
结果显示: 房价问题已经变成上海
Epoch 0 Step 002200, model loss 0.0013, LR: 0.0000100000
真实数据: 比赛的最后六次出手，
结果显示: 比赛的最后六次出手，
Epoch 0 Step 002300, model loss 0.1204, LR: 0.0000100000
真实数据: 术工业委员会主任张云
结果显示: 术工业委员会主任张云
Epoch 0 Step 002400, model loss 0.0064, LR: 0.0000100000
真实数据: 4记者曾就这份清单向
结果显示: 4记者曾就这份清单向
Epoch 0 Step 002500, model loss 3.9893, LR: 0.0000100000
真实数据: 也难以避免不受辐射影
结果显示: 也难以避免不受辅射影
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0015, LR: 0.0000100000
真实数据: 队在中超联赛第11轮
结果显示: 队在中超联赛第11轮
Epoch 0 Step 002700, model loss 0.7114, LR: 0.0000100000
真实数据: 据机动载荷(又称惯性
结果显示: 据机动载荷(又称惯性
Epoch 0 Step 002800, model loss 0.1552, LR: 0.0000100000
真实数据: 万科公司取得了良好的
结果显示: 万科公司取得了良好的
Epoch 0 Step 002900, model loss 0.0224, LR: 0.0000100000
真实数据: 给老板一个善意的提醒
结果显示: 给老板一个善意的提醒
Epoch 0 Step 003000, model loss 2.1223, LR: 0.0000100000
真实数据: 思考后，真没办法下筷
结果显示: 思考后，真没办法下焚
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0060, LR: 0.0000100000
真实数据: 在其他因素相同的情况
结果显示: 在其他因素相同的情况
Epoch 0 Step 003200, model loss 2.8924, LR: 0.0000100000
真实数据: 辽圣宗（公元982-
结果显示: 迁圣宗（公元982-
Epoch 0 Step 003300, model loss 0.0064, LR: 0.0000100000
真实数据: 科研活动总会引起美国
结果显示: 科研活动总会引起美国
Epoch 0 Step 003400, model loss 0.2630, LR: 0.0000100000
真实数据: 来愈自卑了.年轻人里
结果显示: 来愈自卑了.年轻人里
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000022AE35E11A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0081, LR: 0.0000100000
真实数据: 游客的导游该挣小费么
结果显示: 游客的导游该挣小费么
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 1.9507, LR: 0.0000100000
真实数据: 样的差别出现在“意志
结果显示: 样的差别出现在一“意志
Epoch 0 Step 000200, model loss 0.0319, LR: 0.0000100000
真实数据: 邮件病毒的特征较为鲜
结果显示: 邮件病毒的特征较为鲜
Epoch 0 Step 000300, model loss 0.0071, LR: 0.0000100000
真实数据: 的待遇与最合适的位置
结果显示: 的待遇与最合适的位置
Epoch 0 Step 000400, model loss 0.0444, LR: 0.0000100000
真实数据: 事;电气化装甲车辆比
结果显示: 事;电气化装甲车辆比
Epoch 0 Step 000500, model loss 0.0244, LR: 0.0000100000
真实数据: PN评论员说:息肩逆
结果显示: PN评论员说:息肩逆
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 7.3876, LR: 0.0000100000
真实数据: 又称为南无宝幢光王佛
结果显示: 又称为南无宝惨光王佛
Epoch 0 Step 000700, model loss 3.6675, LR: 0.0000100000
真实数据: 轮面对国安的狂轰滥炸
结果显示: 轮面对国安的狂轰溢炸
Epoch 0 Step 000800, model loss 0.8961, LR: 0.0000100000
真实数据: 他人，弹头内部发生腐
结果显示: 他人，弹头内部发生腐
Epoch 0 Step 000900, model loss 0.0030, LR: 0.0000100000
真实数据: 但绝不能一味听从孩子
结果显示: 但绝不能一味听从孩子
Epoch 0 Step 001000, model loss 7.8957, LR: 0.0000100000
真实数据: 生物。3、Inter
结果显示: 生物。3、mnter
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0360, LR: 0.0000100000
真实数据: 在西安参加了2场比赛
结果显示: 在西安参加了2场比赛
Epoch 0 Step 001200, model loss 0.0258, LR: 0.0000100000
真实数据: 至王府井南口”、“王
结果显示: 至王府井南口”、“王
Epoch 0 Step 001300, model loss 0.1060, LR: 0.0000100000
真实数据: 有所须，从结局看除了
结果显示: 有所须，从结局看除了
Epoch 0 Step 001400, model loss 2.5518, LR: 0.0000100000
真实数据: 次委托董事会投票为准
结果显示: 次瞽托董事会投票为准
Epoch 0 Step 001500, model loss 0.0707, LR: 0.0000100000
真实数据: 。她给我取了这个名字
结果显示: 。她给我取了这个名字
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 16.2219, LR: 0.0000100000
真实数据: ，否则易产生乙醚等副
结果显示: ，否则易产生乙敌等副
Epoch 0 Step 001700, model loss 0.3754, LR: 0.0000100000
真实数据: 夫救助葛振林、宋学义
结果显示: 夫救助葛振林、宋学义
Epoch 0 Step 001800, model loss 36.5374, LR: 0.0000100000
真实数据: 说:李金羽令人遐思邈
结果显示: 说:李金就令人越思退
Epoch 0 Step 001900, model loss 0.0061, LR: 0.0000100000
真实数据: 至目前，也是国内最大
结果显示: 至目前，也是国内最大
Epoch 0 Step 002000, model loss 0.2834, LR: 0.0000100000
真实数据: 政府决策保留艺术区核
结果显示: 政府决策保留艺术区核
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0228, LR: 0.0000100000
真实数据: 相信他们有很多是针对
结果显示: 相信他们有很多是针对
Epoch 0 Step 002200, model loss 0.0268, LR: 0.0000100000
真实数据: 占到整个集团的3/4
结果显示: 占到整个集团的3/4
Epoch 0 Step 002300, model loss 0.0015, LR: 0.0000100000
真实数据: 变得沉重起来?本该欢
结果显示: 变得沉重起来?本该欢
Epoch 0 Step 002400, model loss 0.0126, LR: 0.0000100000
真实数据: 无效。我想:一脚补射
结果显示: 无效。我想:一脚补射
Epoch 0 Step 002500, model loss 0.2929, LR: 0.0000100000
真实数据: 与眼下壁分离，应派奖
结果显示: 与眼下壁分离，应派奖
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 0.0443, LR: 0.0000100000
真实数据: 年也。哩。实际上我们
结果显示: 年也。哩。实际上我们
Epoch 0 Step 002700, model loss 0.0053, LR: 0.0000100000
真实数据: 李达从日本回国到上海
结果显示: 李达从日本回国到上海
Epoch 0 Step 002800, model loss 7.2116, LR: 0.0000100000
真实数据: 的眼神就是他的指南针
结果显示: 的康神就是他的指南针
Epoch 0 Step 002900, model loss 4.9904, LR: 0.0000100000
真实数据: 原创电视动画剧(片)
结果显示: 原创电视动画剧(片）
Epoch 0 Step 003000, model loss 0.1054, LR: 0.0000100000
真实数据: 由:演练保证“动脉”
结果显示: 由:演练保证“动脉”
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0009, LR: 0.0000100000
真实数据: 到说话声，不仅是专业
结果显示: 到说话声，不仅是专业
Epoch 0 Step 003200, model loss 0.1157, LR: 0.0000100000
真实数据: 丸，于是晚间黄金价格
结果显示: 丸，于是晚间黄金价格
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x00000159CEE451A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 1.3083, LR: 0.0000100000
真实数据: ，因此，天文计算表明
结果显示: 、因此，天文计算表明
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0066, LR: 0.0000100000
真实数据: 因保唐僧，七人得分上
结果显示: 因保唐僧，七人得分上
Epoch 0 Step 000200, model loss 0.0004, LR: 0.0000100000
真实数据: 现了收取保证金的现象
结果显示: 现了收取保证金的现象
Epoch 0 Step 000300, model loss 0.4277, LR: 0.0000100000
真实数据: 一体、网上答疑咨询网
结果显示: 一体、网上答疑咨询网
Epoch 0 Step 000400, model loss 5.2358, LR: 0.0000100000
真实数据: 加了一定量的膳食纤维
结果显示: 加了一定量的脑食纤维
Epoch 0 Step 000500, model loss 0.0622, LR: 0.0000100000
真实数据: 起一个很好的推动和促
结果显示: 起一个很好的推动和促
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0050, LR: 0.0000100000
真实数据: 改之初为确保改革的顺
结果显示: 改之初为确保改革的顺
Epoch 0 Step 000700, model loss 2.4999, LR: 0.0000100000
真实数据: 到处都是啤酒馆，13
结果显示: 到处都是晖酒馆，13
Epoch 0 Step 000800, model loss 0.0046, LR: 0.0000100000
真实数据: 关于市场中国居民投资
结果显示: 关于市场中国居民投资
Epoch 0 Step 000900, model loss 0.0121, LR: 0.0000100000
真实数据: 权。陆试图联系未果后
结果显示: 权。陆试图联系未果后
Epoch 0 Step 001000, model loss 0.0392, LR: 0.0000100000
真实数据: 986年通过的义务教
结果显示: 986年通过的义务教
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 0.0029, LR: 0.0000100000
真实数据: 海战略》也就是通过协
结果显示: 海战略》也就是通过协
Epoch 0 Step 001200, model loss 0.0132, LR: 0.0000100000
真实数据: 他们又没有其它的技能
结果显示: 他们又没有其它的技能
Epoch 0 Step 001300, model loss 0.0072, LR: 0.0000100000
真实数据: 们对此的价值判断与经
结果显示: 们对此的价值判断与经
Epoch 0 Step 001400, model loss 0.5925, LR: 0.0000100000
真实数据: 大悲的菩萨。尹得其故
结果显示: 大悲的菩萨。尹得其故
Epoch 0 Step 001500, model loss 0.0733, LR: 0.0000100000
真实数据: 独一无二，张急避暗处
结果显示: 独一无二，张急避暗处
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 0.0024, LR: 0.0000100000
真实数据: 部分原因是某些企业的
结果显示: 部分原因是某些企业的
Epoch 0 Step 001700, model loss 1.2669, LR: 0.0000100000
真实数据: 主要靠募捐或自掏腰包
结果显示: 主要靠募捐或自梅腰包
Epoch 0 Step 001800, model loss 0.2798, LR: 0.0000100000
真实数据: 受此影响，生见之，如
结果显示: 受此影响，生见之，如
Epoch 0 Step 001900, model loss 0.0172, LR: 0.0000100000
真实数据: 盟。他一定要娶李国华
结果显示: 盟。他一定要娶李国华
Epoch 0 Step 002000, model loss 0.0460, LR: 0.0000100000
真实数据: 可把整个世界炸毁数次
结果显示: 可把整个世界炸毁数次
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002100, model loss 0.0441, LR: 0.0000100000
真实数据: 草也能读出其中的词句
结果显示: 草也能读出其中的词句
Epoch 0 Step 002200, model loss 0.0886, LR: 0.0000100000
真实数据: 个相关网页.普京拍板
结果显示: 个相关网页.普京拍板
Epoch 0 Step 002300, model loss 44.8874, LR: 0.0000100000
真实数据: 烟生，簇拥着安妮的遗
结果显示: 按生，赞拥着安姚的道
Epoch 0 Step 002400, model loss 0.3242, LR: 0.0000100000
真实数据: ion你不要向他说得
结果显示: ion你不要向他说得
Epoch 0 Step 002500, model loss 0.0368, LR: 0.0000100000
真实数据: 至，浙江经济管理职工
结果显示: 至，浙江经济管理职工
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 002600, model loss 3.5286, LR: 0.0000100000
真实数据: 经济社会发展的主要目
结果显示: 经济社会发展的主罩目
Epoch 0 Step 002700, model loss 0.3757, LR: 0.0000100000
真实数据: gamebooker
结果显示: gamebooker
Epoch 0 Step 002800, model loss 3.4263, LR: 0.0000100000
真实数据: 太平洋马里亚纳群岛南
结果显示: 太平洋卫里亚纳群岛南
Epoch 0 Step 002900, model loss 0.2147, LR: 0.0000100000
真实数据: 华群161递交申请材
结果显示: 华群161递交申请材
Epoch 0 Step 003000, model loss 0.0011, LR: 0.0000100000
真实数据: 面对自己认识的一些优
结果显示: 面对自己认识的一些优
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 003100, model loss 0.0417, LR: 0.0000100000
真实数据: 数每天重复着在键盘上
结果显示: 数每天重复着在键盘上
Epoch 0 Step 003200, model loss 0.4689, LR: 0.0000100000
真实数据: ree”。需要的是激
结果显示: ree”。需要的是激
Epoch 0 Step 003300, model loss 0.0332, LR: 0.0000100000
真实数据: His如果志愿填报不
结果显示: His如果志愿填报不
nohup /home/gaofangjie/tvenv/bin/python3 train_load.py > /home/gaofangjie/train_data.txt 2>&1&
inputs: <class 'tensorflow.python.framework.ops.Tensor'> (1, 224, ?, 3)
densenet169_fine_tuning: (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, 7, ?, 1664)
net: <class 'tensorflow.python.framework.ops.Tensor'> (1, ?, 7, 1664) ? 7 1664
dim: 1 None 11648
feature_map shape Tensor("model_ops/strided_slice:0", shape=(), dtype=int32) 1 Tensor("model_ops/Shape_1:0", shape=(3,), dtype=int32)
logits: (1, ?, 5827)
Tensor("lable_seq:0", shape=(1, ?), dtype=int32)
Tensor("model_ops/Cast:0", shape=(1,), dtype=int32)
loss: Tensor("model_ops/CTCLoss:0", shape=(1,), dtype=float32)
cost Tensor("model_ops/Mean:0", shape=(), dtype=float32)
logits: (?, 1, 5827)
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
max_steps: 3644007
continue training from previous checkpoint 0
<generator object get_batch at 0x0000022E765E21A8>
epoch: 0
generator..............
D:\tensorflow\Synthetic_Chinese_String_Dataset\image
Find 3644007 images
3644007 training images in D:\tensorflow\Synthetic_Chinese_String_Dataset
Epoch 0 Step 000000, model loss 0.0046, LR: 0.0000100000
真实数据: 分利用上海文广新闻传
结果显示: 分利用上海文广新闻传
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000100, model loss 0.0128, LR: 0.0000100000
真实数据: 文化产业只需从中盈利
结果显示: 文化产业只需从中盈利
Epoch 0 Step 000200, model loss 0.0099, LR: 0.0000100000
真实数据: 人先、争创一流的雄心
结果显示: 人先、争创一流的雄心
Epoch 0 Step 000300, model loss 0.0052, LR: 0.0000100000
真实数据: 主要从事中成药生产经
结果显示: 主要从事中成药生产经
Epoch 0 Step 000400, model loss 0.0001, LR: 0.0000100000
真实数据: 了解到的许多过去不为
结果显示: 了解到的许多过去不为
Epoch 0 Step 000500, model loss 0.3987, LR: 0.0000100000
真实数据: 同时每框都有NBA官
结果显示: 同时每框都有NBA官
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 000600, model loss 0.0004, LR: 0.0000100000
真实数据: 、通过公司2005年
结果显示: 、通过公司2005年
Epoch 0 Step 000700, model loss 7.9395, LR: 0.0000100000
真实数据: （记者潘云召杨晴川）
结果显示: （记者潘云召杨睛川）
Epoch 0 Step 000800, model loss 2.1443, LR: 0.0000100000
真实数据: 每延师，多加了一层被
结果显示: 每延师，乡加了一层被
Epoch 0 Step 000900, model loss 0.1891, LR: 0.0000100000
真实数据: 罗伦萨的一举一动不仅
结果显示: 罗伦萨的一举一动不仅
Epoch 0 Step 001000, model loss 0.1547, LR: 0.0000100000
真实数据: 的报价从5000～8
结果显示: 的报价从5000～8
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001100, model loss 21.1330, LR: 0.0000100000
真实数据: 搪塞何为?”天明而去
结果显示: 塞何为?”天明而杰
Epoch 0 Step 001200, model loss 0.0316, LR: 0.0000100000
真实数据: 女者，科推动后勤改革
结果显示: 女者，科推动后勤改革
Epoch 0 Step 001300, model loss 0.0027, LR: 0.0000100000
真实数据: 从成交市场看，据日本
结果显示: 从成交市场看，据日本
Epoch 0 Step 001400, model loss 0.1308, LR: 0.0000100000
真实数据: 盛先生与店内数人员再
结果显示: 盛先生与店内数人员再
Epoch 0 Step 001500, model loss 0.1152, LR: 0.0000100000
真实数据: 过去所说的“世界上只
结果显示: 过去所说的“世界上只
Write model to: D:\tensorflow\densenet_bilstm_ctc\ckpt\ocr_0.ckpt
Epoch 0 Step 001600, model loss 7.9743, LR: 0.0000100000
真实数据: 涤，麦克-毕比得到1
结果显示: 溯，麦克-毕比得到1
Epoch 0 Step 001700, model loss 0.0244, LR: 0.0000100000
真实数据: 回白抚公，speci
结果显示: 回白抚公，speci
